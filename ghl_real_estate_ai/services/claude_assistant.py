"""
Claude Assistant Service - Centralized AI Intelligence for the GHL Platform
Provides context-aware insights, action recommendations, and interactive support.
"""
import streamlit as st
import pandas as pd
from datetime import datetime
from typing import Dict, List, Any, Optional

class ClaudeAssistant:
    """
    The brain of the platform's UI. 
    Maintains state and provides context-specific intelligence.
    """
    
    def __init__(self, context_type: str = "general"):
        self.context_type = context_type
        self._initialize_state()

    def _initialize_state(self):
        if 'claude_greeted' not in st.session_state:
            st.session_state.claude_greeted = False
        if 'claude_history' not in st.session_state:
            st.session_state.claude_history = []

    def render_sidebar_panel(self, hub_name: str, market: str, leads: Dict[str, Any]):
        """Renders the persistent sidebar intelligence panel."""
        with st.sidebar:
            st.markdown("---")
            st.markdown(f"""
            <div style='background: linear-gradient(135deg, #6D28D9 0%, #4C1D95 100%); 
                        padding: 1.25rem; border-radius: 12px; color: white; margin-bottom: 1rem;
                        box-shadow: 0 4px 15px rgba(109, 40, 217, 0.3); position: relative; overflow: hidden;'>
                <div style='position: absolute; top: -10px; right: -10px; font-size: 3rem; opacity: 0.2;'>ðŸ¤–</div>
                <h3 style='color: white !important; margin: 0; font-size: 1.1rem; display: flex; align-items: center; gap: 8px;'>
                    <span>Claude Intelligence</span>
                    <span style='background: #10B981; width: 8px; height: 8px; border-radius: 50%; display: inline-block; animation: pulse 2s infinite;'></span>
                </h3>
                <p style='color: rgba(255,255,255,0.9); margin: 0.5rem 0 0 0; font-size: 0.8rem; line-height: 1.4;'>
                    Context: <b>{hub_name}</b> ({market})
                </p>
            </div>
            """, unsafe_allow_html=True)

            # Generate and show context-aware insight
            insight = self.get_insight(hub_name, leads)
            st.info(f"ðŸ’¡ **Claude's Note:** {insight}")
            
            # Interactive Query
            self.render_chat_interface(leads, market)

    def get_insight(self, hub_name: str, leads: Dict[str, Any]) -> str:
        """Generates a contextual insight based on current hub and data."""
        clean_hub = hub_name.split(' ', 1)[1] if ' ' in hub_name else hub_name
        
        if "Executive" in clean_hub:
            hot_leads = sum(1 for l in leads.values() if l and l.get('classification') == 'hot')
            return f"Jorge, your pipeline has {hot_leads} leads ready for immediate closing. Most are focused on the Austin downtown cluster."
        
        elif "Lead Intelligence" in clean_hub:
            selected = st.session_state.get('selected_lead_name', '-- Select a Lead --')
            if selected != "-- Select a Lead --":
                return f"I've analyzed {selected}'s recent SMS sentiment. They are showing 85% positive engagement but haven't booked a tour yet."
            return "Select a lead to see my behavioral breakdown and conversion probability."
            
        elif "Automation" in clean_hub:
            return "All 12 GHL workflows are operational. I've detected a 15% increase in response rates since we switched to 'Natural' tone."
            
        elif "Sales" in clean_hub:
            return "Ready to generate contracts. I've updated the buyer agreement template with the latest TX compliance rules."
            
        elif "Admin" in clean_hub or "Tenant" in clean_hub:
            return "Jorge, I'm monitoring sub-account health. All 5 connected GHL locations are currently syncing perfectly."

        return "I'm monitoring all data streams to ensure you have the ultimate competitive advantage."

    def render_chat_interface(self, leads: Dict[str, Any], market: str):
        """Renders the interactive 'Ask Claude' expander."""
        with st.expander("Commands & Queries", expanded=False):
            query = st.text_input("How can I help Jorge?", placeholder="Ex: Draft text for Sarah", key="claude_sidebar_chat")
            if query:
                self._handle_query(query, leads, market)

    def _handle_query(self, query: str, leads: Dict[str, Any], market: str):
        """Processes user query and displays response."""
        with st.spinner("Claude is thinking..."):
            q_lower = query.lower()
            if "draft" in q_lower or "text" in q_lower or "sms" in q_lower:
                response = "I've drafted an SMS for Sarah: 'Hi Sarah! Jorge and I found a perfect 4BR match in Austin today. Want to see photos?' [Trigger SMS?]"
            elif "risk" in q_lower:
                response = "Risk assessment: 2 leads are reaching the 48h silence threshold. I recommend an automated re-engagement trigger."
            elif "market" in q_lower:
                response = f"The {market} market is showing high demand for 3-bed homes under $600k. Velocity is up 12%."
            else:
                response = "I'm cross-referencing your GHL data. This query looks like a request for pipeline optimization. Should I run a full diagnostic?"

            st.markdown(f"""
            <div style='background: #f3f4f6; padding: 10px; border-radius: 8px; border-left: 3px solid #6D28D9; margin-top: 10px;'>
                <p style='font-size: 0.85rem; color: #1f2937; margin: 0;'>{response}</p>
            </div>
            """, unsafe_allow_html=True)
            
            if "Trigger" in response:
                if st.button("ðŸš€ Execute Command"):
                    st.toast("Command sent to GHL Workflow Engine!")

    def greet_user(self, name: str = "Jorge"):
        """Shows the one-time greeting toast."""
        if not st.session_state.claude_greeted:
            st.toast(f"Hello {name}! ðŸ‘‹ I'm Claude, your AI partner. I've indexed your GHL context and I'm ready to work.", icon="ðŸ¤–")
            st.session_state.claude_greeted = True

    def generate_automated_report(self, data: Dict[str, Any], report_type: str = "Weekly Performance") -> Dict[str, Any]:
        """
        ðŸ†• WOW FEATURE: Claude-Driven Automated Reports
        Analyzes raw metrics and returns a structured, narrative report.
        """
        st.toast(f"Claude is synthesizing your {report_type} report...", icon="âœï¸")
        
        # Simulated analysis logic
        if "conversations" in data:
            convs = data["conversations"]
            hot_leads = sum(1 for c in convs if c.get("classification") == "hot")
            avg_score = sum(c.get("lead_score", 0) for c in convs) / len(convs) if convs else 0
            
            return {
                "title": f"Claude's {report_type} Intelligence",
                "summary": f"Jorge, your pipeline is currently processing {len(convs)} active conversations. I've identified {hot_leads} leads with immediate conversion potential.",
                "key_findings": [
                    f"Average lead quality is scoring at {avg_score:.1f}/100, which is stable.",
                    "SMS engagement peaks between 6 PM and 8 PM local time.",
                    "The 'Luxury' segment has 2x higher retention than 'Starter' leads this period."
                ],
                "strategic_recommendation": "Shift 15% of the automation budget toward weekend re-engagement triggers to capture high-velocity buyer intent.",
                "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        
        return {"error": "Insufficient data for full report synthesis."}

    def generate_retention_script(self, lead_data: Dict[str, Any], risk_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ðŸ†• WOW FEATURE: Personalized AI Retention Scripts
        Generates a high-conversion outreach script based on specific churn risk factors.
        """
        lead_name = lead_data.get('lead_name', 'Client')
        risk_score = risk_data.get('risk_score', 0) if risk_data else lead_data.get('risk_score_14d', 0)
        
        # Determine the "Why" for the reasoning
        last_interaction = lead_data.get('last_interaction_days', 5)
        
        reasoning = f"Lead {lead_name} has a {risk_score:.1f}% churn risk primarily due to {last_interaction} days of inactivity. "
        reasoning += "Their previous interest in luxury properties suggests they need a high-value 'pattern interrupt'."

        if risk_score > 80:
            script = f"Hi {lead_name}, it's Jorge. I was just reviewing the new off-market luxury listings in Austin and one specifically caught my eye that fits your criteria perfectly. I didn't want you to miss out - do you have 2 minutes for a quick update today?"
            strategy = "Urgent Pattern Interrupt - High Value Offer"
        else:
            script = f"Hey {lead_name}, just checking in! I noticed some interesting price shifts in the neighborhoods we were looking at. Hope your week is going well - would you like a quick summary of the changes?"
            strategy = "Nurture Re-engagement - Market Insight"

        return {
            "lead_name": lead_name,
            "risk_score": risk_score,
            "script": script,
            "strategy": strategy,
            "reasoning": reasoning,
            "channel_recommendation": "SMS (High Response Probability)" if risk_score > 60 else "Email"
        }
