"""
Enhanced Webhook Processor

High-reliability webhook processing with deduplication, circuit breakers, and retry logic.
Ensures 99.5%+ success rate for GHL webhook processing with comprehensive error handling.

Features:
- Redis-based webhook deduplication
- Circuit breaker pattern for GHL API resilience
- Exponential backoff retry logic with jitter
- Rate limiting per GHL location
- Dead letter queue for failed webhooks
- Performance monitoring and alerting

Performance Targets:
- Webhook processing: <200ms (95th percentile)
- Deduplication check: <10ms
- Circuit breaker evaluation: <5ms
- Success rate: >99.5%
"""

import asyncio
import json
import time
import hashlib
import hmac
import random
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
from enum import Enum
from collections import defaultdict, deque

from ghl_real_estate_ai.ghl_utils.logger import get_logger

logger = get_logger(__name__)


class CircuitState(Enum):
    """Circuit breaker states."""
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"


@dataclass
class WebhookEvent:
    """Webhook event data structure."""
    webhook_id: str
    contact_id: str
    location_id: str
    event_type: str
    payload: Dict[str, Any]
    received_at: datetime
    signature: str

    # Processing metadata
    processing_attempts: int = 0
    last_error: Optional[str] = None


@dataclass
class ProcessingResult:
    """Webhook processing result."""
    webhook_id: str
    success: bool
    processing_time_ms: float
    retry_count: int
    error_message: Optional[str]
    circuit_breaker_state: str

    # Additional metadata
    rate_limited: bool = False
    deduplicated: bool = False


@dataclass
class CircuitBreakerState:
    """Circuit breaker state tracking."""
    endpoint: str
    state: CircuitState
    failure_count: int
    success_count: int
    last_failure_time: Optional[datetime]
    next_attempt_time: Optional[datetime]

    # Configuration
    failure_threshold: int = 5
    success_threshold: int = 3
    timeout_seconds: int = 60


@dataclass
class RetryConfig:
    """Retry configuration."""
    max_retries: int = 5
    base_delay_seconds: float = 1.0
    max_delay_seconds: float = 32.0
    exponential_base: float = 2.0
    jitter: bool = True

    def calculate_delay(self, retry_count: int) -> float:
        """Calculate delay for retry attempt."""
        delay = min(
            self.base_delay_seconds * (self.exponential_base ** retry_count),
            self.max_delay_seconds
        )

        if self.jitter:
            # Add Â±25% jitter to prevent thundering herd
            jitter_range = delay * 0.25
            delay += random.uniform(-jitter_range, jitter_range)

        return max(0, delay)


class EnhancedWebhookProcessor:
    """
    Enhanced Webhook Processor

    Provides high-reliability webhook processing with deduplication,
    circuit breakers, and comprehensive error handling.
    """

    def __init__(
        self,
        storage_dir: str = "data/webhook_processing",
        redis_client=None,
        ghl_client=None,
        webhook_secret: str = None
    ):
        """
        Initialize enhanced webhook processor.

        Args:
            storage_dir: Directory for persistent storage
            redis_client: Redis client for caching and deduplication
            ghl_client: GHL client for API operations
            webhook_secret: Secret for webhook signature validation
        """
        self.storage_dir = Path(storage_dir)
        self.storage_dir.mkdir(parents=True, exist_ok=True)

        self.redis_client = redis_client
        self.ghl_client = ghl_client
        self.webhook_secret = webhook_secret or "default-secret-change-in-production"

        # Circuit breaker states per endpoint
        self._circuit_breakers: Dict[str, CircuitBreakerState] = {}

        # Retry queue for failed webhooks
        self._retry_queue: List[Dict[str, Any]] = []

        # Rate limiting tracking
        self._rate_limits: Dict[str, deque] = defaultdict(deque)
        self._rate_limit_window = 60  # seconds
        self._rate_limit_max = 100  # requests per window

        # Retry configuration
        self.retry_config = RetryConfig()

        # Performance tracking
        self._performance_metrics = {
            'total_processed': 0,
            'successful_processed': 0,
            'deduplicated': 0,
            'rate_limited': 0,
            'circuit_breaker_opened': 0,
            'avg_processing_time_ms': 0.0
        }

        logger.info(f"Enhanced Webhook Processor initialized at {self.storage_dir}")

    async def process_webhook(
        self,
        webhook_id: str,
        payload: Dict[str, Any],
        signature: str
    ) -> ProcessingResult:
        """
        Process incoming webhook with full reliability features.

        Args:
            webhook_id: Unique webhook identifier
            payload: Webhook payload data
            signature: Webhook signature for validation

        Returns:
            ProcessingResult with success status and metadata
        """
        start_time = time.time()

        try:
            # Extract webhook metadata
            contact_id = payload.get("contactId", "unknown")
            location_id = payload.get("locationId", "unknown")
            event_type = payload.get("type", "unknown")

            # Create webhook event
            event = WebhookEvent(
                webhook_id=webhook_id,
                contact_id=contact_id,
                location_id=location_id,
                event_type=event_type,
                payload=payload,
                received_at=datetime.now(),
                signature=signature
            )

            # Step 1: Validate signature
            if not await self._validate_signature(payload, signature):
                return self._create_result(
                    webhook_id, False, time.time() - start_time,
                    error_message="Invalid webhook signature"
                )

            # Step 2: Check for duplicates
            if await self._is_duplicate(webhook_id):
                self._performance_metrics['deduplicated'] += 1
                return self._create_result(
                    webhook_id, True, time.time() - start_time,
                    deduplicated=True
                )

            # Step 3: Check rate limiting
            if not await self._check_rate_limit(location_id):
                self._performance_metrics['rate_limited'] += 1
                return self._create_result(
                    webhook_id, False, time.time() - start_time,
                    error_message="Rate limit exceeded",
                    rate_limited=True
                )

            # Step 4: Check circuit breaker
            cb_state = await self._get_circuit_breaker_state("process_webhook")
            if cb_state.state == CircuitState.OPEN:
                if datetime.now() < cb_state.next_attempt_time:
                    return self._create_result(
                        webhook_id, False, time.time() - start_time,
                        error_message="Circuit breaker is open",
                        circuit_breaker_state="open"
                    )
                else:
                    # Transition to half-open
                    cb_state.state = CircuitState.HALF_OPEN
                    await self._update_circuit_breaker_state(cb_state)

            # Step 5: Process webhook
            success = await self._execute_webhook_processing(event)

            # Step 6: Update circuit breaker based on result
            await self._record_circuit_breaker_result("process_webhook", success)

            # Step 7: Mark as processed to prevent duplicates
            await self._mark_as_processed(webhook_id)

            # Step 8: Track performance
            processing_time_ms = (time.time() - start_time) * 1000
            self._update_performance_metrics(processing_time_ms, success)

            if success:
                self._performance_metrics['successful_processed'] += 1

            return self._create_result(
                webhook_id, success, processing_time_ms,
                circuit_breaker_state=cb_state.state.value
            )

        except Exception as e:
            logger.error(f"Unexpected error processing webhook {webhook_id}: {e}")
            processing_time_ms = (time.time() - start_time) * 1000

            # Record circuit breaker failure
            await self._record_circuit_breaker_result("process_webhook", False)

            return self._create_result(
                webhook_id, False, processing_time_ms,
                error_message=str(e)
            )

    async def _is_duplicate(self, webhook_id: str) -> bool:
        """Check if webhook has already been processed."""
        try:
            if self.redis_client:
                # Check Redis for processed webhook
                result = await self.redis_client.get(f"webhook:processed:{webhook_id}")
                return result is not None
            else:
                # Fallback to in-memory tracking
                # In production, this would check a persistent store
                return False

        except Exception as e:
            logger.error(f"Error checking duplicate for {webhook_id}: {e}")
            return False  # Assume not duplicate on error

    async def _validate_signature(self, payload: Dict[str, Any], signature: str) -> bool:
        """Validate webhook signature for security."""
        try:
            # Generate expected signature
            payload_string = json.dumps(payload, sort_keys=True)
            expected_signature = hmac.new(
                self.webhook_secret.encode(),
                payload_string.encode(),
                hashlib.sha256
            ).hexdigest()

            # Compare signatures
            return hmac.compare_digest(signature, expected_signature)

        except Exception as e:
            logger.error(f"Error validating signature: {e}")
            return False  # Reject on validation error

    async def _check_rate_limit(self, location_id: str) -> bool:
        """Check if location is within rate limits."""
        try:
            current_time = time.time()
            location_requests = self._rate_limits[location_id]

            # Remove old requests outside the window
            while location_requests and current_time - location_requests[0] > self._rate_limit_window:
                location_requests.popleft()

            # Check if under limit
            if len(location_requests) >= self._rate_limit_max:
                return False

            # Add current request
            location_requests.append(current_time)
            return True

        except Exception as e:
            logger.error(f"Error checking rate limit for {location_id}: {e}")
            return True  # Allow on error to avoid blocking

    async def _get_circuit_breaker_state(self, endpoint: str) -> CircuitBreakerState:
        """Get circuit breaker state for endpoint."""
        if endpoint not in self._circuit_breakers:
            self._circuit_breakers[endpoint] = CircuitBreakerState(
                endpoint=endpoint,
                state=CircuitState.CLOSED,
                failure_count=0,
                success_count=0,
                last_failure_time=None,
                next_attempt_time=None
            )

        return self._circuit_breakers[endpoint]

    async def _update_circuit_breaker_state(self, state: CircuitBreakerState) -> None:
        """Update circuit breaker state."""
        self._circuit_breakers[state.endpoint] = state

        # Persist to Redis if available
        if self.redis_client:
            try:
                await self.redis_client.setex(
                    f"circuit_breaker:{state.endpoint}",
                    300,  # 5 minute TTL
                    json.dumps(asdict(state), default=str)
                )
            except Exception as e:
                logger.error(f"Failed to persist circuit breaker state: {e}")

    async def _record_circuit_breaker_result(self, endpoint: str, success: bool) -> None:
        """Record result and update circuit breaker state."""
        cb_state = await self._get_circuit_breaker_state(endpoint)

        if success:
            cb_state.success_count += 1
            cb_state.failure_count = 0  # Reset failure count on success

            # Close circuit if in half-open state with enough successes
            if (cb_state.state == CircuitState.HALF_OPEN and
                cb_state.success_count >= cb_state.success_threshold):
                cb_state.state = CircuitState.CLOSED
                cb_state.success_count = 0
                logger.info(f"Circuit breaker for {endpoint} closed after successful recovery")

        else:
            cb_state.failure_count += 1
            cb_state.success_count = 0  # Reset success count on failure
            cb_state.last_failure_time = datetime.now()

            # Open circuit if failure threshold exceeded
            if cb_state.failure_count >= cb_state.failure_threshold:
                cb_state.state = CircuitState.OPEN
                cb_state.next_attempt_time = datetime.now() + timedelta(seconds=cb_state.timeout_seconds)
                self._performance_metrics['circuit_breaker_opened'] += 1
                logger.warning(f"Circuit breaker for {endpoint} opened after {cb_state.failure_count} failures")

        await self._update_circuit_breaker_state(cb_state)

    async def _execute_webhook_processing(self, event: WebhookEvent) -> bool:
        """Execute the actual webhook processing logic."""
        try:
            if self.ghl_client:
                # Use GHL client to send response
                result = await self.ghl_client.send_response(
                    contact_id=event.contact_id,
                    message_data=event.payload
                )
                return result.get("success", False)
            else:
                # Mock successful processing for testing
                logger.info(f"Processing webhook {event.webhook_id} for contact {event.contact_id}")
                return True

        except Exception as e:
            logger.error(f"Error executing webhook processing: {e}")
            return False

    async def _mark_as_processed(self, webhook_id: str) -> None:
        """Mark webhook as processed to prevent duplicates."""
        try:
            if self.redis_client:
                # Store in Redis with 24 hour TTL
                await self.redis_client.setex(
                    f"webhook:processed:{webhook_id}",
                    86400,  # 24 hours
                    json.dumps({
                        "processed_at": datetime.now().isoformat(),
                        "success": True
                    })
                )
        except Exception as e:
            logger.error(f"Error marking webhook as processed: {e}")

    async def _schedule_retry(
        self,
        webhook_id: str,
        payload: Dict[str, Any],
        retry_count: int
    ) -> None:
        """Schedule webhook for retry with exponential backoff."""
        if retry_count >= self.retry_config.max_retries:
            await self._send_to_dead_letter_queue(
                webhook_id, payload, f"Max retries ({self.retry_config.max_retries}) exceeded"
            )
            return

        delay = self.retry_config.calculate_delay(retry_count)
        retry_time = datetime.now() + timedelta(seconds=delay)

        retry_item = {
            "webhook_id": webhook_id,
            "payload": payload,
            "retry_count": retry_count + 1,
            "scheduled_time": retry_time.isoformat(),
            "created_at": datetime.now().isoformat()
        }

        self._retry_queue.append(retry_item)

        logger.info(f"Scheduled retry {retry_count + 1}/{self.retry_config.max_retries} "
                   f"for webhook {webhook_id} in {delay:.1f} seconds")

    async def _send_to_dead_letter_queue(
        self,
        webhook_id: str,
        payload: Dict[str, Any],
        error: str
    ) -> None:
        """Send failed webhook to dead letter queue."""
        try:
            dlq_entry = {
                "webhook_id": webhook_id,
                "payload": payload,
                "error": error,
                "failed_at": datetime.now().isoformat(),
                "retry_count": self.retry_config.max_retries
            }

            # Store in dead letter queue file
            dlq_file = self.storage_dir / "dead_letter_queue.jsonl"
            with open(dlq_file, "a") as f:
                f.write(json.dumps(dlq_entry, default=str) + "\n")

            logger.error(f"Webhook {webhook_id} sent to dead letter queue: {error}")

        except Exception as e:
            logger.error(f"Failed to write to dead letter queue: {e}")

    async def _get_dead_letter_queue_entries(self) -> List[Dict[str, Any]]:
        """Get entries from dead letter queue."""
        try:
            dlq_file = self.storage_dir / "dead_letter_queue.jsonl"
            if not dlq_file.exists():
                return []

            entries = []
            with open(dlq_file, "r") as f:
                for line in f:
                    if line.strip():
                        entries.append(json.loads(line))

            return entries

        except Exception as e:
            logger.error(f"Failed to read dead letter queue: {e}")
            return []

    def _create_result(
        self,
        webhook_id: str,
        success: bool,
        processing_time_ms: float,
        retry_count: int = 0,
        error_message: Optional[str] = None,
        circuit_breaker_state: str = "closed",
        rate_limited: bool = False,
        deduplicated: bool = False
    ) -> ProcessingResult:
        """Create processing result object."""
        return ProcessingResult(
            webhook_id=webhook_id,
            success=success,
            processing_time_ms=processing_time_ms,
            retry_count=retry_count,
            error_message=error_message,
            circuit_breaker_state=circuit_breaker_state,
            rate_limited=rate_limited,
            deduplicated=deduplicated
        )

    def _update_performance_metrics(self, processing_time_ms: float, success: bool) -> None:
        """Update performance tracking metrics."""
        self._performance_metrics['total_processed'] += 1

        # Update average processing time
        total = self._performance_metrics['total_processed']
        current_avg = self._performance_metrics['avg_processing_time_ms']
        self._performance_metrics['avg_processing_time_ms'] = (
            (current_avg * (total - 1) + processing_time_ms) / total
        )

    async def get_performance_metrics(self) -> Dict[str, Any]:
        """Get current performance metrics."""
        total = max(self._performance_metrics['total_processed'], 1)

        return {
            **self._performance_metrics,
            'success_rate': self._performance_metrics['successful_processed'] / total,
            'deduplication_rate': self._performance_metrics['deduplicated'] / total,
            'rate_limit_rate': self._performance_metrics['rate_limited'] / total,
            'circuit_breaker_opens': self._performance_metrics['circuit_breaker_opened']
        }

    async def get_circuit_breaker_status(self) -> Dict[str, Dict[str, Any]]:
        """Get status of all circuit breakers."""
        return {
            endpoint: asdict(state)
            for endpoint, state in self._circuit_breakers.items()
        }

    async def reset_circuit_breaker(self, endpoint: str) -> bool:
        """Manually reset a circuit breaker."""
        try:
            if endpoint in self._circuit_breakers:
                self._circuit_breakers[endpoint].state = CircuitState.CLOSED
                self._circuit_breakers[endpoint].failure_count = 0
                self._circuit_breakers[endpoint].success_count = 0
                await self._update_circuit_breaker_state(self._circuit_breakers[endpoint])
                logger.info(f"Circuit breaker for {endpoint} manually reset")
                return True
            return False

        except Exception as e:
            logger.error(f"Failed to reset circuit breaker for {endpoint}: {e}")
            return False


# Singleton instance
_enhanced_webhook_processor = None


def get_enhanced_webhook_processor(**kwargs) -> EnhancedWebhookProcessor:
    """Get singleton enhanced webhook processor instance."""
    global _enhanced_webhook_processor
    if _enhanced_webhook_processor is None:
        _enhanced_webhook_processor = EnhancedWebhookProcessor(**kwargs)
    return _enhanced_webhook_processor


# Export main classes
__all__ = [
    "EnhancedWebhookProcessor",
    "WebhookEvent",
    "ProcessingResult",
    "CircuitBreakerState",
    "RetryConfig",
    "CircuitState",
    "get_enhanced_webhook_processor"
]