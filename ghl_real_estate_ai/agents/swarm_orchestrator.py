#!/usr/bin/env python3
"""
ðŸŽ¯ GHL Finalization Agent Swarm Orchestrator
============================================

Coordinates a specialized swarm of agents to finalize the GHL Real Estate AI project.

Agent Roles:
1. **Alpha - Code Auditor**: Reviews code quality, identifies issues
2. **Beta - Test Completer**: Implements missing test logic (TODOs)
3. **Gamma - Integration Validator**: Validates all service integrations
4. **Delta - Documentation Finalizer**: Ensures all docs are complete
5. **Epsilon - Deployment Preparer**: Prepares project for production

Author: Agent Swarm System
Date: 2026-01-05
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Set
from dataclasses import dataclass, field
from enum import Enum
import subprocess


class AgentRole(Enum):
    """Agent role definitions"""
    ALPHA = "code_auditor"
    BETA = "test_completer"
    GAMMA = "integration_validator"
    DELTA = "documentation_finalizer"
    EPSILON = "deployment_preparer"


class TaskStatus(Enum):
    """Task status tracking"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    BLOCKED = "blocked"


@dataclass
class Task:
    """Individual task definition"""
    id: str
    title: str
    description: str
    assigned_to: AgentRole
    status: TaskStatus = TaskStatus.PENDING
    dependencies: List[str] = field(default_factory=list)
    priority: int = 1  # 1=highest, 5=lowest
    estimated_time: int = 10  # minutes
    result: Optional[Dict] = None
    error: Optional[str] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None


@dataclass
class Agent:
    """Agent definition"""
    role: AgentRole
    name: str
    description: str
    capabilities: List[str]
    tasks: List[Task] = field(default_factory=list)
    status: str = "idle"  # idle, working, completed, error
    

from ghl_real_estate_ai.agents.blackboard import SharedBlackboard
from ghl_real_estate_ai.agent_system.skills.base import registry as skill_registry
from ghl_real_estate_ai.core.llm_client import LLMClient
from ghl_real_estate_ai.agents.traceability import trace_agent_action

class SwarmOrchestrator:
    """
    Orchestrates the agent swarm for GHL project finalization
    """
    
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.agents: Dict[AgentRole, Agent] = {}
        self.tasks: Dict[str, Task] = {}
        self.task_graph: Dict[str, List[str]] = {}
        self.completed_tasks: Set[str] = set()
        self.blackboard = SharedBlackboard()
        self.llm = LLMClient()
        
        self._initialize_agents()
        self._initialize_tasks()

    @trace_agent_action(action_name="task_reflection")
    async def reflect_on_result(self, task: Task, context: str, result_content: str) -> bool:
        """
        Self-correction mechanism: The agent reviews its own work.
        Returns True if satisfied, False if rework is needed.
        """
        reflection_prompt = f"""
        You are a Quality Assurance Auditor. Review the following task execution.
        
        Task: {task.title}
        Objective: {task.description}
        
        Execution Result:
        {result_content}
        
        Context:
        {context}
        
        Did the agent successfully achieve the objective? 
        If yes, reply with 'APPROVED'.
        If no, reply with 'REJECTED: <reason>'.
        """
        
        response = await self.llm.agenerate(
            prompt=reflection_prompt,
            model="gemini-2.0-pro-exp-02-05", # Always use high-reasoning model for reflection
            temperature=0.1
        )
        
        if "APPROVED" in response.content:
            print(f"âœ… Reflection PASSED for task {task.id}")
            return True
        else:
            print(f"âš ï¸ Reflection FAILED for task {task.id}: {response.content}")
            return False

    @trace_agent_action(action_name="task_execution")
    async def execute_task(self, task_id: str, complexity: str = "medium", risk: str = "low"):
        """
        Execute a task using a Recursive Tool Loop (ReAct).
        Supports multi-turn tool use and HITL approval for high-risk tasks.
        """
        task = self.tasks[task_id]
        agent = self.agents[task.assigned_to]
        
        # HITL Gatekeeping
        if risk == "high":
            confirm = input(f"âš ï¸ [HITL] Task {task_id} is HIGH RISK. Approve execution? (y/n): ")
            if confirm.lower() != 'y':
                task.status = TaskStatus.BLOCKED
                self.blackboard.write(f"task_blocked_{task_id}", "User denied high-risk execution", agent.name)
                return

        print(f"ðŸš€ Executing task {task_id}: {task.title} (Agent: {agent.name})")
        task.status = TaskStatus.IN_PROGRESS
        task.started_at = datetime.now()
        
        # Dynamic Model Selection
        model_name = "gemini-2.0-pro-exp-02-05" if complexity == "high" else self.llm.model
        
        context = self.blackboard.get_full_context()
        skills = skill_registry.find_relevant_skills(task.description)
        skill_tools = [s.to_gemini_tool()["function_declarations"][0] for s in skills]
        
        # Maintain conversation history
        messages = [
            {"role": "user", "content": f"Objective: {task.description}\n\nCurrent Blackboard Context:\n{context}\n\nPlease achieve the objective. Use available tools if needed."}
        ]

        # RECURSIVE TOOL LOOP (Max 10 turns)
        final_response = ""
        for turn in range(10):
            response = await self.llm.agenerate(
                prompt=messages[-1]["content"],
                history=messages[:-1],
                system_prompt=f"You are {agent.name}, an expert {agent.description}. Use tools provided to achieve the objective.",
                tools=skill_tools if skill_tools else None,
                model=model_name
            )
            
            # Record response in messages for context maintenance
            if response.content:
                messages.append({"role": "assistant", "content": response.content})
                final_response = response.content
            
            # Handle Tool Calls
            if response.tool_calls:
                tool_results = []
                for tool_call in response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["args"]
                    
                    print(f"ðŸ› ï¸ Agent {agent.name} calling tool: {tool_name}({tool_args})")
                    self.blackboard.write(f"tool_call_{task_id}_t{turn}", {"tool": tool_name, "args": tool_args}, agent.name)
                    
                    skill = skill_registry.get_skill(tool_name)
                    if skill:
                        try:
                            result = skill.execute(**tool_args)
                            print(f"âœ… Tool {tool_name} returned: {str(result)[:100]}...")
                            tool_results.append({"tool": tool_name, "result": result})
                        except Exception as e:
                            print(f"âŒ Tool {tool_name} failed: {e}")
                            tool_results.append({"tool": tool_name, "error": str(e)})
                    else:
                        tool_results.append({"tool": tool_name, "error": "Skill not found"})

                # Add tool results back to context
                messages.append({
                    "role": "user", 
                    "content": f"Tool Results: {json.dumps(tool_results)}"
                })
                
                # Continue loop to allow agent to process results
                continue
            
            # If no tool calls and we have content, we are done
            if response.content:
                break
        
        # Automated Reflection (Phase 4 Enhancement)
        # Verify the result before marking complete
        if complexity == "high" or risk == "high" or True: # Enable for all for now to test
             approved = await self.reflect_on_result(task, context, final_response)
             if not approved:
                 # In a full implementation, this would trigger a retry loop or human escalation
                 # For now, we log the failure but mark as completed (with warning) to avoid infinite loops
                 self.blackboard.write(f"task_reflection_failed_{task_id}", "Auto-reflection rejected the result", agent.name)
                 task.error = "Auto-reflection rejected the result"

        # Post-execution Reflection & Blackboard Update
        task.status = TaskStatus.COMPLETED
        task.completed_at = datetime.now()
        task.result = {"content": final_response, "messages_count": len(messages)}
        self.completed_tasks.add(task_id)
        
        self.blackboard.write(f"task_result_{task_id}", task.result, agent.name)
        
        return task.result

        
    def _initialize_agents(self):
        """Initialize all agents with their capabilities"""
        
        # Alpha - Code Auditor
        self.agents[AgentRole.ALPHA] = Agent(
            role=AgentRole.ALPHA,
            name="Alpha Code Auditor",
            description="Reviews code quality, identifies issues, ensures best practices",
            capabilities=[
                "Code quality analysis",
                "Security vulnerability scanning",
                "Performance optimization identification",
                "Code smell detection",
                "Dependency analysis"
            ]
        )
        
        # Beta - Test Completer
        self.agents[AgentRole.BETA] = Agent(
            role=AgentRole.BETA,
            name="Beta Test Completer",
            description="Implements missing test logic and ensures test coverage",
            capabilities=[
                "TODO resolution in tests",
                "Test logic implementation",
                "Test coverage analysis",
                "Mock creation",
                "Assertion writing"
            ]
        )
        
        # Gamma - Integration Validator
        self.agents[AgentRole.GAMMA] = Agent(
            role=AgentRole.GAMMA,
            name="Gamma Integration Validator",
            description="Validates all service integrations and API connections",
            capabilities=[
                "Service integration testing",
                "API endpoint validation",
                "Database connection verification",
                "External service connectivity",
                "Error handling validation"
            ]
        )
        
        # Delta - Documentation Finalizer
        self.agents[AgentRole.DELTA] = Agent(
            role=AgentRole.DELTA,
            name="Delta Documentation Finalizer",
            description="Ensures all documentation is complete and accurate",
            capabilities=[
                "README updates",
                "API documentation",
                "Inline documentation",
                "Architecture diagrams",
                "User guides"
            ]
        )
        
        # Epsilon - Deployment Preparer
        self.agents[AgentRole.EPSILON] = Agent(
            role=AgentRole.EPSILON,
            name="Epsilon Deployment Preparer",
            description="Prepares project for production deployment",
            capabilities=[
                "Environment configuration",
                "Dependency management",
                "Build process validation",
                "Deployment scripts",
                "Production readiness checklist"
            ]
        )
        
    def _initialize_tasks(self):
        """Initialize all finalization tasks with dependencies"""
        
        tasks = [
            # Phase 1: Analysis & Planning
            Task(
                id="task_001",
                title="Project Structure Analysis",
                description="Analyze complete project structure and identify all components",
                assigned_to=AgentRole.ALPHA,
                priority=1,
                estimated_time=5
            ),
            Task(
                id="task_002",
                title="Test TODO Identification",
                description="Identify all TODO comments in test files",
                assigned_to=AgentRole.BETA,
                priority=1,
                estimated_time=5
            ),
            
            # Phase 2: Code Quality
            Task(
                id="task_003",
                title="Code Quality Audit",
                description="Run comprehensive code quality checks",
                assigned_to=AgentRole.ALPHA,
                dependencies=["task_001"],
                priority=1,
                estimated_time=15
            ),
            Task(
                id="task_004",
                title="Security Vulnerability Scan",
                description="Scan for security vulnerabilities",
                assigned_to=AgentRole.ALPHA,
                dependencies=["task_001"],
                priority=1,
                estimated_time=10
            ),
            
            # Phase 3: Test Completion
            Task(
                id="task_005",
                title="Implement Test Logic - Reengagement",
                description="Complete TODO items in test_reengagement_engine_extended.py",
                assigned_to=AgentRole.BETA,
                dependencies=["task_002"],
                priority=2,
                estimated_time=20
            ),
            Task(
                id="task_006",
                title="Implement Test Logic - Memory Service",
                description="Complete TODO items in test_memory_service_extended.py",
                assigned_to=AgentRole.BETA,
                dependencies=["task_002"],
                priority=2,
                estimated_time=20
            ),
            Task(
                id="task_007",
                title="Implement Test Logic - GHL Client",
                description="Complete TODO items in test_ghl_client_extended.py",
                assigned_to=AgentRole.BETA,
                dependencies=["task_002"],
                priority=2,
                estimated_time=20
            ),
            Task(
                id="task_008",
                title="Implement Security Tests",
                description="Complete security-related TODO items",
                assigned_to=AgentRole.BETA,
                dependencies=["task_002"],
                priority=1,
                estimated_time=30
            ),
            
            # Phase 4: Integration Validation
            Task(
                id="task_009",
                title="Validate GHL API Integration",
                description="Test all GHL API endpoints and connections",
                assigned_to=AgentRole.GAMMA,
                dependencies=["task_005", "task_006", "task_007"],
                priority=2,
                estimated_time=25
            ),
            Task(
                id="task_010",
                title="Validate Database Connections",
                description="Test all database operations and connections",
                assigned_to=AgentRole.GAMMA,
                dependencies=["task_003"],
                priority=2,
                estimated_time=15
            ),
            Task(
                id="task_011",
                title="Validate Service Dependencies",
                description="Verify all service-to-service integrations",
                assigned_to=AgentRole.GAMMA,
                dependencies=["task_003"],
                priority=2,
                estimated_time=20
            ),
            
            # Phase 5: Documentation
            Task(
                id="task_012",
                title="Update Main README",
                description="Ensure README is complete with all features",
                assigned_to=AgentRole.DELTA,
                dependencies=["task_009", "task_010"],
                priority=3,
                estimated_time=15
            ),
            Task(
                id="task_013",
                title="Generate API Documentation",
                description="Create/update API documentation",
                assigned_to=AgentRole.DELTA,
                dependencies=["task_009"],
                priority=3,
                estimated_time=20
            ),
            Task(
                id="task_014",
                title="Update Service Documentation",
                description="Document all 62+ services",
                assigned_to=AgentRole.DELTA,
                dependencies=["task_011"],
                priority=3,
                estimated_time=30
            ),
            
            # Phase 6: Deployment Preparation
            Task(
                id="task_015",
                title="Environment Configuration",
                description="Setup and validate environment variables",
                assigned_to=AgentRole.EPSILON,
                dependencies=["task_003", "task_004"],
                priority=1,
                estimated_time=15
            ),
            Task(
                id="task_016",
                title="Dependency Management",
                description="Validate and freeze all dependencies",
                assigned_to=AgentRole.EPSILON,
                dependencies=["task_003"],
                priority=1,
                estimated_time=10
            ),
            Task(
                id="task_017",
                title="Production Readiness Checklist",
                description="Complete production deployment checklist",
                assigned_to=AgentRole.EPSILON,
                dependencies=["task_012", "task_015", "task_016"],
                priority=1,
                estimated_time=20
            ),
            Task(
                id="task_018",
                title="Deployment Scripts",
                description="Create/validate deployment scripts",
                assigned_to=AgentRole.EPSILON,
                dependencies=["task_015", "task_016"],
                priority=2,
                estimated_time=25
            ),
            
            # Phase 7: Final Validation
            Task(
                id="task_019",
                title="Run Full Test Suite",
                description="Execute all tests and verify passing",
                assigned_to=AgentRole.GAMMA,
                dependencies=["task_005", "task_006", "task_007", "task_008"],
                priority=1,
                estimated_time=30
            ),
            Task(
                id="task_020",
                title="Final Integration Test",
                description="Run end-to-end integration tests",
                assigned_to=AgentRole.GAMMA,
                dependencies=["task_019"],
                priority=1,
                estimated_time=25
            ),
        ]
        
        # Store tasks
        for task in tasks:
            self.tasks[task.id] = task
            self.agents[task.assigned_to].tasks.append(task)
            
        # Build task graph
        self._build_task_graph()
        
    def _build_task_graph(self):
        """Build task dependency graph"""
        for task_id, task in self.tasks.items():
            self.task_graph[task_id] = task.dependencies
            
    def get_ready_tasks(self) -> List[Task]:
        """Get all tasks ready to execute (no pending dependencies)"""
        ready = []
        for task_id, task in self.tasks.items():
            if task.status == TaskStatus.PENDING:
                # Check if all dependencies are completed
                deps_completed = all(
                    dep_id in self.completed_tasks 
                    for dep_id in task.dependencies
                )
                if deps_completed:
                    ready.append(task)
        
        # Sort by priority (lower number = higher priority)
        ready.sort(key=lambda t: (t.priority, t.id))
        return ready
    
    def get_status_report(self) -> Dict:
        """Generate comprehensive status report"""
        total_tasks = len(self.tasks)
        completed = len([t for t in self.tasks.values() if t.status == TaskStatus.COMPLETED])
        in_progress = len([t for t in self.tasks.values() if t.status == TaskStatus.IN_PROGRESS])
        failed = len([t for t in self.tasks.values() if t.status == TaskStatus.FAILED])
        blocked = len([t for t in self.tasks.values() if t.status == TaskStatus.BLOCKED])
        
        agent_stats = {}
        for role, agent in self.agents.items():
            agent_tasks = agent.tasks
            agent_stats[role.value] = {
                "total": len(agent_tasks),
                "completed": len([t for t in agent_tasks if t.status == TaskStatus.COMPLETED]),
                "in_progress": len([t for t in agent_tasks if t.status == TaskStatus.IN_PROGRESS]) ,
                "pending": len([t for t in agent_tasks if t.status == TaskStatus.PENDING])
            }
        
        return {
            "timestamp": datetime.now().isoformat(),
            "overall": {
                "total_tasks": total_tasks,
                "completed": completed,
                "in_progress": in_progress,
                "failed": failed,
                "blocked": blocked,
                "progress_percentage": (completed / total_tasks * 100) if total_tasks > 0 else 0
            },
            "agents": agent_stats,
            "ready_tasks": len(self.get_ready_tasks())
        }
    
    def print_status(self):
        """Print formatted status report"""
        status = self.get_status_report()
        
        print("\n" + "="*80)
        print("ðŸŽ¯ GHL PROJECT FINALIZATION - AGENT SWARM STATUS")
        print("="*80)
        print(f"\nðŸ“Š Overall Progress: {status['overall']['progress_percentage']:.1f}%")
        print(f"   âœ… Completed: {status['overall']['completed']}/{status['overall']['total_tasks']}")
        print(f"   ðŸ”„ In Progress: {status['overall']['in_progress']}")
        print(f"   â³ Pending: {status['overall']['total_tasks'] - status['overall']['completed'] - status['overall']['in_progress']}")
        print(f"   âŒ Failed: {status['overall']['failed']}")
        print(f"   ðŸš« Blocked: {status['overall']['blocked']}")
        
        print("\nðŸ‘¥ Agent Status:")
        for agent_role, agent in self.agents.items():
            stats = status['agents'][agent_role.value]
            print(f"\n   {agent.name}:")
            print(f"      Status: {agent.status}")
            print(f"      Tasks: {stats['completed']}/{stats['total']} completed")
            if stats['in_progress'] > 0:
                print(f"      Currently working on {stats['in_progress']} task(s)")
        
        ready_tasks = self.get_ready_tasks()
        if ready_tasks:
            print(f"\nðŸš€ Next {len(ready_tasks)} task(s) ready to execute:")
            for task in ready_tasks[:5]:  # Show first 5
                print(f"   â€¢ [{task.id}] {task.title} -> {task.assigned_to.value}")
        
        print("\n" + "="*80 + "\n")
    
    def generate_execution_plan(self) -> List[Dict]:
        """Generate execution plan showing task order"""
        # ... (keep existing implementation)
        return [] # Placeholder as we are adding a new method below

    async def run_parallel_swarm(self):
        """
        Executes the swarm tasks in parallel where dependencies allow.
        """
        print("\nðŸš€ Starting Parallel Swarm Execution...")
        
        while len(self.completed_tasks) < len(self.tasks):
            ready_tasks = self.get_ready_tasks()
            if not ready_tasks:
                if any(t.status == TaskStatus.FAILED for t in self.tasks.values()):
                    print("âŒ Swarm halted due to task failures.")
                    break
                print("ðŸ No more tasks ready. Swarm complete.")
                break
            
            print(f"ðŸ“¡ Dispatching {len(ready_tasks)} parallel tasks...")
            # Execute all currently ready tasks in parallel
            await asyncio.gather(*(self.execute_task(t.id) for t in ready_tasks))
            
        print("\nâœ¨ Parallel Swarm Execution Finished.")
        self.print_status()


def main():
    """Main execution"""
    project_root = Path(__file__).parent.parent
    orchestrator = SwarmOrchestrator(project_root)
    
    print("\nðŸš€ GHL Project Finalization - Agent Swarm Initialized")
    print("="*80)
    
    # Print initial status
    orchestrator.print_status()
    
    # Generate execution plan
    plan = orchestrator.generate_execution_plan()
    
    print("ðŸ“‹ EXECUTION PLAN")
    print("="*80)
    total_time = sum(task['estimated_time'] for task in plan)
    print(f"\nTotal estimated time: {total_time} minutes ({total_time/60:.1f} hours)")
    print(f"Total tasks: {len(plan)}\n")
    
    # Group by phase
    phases = {
        1: "Analysis & Planning",
        2: "Code Quality",
        3: "Test Completion",
        4: "Integration Validation",
        5: "Documentation",
        6: "Deployment Preparation",
        7: "Final Validation"
    }
    
    current_phase = 1
    for i, task in enumerate(plan, 1):
        # Detect phase changes (rough heuristic)
        if i > 2 and current_phase == 1:
            current_phase = 2
        elif i > 4 and current_phase == 2:
            current_phase = 3
        elif i > 8 and current_phase == 3:
            current_phase = 4
        elif i > 11 and current_phase == 4:
            current_phase = 5
        elif i > 14 and current_phase == 5:
            current_phase = 6
        elif i > 18 and current_phase == 6:
            current_phase = 7
        
        if i == 1 or (i > 2 and plan[i-2].get('phase') != current_phase):
            phase_name = phases.get(current_phase, "Unknown")
            print(f"--- PHASE {current_phase}: {phase_name} ---")
        
        print(f"{i:2}. [{task['id']}] {task['title']} ({task['assigned_to']})")

if __name__ == "__main__":
    main()