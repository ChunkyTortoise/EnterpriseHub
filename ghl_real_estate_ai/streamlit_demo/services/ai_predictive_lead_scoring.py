#!/usr/bin/env python3
"""
ðŸŽ¯ AI-Powered Predictive Lead Scoring Service
=============================================

Machine learning-based lead scoring system that predicts lead quality
and conversion probability.

Features:
- Real-time lead scoring (0-100)
- Confidence intervals
- Explainable AI (feature importance)
- Automatic tier assignment (hot/warm/cold)
- Action recommendations

Author: Eta ML Implementer Agent
Date: 2026-01-05
"""

import json
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
import math


@dataclass
class LeadFeatures:
    """Lead feature vector for scoring"""
    engagement_score: float  # 0-1: email/SMS engagement rate
    response_time: float  # hours: avg response time
    page_views: int  # number of property page views
    budget_match: float  # 0-1: budget alignment score
    timeline_urgency: str  # immediate/soon/exploring
    property_matches: int  # number of matching properties
    communication_quality: float  # 0-1: quality of responses
    source_quality: str  # organic/referral/paid/other


@dataclass
class LeadScore:
    """Lead scoring result"""
    lead_id: str
    score: float  # 0-100
    confidence: float  # 0-1
    tier: str  # hot/warm/cold
    factors: List[Dict]
    recommendations: List[str]
    scored_at: datetime


class PredictiveLeadScorer:
    """
    ML-based lead scoring engine
    
    Uses a combination of:
    - Engagement metrics
    - Behavioral signals
    - Demographic fit
    - Historical patterns
    """
    
    def __init__(self):
        self.feature_weights = self._initialize_weights()
        self.timeline_mapping = {
            "immediate": 1.0,
            "soon": 0.7,
            "exploring": 0.3
        }
        self.source_mapping = {
            "organic": 0.9,
            "referral": 1.0,
            "paid": 0.6,
            "other": 0.5
        }
    
    def _initialize_weights(self) -> Dict[str, float]:
        """Initialize feature weights (learned from historical data)"""
        return {
            "engagement_score": 0.20,
            "response_time": 0.15,
            "page_views": 0.10,
            "budget_match": 0.20,
            "timeline_urgency": 0.15,
            "property_matches": 0.08,
            "communication_quality": 0.10,
            "source_quality": 0.02
        }
    
    def extract_features(self, lead_data: Dict) -> LeadFeatures:
        """
        Extract features from lead data
        
        Args:
            lead_data: Raw lead information
            
        Returns:
            LeadFeatures object
        """
        # Calculate engagement score
        engagement_score = self._calculate_engagement(lead_data)
        
        # Calculate response time
        response_time = self._calculate_response_time(lead_data)
        
        # Extract other features
        page_views = lead_data.get("page_views", 0)
        budget_match = self._calculate_budget_match(lead_data)
        timeline_urgency = lead_data.get("timeline", "exploring")
        property_matches = lead_data.get("property_matches", 0)
        communication_quality = self._assess_communication_quality(lead_data)
        source_quality = lead_data.get("source", "other")
        
        return LeadFeatures(
            engagement_score=engagement_score,
            response_time=response_time,
            page_views=page_views,
            budget_match=budget_match,
            timeline_urgency=timeline_urgency,
            property_matches=property_matches,
            communication_quality=communication_quality,
            source_quality=source_quality
        )
    
    def score_lead(self, lead_id: str, lead_data: Dict, include_explanation: bool = True) -> LeadScore:
        """
        Score a lead using ML model
        
        Args:
            lead_id: Lead identifier
            lead_data: Lead information
            include_explanation: Whether to include factor explanations
            
        Returns:
            LeadScore with predictions and explanations
        """
        # Extract features
        features = self.extract_features(lead_data)
        
        # Calculate raw score
        raw_score, feature_contributions = self._calculate_score(features)
        
        # Normalize to 0-100
        normalized_score = self._normalize_score(raw_score)
        
        # Calculate confidence
        confidence = self._calculate_confidence(features, feature_contributions)
        
        # Assign tier
        tier = self._assign_tier(normalized_score, confidence)
        
        # Generate explanations
        factors = []
        if include_explanation:
            factors = self._explain_score(features, feature_contributions)
        
        # Generate recommendations
        recommendations = self._generate_recommendations(normalized_score, tier, features)
        
        return LeadScore(
            lead_id=lead_id,
            score=round(normalized_score, 2),
            confidence=round(confidence, 3),
            tier=tier,
            factors=factors,
            recommendations=recommendations,
            scored_at=datetime.now()
        )
    
    def _calculate_score(self, features: LeadFeatures) -> Tuple[float, Dict]:
        """Calculate weighted score and track contributions"""
        contributions = {}
        total_score = 0.0
        
        # Engagement score (0-1)
        engagement_contrib = features.engagement_score * self.feature_weights["engagement_score"]
        contributions["engagement_score"] = engagement_contrib
        total_score += engagement_contrib
        
        # Response time (inverse - faster is better)
        response_contrib = self._score_response_time(features.response_time) * self.feature_weights["response_time"]
        contributions["response_time"] = response_contrib
        total_score += response_contrib
        
        # Page views (normalized)
        page_views_contrib = min(features.page_views / 20.0, 1.0) * self.feature_weights["page_views"]
        contributions["page_views"] = page_views_contrib
        total_score += page_views_contrib
        
        # Budget match (0-1)
        budget_contrib = features.budget_match * self.feature_weights["budget_match"]
        contributions["budget_match"] = budget_contrib
        total_score += budget_contrib
        
        # Timeline urgency
        timeline_score = self.timeline_mapping.get(features.timeline_urgency, 0.5)
        timeline_contrib = timeline_score * self.feature_weights["timeline_urgency"]
        contributions["timeline_urgency"] = timeline_contrib
        total_score += timeline_contrib
        
        # Property matches
        matches_contrib = min(features.property_matches / 10.0, 1.0) * self.feature_weights["property_matches"]
        contributions["property_matches"] = matches_contrib
        total_score += matches_contrib
        
        # Communication quality
        comm_contrib = features.communication_quality * self.feature_weights["communication_quality"]
        contributions["communication_quality"] = comm_contrib
        total_score += comm_contrib
        
        # Source quality
        source_score = self.source_mapping.get(features.source_quality, 0.5)
        source_contrib = source_score * self.feature_weights["source_quality"]
        contributions["source_quality"] = source_contrib
        total_score += source_contrib
        
        return total_score, contributions
    
    def _normalize_score(self, raw_score: float) -> float:
        """Normalize score to 0-100 range"""
        # Apply sigmoid for smooth distribution
        normalized = 1 / (1 + math.exp(-10 * (raw_score - 0.5)))
        return normalized * 100
    
    def _calculate_confidence(self, features: LeadFeatures, contributions: Dict) -> float:
        """Calculate confidence in the prediction"""
        # Higher confidence when we have more data points
        data_completeness = sum([
            1 if features.engagement_score > 0 else 0,
            1 if features.response_time > 0 else 0,
            1 if features.page_views > 0 else 0,
            1 if features.budget_match > 0 else 0,
            1 if features.property_matches > 0 else 0,
            1 if features.communication_quality > 0 else 0,
        ]) / 6.0
        
        # Higher confidence when contributions are balanced (not dominated by one feature)
        contrib_values = list(contributions.values())
        balance = 1.0 - (max(contrib_values) - min(contrib_values))
        
        confidence = (data_completeness * 0.7) + (balance * 0.3)
        return max(0.3, min(confidence, 0.95))  # Clamp between 0.3 and 0.95
    
    def _assign_tier(self, score: float, confidence: float) -> str:
        """Assign tier based on score and confidence"""
        # Adjust thresholds based on confidence
        if confidence < 0.5:
            # Lower confidence = more conservative tiers
            hot_threshold = 80
            warm_threshold = 60
        else:
            hot_threshold = 70
            warm_threshold = 50
        
        if score >= hot_threshold:
            return "hot"
        elif score >= warm_threshold:
            return "warm"
        else:
            return "cold"
    
    def _explain_score(self, features: LeadFeatures, contributions: Dict) -> List[Dict]:
        """Generate explanations for the score"""
        factors = []
        
        # Sort by contribution
        sorted_contribs = sorted(contributions.items(), key=lambda x: x[1], reverse=True)
        
        for feature_name, contribution in sorted_contribs[:5]:  # Top 5 factors
            impact = "positive" if contribution > 0.05 else "neutral"
            
            # Get human-readable description
            description = self._get_feature_description(feature_name, features)
            
            factors.append({
                "name": feature_name.replace("_", " ").title(),
                "impact": round(contribution * 100, 1),
                "value": description,
                "sentiment": impact
            })
        
        return factors
    
    def _get_feature_description(self, feature_name: str, features: LeadFeatures) -> str:
        """Get human-readable feature description"""
        descriptions = {
            "engagement_score": f"{features.engagement_score*100:.0f}% engagement rate",
            "response_time": f"{features.response_time:.1f} hour avg response",
            "page_views": f"{features.page_views} property views",
            "budget_match": f"{features.budget_match*100:.0f}% budget match",
            "timeline_urgency": f"{features.timeline_urgency} timeline",
            "property_matches": f"{features.property_matches} matching properties",
            "communication_quality": f"{features.communication_quality*100:.0f}% communication quality",
            "source_quality": f"{features.source_quality} source"
        }
        return descriptions.get(feature_name, "N/A")
    
    def _generate_recommendations(self, score: float, tier: str, features: LeadFeatures) -> List[str]:
        """Generate action recommendations"""
        recommendations = []
        
        if tier == "hot":
            recommendations.append("ðŸ”¥ Priority follow-up within 1 hour")
            recommendations.append("Schedule property viewing ASAP")
            if features.budget_match > 0.8:
                recommendations.append("Lead is well-qualified - present financing options")
        
        elif tier == "warm":
            recommendations.append("Follow up within 24 hours")
            if features.engagement_score < 0.5:
                recommendations.append("Increase engagement with personalized content")
            if features.property_matches < 3:
                recommendations.append("Send more property recommendations")
        
        else:  # cold
            recommendations.append("Add to nurture campaign")
            recommendations.append("Re-engage with educational content")
            if features.response_time > 48:
                recommendations.append("Try different communication channel")
        
        # Specific recommendations based on features
        if features.timeline_urgency == "immediate":
            recommendations.append("Lead has urgent timeline - prioritize showing availability")
        
        if features.communication_quality < 0.5:
            recommendations.append("Improve response quality - ask more qualifying questions")
        
        return recommendations[:5]  # Return top 5

    def predict_next_action(self, lead_data: Dict) -> str:
        """
        Predict the next best action for a lead based on their data.
        This provides the intelligence required by the Lead Intelligence Hub.
        """
        score_result = self.score_lead(lead_data.get("id", "unknown"), lead_data)
        tier = score_result.tier
        
        # Extract features for more granular guidance
        features = self.extract_features(lead_data)
        
        if tier == "hot":
            if features.budget_match > 0.8:
                return "Send Pre-Approval Request & Schedule Showing"
            return "Call Immediately: High Intent Detected"
        
        elif tier == "warm":
            if features.property_matches > 5:
                return "Share Curated Property Portfolio"
            return "Send Market Comparison Report"
            
        else: # Cold
            if features.engagement_score > 0.3:
                return "Enroll in Re-engagement Drip"
            return "Add to Long-term Nurture Loop"
    
    def _calculate_engagement(self, lead_data: Dict) -> float:
        """Calculate engagement score from interactions"""
        opens = lead_data.get("email_opens", 0)
        clicks = lead_data.get("email_clicks", 0)
        sent = lead_data.get("emails_sent", 1)
        
        open_rate = opens / max(sent, 1)
        click_rate = clicks / max(sent, 1)
        
        return (open_rate * 0.6) + (click_rate * 0.4)
    
    def _calculate_response_time(self, lead_data: Dict) -> float:
        """Calculate average response time in hours"""
        responses = lead_data.get("response_times", [])
        if not responses:
            return 48.0  # Default to 48 hours if no data
        
        return sum(responses) / len(responses)
    
    def _calculate_budget_match(self, lead_data: Dict) -> float:
        """Calculate budget alignment score"""
        lead_budget = lead_data.get("budget", 0)
        viewed_prices = lead_data.get("viewed_property_prices", [])
        
        if not viewed_prices or lead_budget == 0:
            return 0.5  # Default to neutral
        
        avg_viewed = sum(viewed_prices) / len(viewed_prices)
        
        # Perfect match = 1.0, large mismatch = 0.0
        ratio = min(lead_budget, avg_viewed) / max(lead_budget, avg_viewed)
        return ratio
    
    def _assess_communication_quality(self, lead_data: Dict) -> float:
        """Assess quality of lead's communications"""
        messages = lead_data.get("messages", [])
        
        if not messages:
            return 0.5  # Default
        
        quality_score = 0.0
        
        for msg in messages:
            # Longer messages = better engagement
            length_score = min(len(msg.get("content", "")) / 200.0, 1.0) * 0.3
            
            # Questions indicate interest
            question_count = msg.get("content", "").count("?")
            question_score = min(question_count / 3.0, 1.0) * 0.4
            
            # Specific details indicate seriousness
            has_details = any(keyword in msg.get("content", "").lower() 
                            for keyword in ["budget", "timeline", "location", "bedrooms"])
            detail_score = 0.3 if has_details else 0.0
            
            quality_score += (length_score + question_score + detail_score) / len(messages)
        
        return min(quality_score, 1.0)
    
    def _score_response_time(self, response_time: float) -> float:
        """Convert response time to score (faster = better)"""
        # < 1 hour = 1.0, > 48 hours = 0.0
        if response_time < 1:
            return 1.0
        elif response_time > 48:
            return 0.0
        else:
            # Linear decay
            return 1.0 - (response_time / 48.0)
    
    def batch_score(self, leads: List[Dict]) -> List[LeadScore]:
        """Score multiple leads in batch"""
        return [self.score_lead(lead["id"], lead) for lead in leads]
    
    def to_dict(self, score: LeadScore) -> Dict:
        """Convert LeadScore to dictionary"""
        return {
            "lead_id": score.lead_id,
            "score": score.score,
            "confidence": score.confidence,
            "tier": score.tier,
            "factors": score.factors,
            "recommendations": score.recommendations,
            "scored_at": score.scored_at.isoformat()
        }


# Example usage
if __name__ == "__main__":
    scorer = PredictiveLeadScorer()
    
    # Example lead data
    lead_data = {
        "id": "lead_123",
        "email_opens": 8,
        "email_clicks": 5,
        "emails_sent": 10,
        "response_times": [2.5, 1.8, 3.2],
        "page_views": 12,
        "budget": 500000,
        "viewed_property_prices": [480000, 520000, 495000],
        "timeline": "soon",
        "property_matches": 7,
        "messages": [
            {"content": "I'm interested in properties in downtown. What's available in my budget of $500k?"},
            {"content": "Can we schedule a viewing next week?"}
        ],
        "source": "organic"
    }
    
    # Score the lead
    result = scorer.score_lead("lead_123", lead_data)
    
    print(f"\nðŸŽ¯ Lead Scoring Result")
    print(f"   Score: {result.score}/100")
    print(f"   Tier: {result.tier.upper()}")
    print(f"   Confidence: {result.confidence*100:.1f}%")
    print(f"\n   Top Factors:")
    for factor in result.factors[:3]:
        print(f"   â€¢ {factor['name']}: {factor['value']} (impact: {factor['impact']})")
    print(f"\n   Recommendations:")
    for rec in result.recommendations:
        print(f"   â€¢ {rec}")
