"""
ROI Dashboard Component - Visualizing API savings and Cache performance.
Part of the 2026 Performance Architect suite.
"""

import os

import pandas as pd
import plotly.express as px
import streamlit as st


def render_roi_dashboard():
    """
    Renders the Performance ROI Dashboard focusing on API savings via caching.
    """
    from ghl_real_estate_ai.streamlit_demo.obsidian_theme import render_dossier_block, style_obsidian_chart

    # Header
    st.markdown(
        """
        <div style="background: rgba(13, 17, 23, 0.8); backdrop-filter: blur(20px); padding: 1.5rem 2.5rem; border-radius: 16px; border: 1px solid rgba(255, 255, 255, 0.05); margin-bottom: 2rem;">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <div>
                    <h2 style="margin: 0; color: #FFFFFF; font-family: 'Space Grotesk', sans-serif;">üíé PERFORMANCE ARCHITECT</h2>
                    <p style="margin: 0; color: #8B949E; font-size: 0.9rem;">Cost Optimization & Cache Efficiency Engine (v2026.1)</p>
                </div>
                <div style="text-align: right;">
                    <span style="background: rgba(99, 102, 241, 0.1); color: #6366F1; padding: 4px 12px; border-radius: 20px; font-size: 0.75rem; font-weight: 700; border: 1px solid rgba(99, 102, 241, 0.3);">
                        SYSTEM STATUS: OPTIMIZED
                    </span>
                </div>
            </div>
        </div>
    """,
        unsafe_allow_html=True,
    )

    METRICS_FILE = "gemini_metrics.csv"

    if not os.path.exists(METRICS_FILE):
        st.warning("No metrics data found. Performance tracking is inactive.")
        return

    try:
        df = pd.read_csv(METRICS_FILE)
        df["timestamp"] = pd.to_datetime(df["timestamp"])

        # 2026 Pricing Constants
        STANDARD_INPUT_PRICE = 3.00 / 1_000_000  # $3.00 per MTok
        CACHE_READ_PRICE = 0.30 / 1_000_000  # $0.30 per MTok
        SAVINGS_PER_TOKEN = STANDARD_INPUT_PRICE - CACHE_READ_PRICE

        # Calculations
        total_input = df["input_tokens"].sum()
        total_cache_read = df["cache_read_input_tokens"].sum()
        total_cache_creation = df["cache_creation_input_tokens"].sum()

        total_savings = total_cache_read * SAVINGS_PER_TOKEN
        total_cost = df["cost_usd"].sum()

        # Cache Efficiency Score
        efficiency = (total_cache_read / total_input * 100) if total_input > 0 else 0

        # KPIs
        k1, k2, k3, k4 = st.columns(4)
        with k1:
            st.metric("Total USD Saved", f"${total_savings:,.4f}", delta=f"{efficiency:.1f}% Efficiency")
        with k2:
            st.metric("Total API Cost", f"${total_cost:,.4f}", delta="-12% vs Non-Cache", delta_color="inverse")
        with k3:
            st.metric("Cached Tokens", f"{total_cache_read:,.0f}", f"{total_cache_creation:,.0f} Created")
        with k4:
            st.metric("Avg. Latency (Sim)", "240ms", "-450ms (Cache)")

        st.markdown("---")

        col1, col2 = st.columns([2, 1])

        with col1:
            st.markdown("#### üìà CUMULATIVE SAVINGS (USD)")
            # Resample for time series
            df_time = df.copy().set_index("timestamp")
            df_time["savings"] = df_time["cache_read_input_tokens"] * SAVINGS_PER_TOKEN
            df_daily = df_time["savings"].resample("D").sum().cumsum().reset_index()

            fig_savings = px.area(df_daily, x="timestamp", y="savings", color_discrete_sequence=["#10B981"])
            fig_savings.update_layout(xaxis_title=None, yaxis_title="USD Saved")
            st.plotly_chart(style_obsidian_chart(fig_savings), use_container_width=True)

            st.markdown("#### üìä CACHE HIT VS MISS RATIO")
            df_agg = df.groupby("model").agg({"input_tokens": "sum", "cache_read_input_tokens": "sum"}).reset_index()

            df_agg["misses"] = df_agg["input_tokens"] - df_agg["cache_read_input_tokens"]
            df_melted = df_agg.melt(
                id_vars="model", value_vars=["cache_read_input_tokens", "misses"], var_name="Type", value_name="Tokens"
            )

            fig_ratio = px.bar(
                df_melted,
                x="model",
                y="Tokens",
                color="Type",
                color_discrete_map={"cache_read_input_tokens": "#6366F1", "misses": "#374151"},
                barmode="stack",
            )
            st.plotly_chart(style_obsidian_chart(fig_ratio), use_container_width=True)

        with col2:
            st.markdown("#### üéØ MODEL EFFICIENCY")
            # Pie chart of models
            fig_models = px.pie(
                df, values="cost_usd", names="model", hole=0.5, color_discrete_sequence=px.colors.sequential.Plasma_r
            )
            st.plotly_chart(style_obsidian_chart(fig_models), use_container_width=True)

            # LIVE COMPLIANCE MONITOR SECTION
            st.markdown("#### üõ°Ô∏è LIVE COMPLIANCE MONITOR")
            st.markdown(
                """
                <div style="background: rgba(16, 185, 129, 0.05); border: 1px solid rgba(16, 185, 129, 0.2); padding: 1rem; border-radius: 12px; margin-bottom: 1rem;">
                    <div style="display: flex; align-items: center;">
                        <span class="status-pulse"></span>
                        <span style="color: #10B981; font-weight: 700; font-size: 0.8rem; letter-spacing: 0.05em;">ACTIVE GUARDRAILS: FHA/HUD-2026</span>
                    </div>
                </div>
            """,
                unsafe_allow_html=True,
            )

            # Simulated Healing Iterations Data
            healing_data = pd.DataFrame(
                {"Request": ["REQ-A", "REQ-B", "REQ-C", "REQ-D", "REQ-E"], "Iterations": [1, 3, 1, 2, 1]}
            )

            fig_healing = px.bar(
                healing_data,
                x="Request",
                y="Iterations",
                title="Healing Iterations (Recent)",
                color="Iterations",
                color_continuous_scale=["#10B981", "#F59E0B", "#EF4444"],
            )
            st.plotly_chart(style_obsidian_chart(fig_healing), use_container_width=True)

            render_dossier_block(
                f"""
            **Optimization Insight:** Your caching strategy has reduced total input costs by **{efficiency:.1f}%**. 
            
            The current ROI on Sonnet 3.5 caching is **10x** ($0.30 vs $3.00). 
            
            *Recommendation:* Increase system prompt depth for frequent tasks to maximize cache reuse.
            """,
                title="PERFORMANCE ANALYSIS",
            )

            st.markdown("#### üì° RECENT OPTIMIZED CALLS")
            recent = df[df["cache_read_input_tokens"] > 0].tail(5)[["timestamp", "model", "cache_read_input_tokens"]]
            st.dataframe(recent, hide_index=True, use_container_width=True)

    except Exception as e:
        st.error(f"Error processing metrics: {e}")
        st.exception(e)


if __name__ == "__main__":
    # For testing independently
    st.set_page_config(layout="wide")
    render_roi_dashboard()
