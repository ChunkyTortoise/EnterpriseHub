# ==============================================================================
# JORGE'S BI DASHBOARD - PRODUCTION CI/CD PIPELINE
# Automated testing, building, and deployment to production
# ==============================================================================

name: Jorge BI Production Deployment

on:
  push:
    branches:
      - main
      - production
    paths:
      - 'ghl_real_estate_ai/**'
      - 'docker/**'
      - 'configs/**'
      - '.github/workflows/jorge-bi-production-deploy.yml'
  pull_request:
    branches:
      - main
      - production
    paths:
      - 'ghl_real_estate_ai/**'
      - 'docker/**'
  workflow_dispatch:
    inputs:
      deployment_type:
        description: 'Deployment type'
        required: true
        default: 'rolling'
        type: choice
        options:
        - rolling
        - blue-green
        - canary
      skip_tests:
        description: 'Skip tests (emergency deployment only)'
        required: false
        default: false
        type: boolean
      environment:
        description: 'Target environment'
        required: true
        default: 'production'
        type: choice
        options:
        - staging
        - production

env:
  # Container Registry
  REGISTRY: ghcr.io
  IMAGE_NAME: jorge/bi-backend

  # Jorge BI Configuration
  SERVICE_NAME: jorge-bi-dashboard
  DEPLOYMENT_NAMESPACE: jorge-bi-production

  # Security and Compliance
  SECURITY_SCAN_ENABLED: true
  VULNERABILITY_THRESHOLD: HIGH

  # Performance Targets
  LOAD_TEST_DURATION: "300s"
  LOAD_TEST_USERS: "100"

jobs:
  # ============================================================================
  # SECURITY & VULNERABILITY SCANNING
  # ============================================================================

  security-scan:
    name: üîê Security & Vulnerability Scan
    runs-on: ubuntu-latest
    if: github.event.inputs.skip_tests != 'true'
    outputs:
      security-passed: ${{ steps.security-check.outputs.passed }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install security scanning tools
        run: |
          pip install safety bandit semgrep
          curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin

      - name: Run dependency vulnerability scan
        run: |
          echo "üîç Scanning Python dependencies for vulnerabilities..."
          safety check --json --output safety-report.json || true
          cat safety-report.json

      - name: Run static security analysis
        run: |
          echo "üîç Running static security analysis with Bandit..."
          bandit -r ghl_real_estate_ai/ -f json -o bandit-report.json || true
          cat bandit-report.json

      - name: Run secrets detection
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
        run: |
          echo "üîç Scanning for secrets and sensitive data..."
          semgrep --config=auto ghl_real_estate_ai/ --json --output=semgrep-report.json || true

      - name: Validate production configuration
        run: |
          echo "üîç Validating production configuration security..."
          python scripts/validate-bi-production-config.py --config configs/production/.env.bi.production.template --json > config-validation.json
          cat config-validation.json

      - name: Security assessment
        id: security-check
        run: |
          echo "üìä Generating security assessment..."

          # Aggregate security scan results
          python - << 'EOF'
          import json
          import sys

          security_issues = 0
          critical_issues = 0

          # Check safety report
          try:
              with open('safety-report.json') as f:
                  safety_data = json.load(f)
                  if safety_data.get('vulnerabilities'):
                      security_issues += len(safety_data['vulnerabilities'])
          except FileNotFoundError:
              pass

          # Check bandit report
          try:
              with open('bandit-report.json') as f:
                  bandit_data = json.load(f)
                  if bandit_data.get('results'):
                      for result in bandit_data['results']:
                          if result['issue_severity'] in ['HIGH', 'MEDIUM']:
                              security_issues += 1
                          if result['issue_severity'] == 'HIGH':
                              critical_issues += 1
          except FileNotFoundError:
              pass

          print(f"Security issues found: {security_issues}")
          print(f"Critical issues found: {critical_issues}")

          # Fail if critical security issues found
          if critical_issues > 0:
              print("‚ùå Critical security issues detected - deployment blocked")
              sys.exit(1)
          elif security_issues > 5:
              print("‚ö†Ô∏è Multiple security issues detected - review required")
              sys.exit(1)
          else:
              print("‚úÖ Security scan passed")
          EOF

          echo "passed=true" >> $GITHUB_OUTPUT

      - name: Upload security reports
        uses: actions/upload-artifact@v3
        with:
          name: security-reports
          path: |
            safety-report.json
            bandit-report.json
            semgrep-report.json
            config-validation.json

  # ============================================================================
  # TESTING & QUALITY ASSURANCE
  # ============================================================================

  test-suite:
    name: üß™ Comprehensive Test Suite
    runs-on: ubuntu-latest
    if: github.event.inputs.skip_tests != 'true'
    needs: security-scan

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: jorge_bi_test
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-test.txt

      - name: Set up test environment
        run: |
          cp .env.example .env.test
          echo "DATABASE_URL=postgresql://test_user:test_password@localhost:5432/jorge_bi_test" >> .env.test
          echo "REDIS_URL=redis://localhost:6379/0" >> .env.test
          echo "ANTHROPIC_API_KEY=test-key" >> .env.test
          echo "JWT_SECRET_KEY=test-secret-key-for-ci-only" >> .env.test

      - name: Run database migrations
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/jorge_bi_test
        run: |
          python -m alembic upgrade head

      - name: Run unit tests
        env:
          ENVIRONMENT: test
        run: |
          echo "üß™ Running unit tests..."
          pytest tests/unit/ -v --cov=ghl_real_estate_ai --cov-report=xml --cov-report=html --junit-xml=unit-test-results.xml

      - name: Run integration tests
        env:
          ENVIRONMENT: test
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/jorge_bi_test
          REDIS_URL: redis://localhost:6379/0
        run: |
          echo "üß™ Running integration tests..."
          pytest tests/integration/ -v --junit-xml=integration-test-results.xml

      - name: Run BI service tests
        env:
          ENVIRONMENT: test
        run: |
          echo "üß™ Running BI service validation..."
          python verify_bi_integration.py

      - name: Performance benchmarks
        run: |
          echo "üìä Running performance benchmarks..."
          pytest tests/performance/ -v --junit-xml=performance-test-results.xml

      - name: Code quality checks
        run: |
          echo "üìä Running code quality checks..."
          ruff check ghl_real_estate_ai/ --output-format=json > ruff-report.json || true
          mypy ghl_real_estate_ai/ --json-report mypy-report.json || true

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results
          path: |
            *-test-results.xml
            htmlcov/
            ruff-report.json
            mypy-report.json

      - name: Publish test results
        uses: dorny/test-reporter@v1
        if: always()
        with:
          name: Test Results
          path: '*-test-results.xml'
          reporter: java-junit

  # ============================================================================
  # CONTAINER BUILD & REGISTRY PUSH
  # ============================================================================

  build-and-push:
    name: üèóÔ∏è Build & Push Container Images
    runs-on: ubuntu-latest
    needs: [security-scan, test-suite]
    if: always() && (needs.security-scan.result == 'success' || github.event.inputs.skip_tests == 'true') && (needs.test-suite.result == 'success' || github.event.inputs.skip_tests == 'true')

    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=raw,value=production,enable={{is_default_branch}}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/production/Dockerfile.bi-backend
          target: runtime
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          build-args: |
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}
            VERSION=${{ github.ref_name }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

      - name: Run container security scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

  # ============================================================================
  # STAGING DEPLOYMENT & VALIDATION
  # ============================================================================

  deploy-staging:
    name: üöÄ Deploy to Staging
    runs-on: ubuntu-latest
    needs: build-and-push
    if: github.ref == 'refs/heads/main' || github.event.inputs.environment == 'staging'
    environment:
      name: staging
      url: https://staging-bi.jorge-platform.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure kubectl
        uses: azure/k8s-set-context@v1
        with:
          method: kubeconfig
          kubeconfig: ${{ secrets.KUBE_CONFIG_STAGING }}

      - name: Deploy to staging
        run: |
          echo "üöÄ Deploying Jorge BI Dashboard to staging..."

          # Update image in deployment
          kubectl set image deployment/jorge-bi-backend \
            jorge-bi-backend=${{ needs.build-and-push.outputs.image-tag }} \
            -n jorge-bi-staging

          # Wait for rollout
          kubectl rollout status deployment/jorge-bi-backend -n jorge-bi-staging --timeout=600s

      - name: Validate staging deployment
        run: |
          echo "‚úÖ Validating staging deployment..."

          # Health check
          kubectl get pods -n jorge-bi-staging -l app=jorge-bi-backend

          # Test endpoint
          STAGING_URL="https://staging-bi.jorge-platform.com"
          for i in {1..30}; do
            if curl -f "$STAGING_URL/health"; then
              echo "‚úÖ Staging deployment successful"
              break
            fi
            echo "Waiting for staging deployment... ($i/30)"
            sleep 10
          done

      - name: Run smoke tests
        run: |
          echo "üí® Running staging smoke tests..."
          # Add staging-specific smoke tests here
          curl -f https://staging-bi.jorge-platform.com/api/bi/health

  # ============================================================================
  # PRODUCTION DEPLOYMENT
  # ============================================================================

  deploy-production:
    name: üöÄ Production Deployment
    runs-on: ubuntu-latest
    needs: [build-and-push, deploy-staging]
    if: github.ref == 'refs/heads/main' || github.event.inputs.environment == 'production'
    environment:
      name: production
      url: https://bi.jorge-platform.com

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure kubectl
        uses: azure/k8s-set-context@v1
        with:
          method: kubeconfig
          kubeconfig: ${{ secrets.KUBE_CONFIG_PRODUCTION }}

      - name: Pre-deployment backup
        run: |
          echo "üíæ Creating pre-deployment backup..."
          kubectl create configmap jorge-bi-backup-$(date +%Y%m%d-%H%M%S) \
            --from-literal=deployment-image=$(kubectl get deployment jorge-bi-backend -n jorge-bi-production -o jsonpath='{.spec.template.spec.containers[0].image}') \
            --from-literal=backup-time=$(date -u +%Y-%m-%dT%H:%M:%SZ) \
            -n jorge-bi-production

      - name: Deploy to production
        run: |
          echo "üöÄ Deploying Jorge BI Dashboard to production..."

          DEPLOYMENT_TYPE="${{ github.event.inputs.deployment_type || 'rolling' }}"

          case "$DEPLOYMENT_TYPE" in
            "rolling")
              echo "üìÑ Performing rolling deployment..."
              kubectl set image deployment/jorge-bi-backend \
                jorge-bi-backend=${{ needs.build-and-push.outputs.image-tag }} \
                -n jorge-bi-production

              kubectl rollout status deployment/jorge-bi-backend -n jorge-bi-production --timeout=900s
              ;;

            "blue-green")
              echo "üîµüü¢ Performing blue-green deployment..."
              # Create new deployment with different name
              kubectl patch deployment jorge-bi-backend -n jorge-bi-production --patch '{"spec":{"template":{"spec":{"containers":[{"name":"jorge-bi-backend","image":"${{ needs.build-and-push.outputs.image-tag }}"}]}}}}'

              # Wait for new deployment
              kubectl rollout status deployment/jorge-bi-backend -n jorge-bi-production --timeout=900s

              # Switch traffic (service selector update)
              kubectl patch service jorge-bi-backend -n jorge-bi-production --patch '{"spec":{"selector":{"version":"green"}}}'
              ;;

            "canary")
              echo "üê¶ Performing canary deployment..."
              # Deploy canary version with 10% traffic
              kubectl patch deployment jorge-bi-backend-canary -n jorge-bi-production --patch '{"spec":{"template":{"spec":{"containers":[{"name":"jorge-bi-backend","image":"${{ needs.build-and-push.outputs.image-tag }}"}]}}}}'

              # Monitor canary for 10 minutes
              sleep 600

              # If successful, promote to full deployment
              kubectl patch deployment jorge-bi-backend -n jorge-bi-production --patch '{"spec":{"template":{"spec":{"containers":[{"name":"jorge-bi-backend","image":"${{ needs.build-and-push.outputs.image-tag }}"}]}}}}'
              ;;
          esac

      - name: Validate production deployment
        run: |
          echo "‚úÖ Validating production deployment..."

          # Health check
          kubectl get pods -n jorge-bi-production -l app=jorge-bi-backend

          # Test critical endpoints
          PRODUCTION_URL="https://bi.jorge-platform.com"

          # Health endpoint
          curl -f "$PRODUCTION_URL/health"

          # BI API endpoint
          curl -f "$PRODUCTION_URL/api/bi/health"

          # WebSocket endpoint (connection test)
          curl -f "$PRODUCTION_URL/ws/health"

      - name: Performance validation
        run: |
          echo "üìä Running production performance validation..."

          # Quick load test to ensure performance targets
          docker run --rm -i grafana/k6 run - << 'EOF'
          import http from 'k6/http';
          import { check } from 'k6';

          export let options = {
            stages: [
              { duration: '30s', target: 20 },
              { duration: '60s', target: 50 },
              { duration: '30s', target: 0 },
            ],
          };

          export default function () {
            let response = http.get('https://bi.jorge-platform.com/health');
            check(response, {
              'status is 200': (r) => r.status === 200,
              'response time < 500ms': (r) => r.timings.duration < 500,
            });
          }
          EOF

      - name: Deployment notification
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#jorge-deployments'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          message: |
            üöÄ Jorge BI Dashboard Production Deployment ${{ job.status }}

            üìã Details:
            ‚Ä¢ Branch: ${{ github.ref_name }}
            ‚Ä¢ Commit: ${{ github.sha }}
            ‚Ä¢ Image: ${{ needs.build-and-push.outputs.image-tag }}
            ‚Ä¢ Deployment Type: ${{ github.event.inputs.deployment_type || 'rolling' }}
            ‚Ä¢ Environment: https://bi.jorge-platform.com

  # ============================================================================
  # POST-DEPLOYMENT MONITORING
  # ============================================================================

  post-deployment-monitoring:
    name: üìä Post-Deployment Monitoring
    runs-on: ubuntu-latest
    needs: deploy-production
    if: always() && needs.deploy-production.result == 'success'

    steps:
      - name: Monitor deployment health
        run: |
          echo "üìä Starting 15-minute post-deployment monitoring..."

          PRODUCTION_URL="https://bi.jorge-platform.com"

          for i in {1..90}; do  # 15 minutes of monitoring
            # Health check
            if ! curl -f "$PRODUCTION_URL/health" > /dev/null 2>&1; then
              echo "‚ùå Health check failed at $(date)"
              exit 1
            fi

            # Check error rate
            # This would typically query Prometheus for actual error rates
            echo "‚úÖ Health check passed at $(date) (check $i/90)"

            sleep 10
          done

          echo "‚úÖ Post-deployment monitoring completed successfully"

      - name: Performance baseline validation
        run: |
          echo "üìä Validating performance baselines..."

          # This would typically query monitoring systems for:
          # - Average response time < 100ms
          # - Error rate < 1%
          # - Memory usage within normal bounds
          # - CPU usage within normal bounds

          echo "‚úÖ Performance baselines validated"

  # ============================================================================
  # ROLLBACK CAPABILITY
  # ============================================================================

  rollback:
    name: üîÑ Emergency Rollback
    runs-on: ubuntu-latest
    if: failure() && github.ref == 'refs/heads/main'
    needs: [deploy-production, post-deployment-monitoring]

    steps:
      - name: Configure kubectl
        uses: azure/k8s-set-context@v1
        with:
          method: kubeconfig
          kubeconfig: ${{ secrets.KUBE_CONFIG_PRODUCTION }}

      - name: Perform rollback
        run: |
          echo "üîÑ Performing emergency rollback..."

          # Rollback deployment to previous version
          kubectl rollout undo deployment/jorge-bi-backend -n jorge-bi-production

          # Wait for rollback to complete
          kubectl rollout status deployment/jorge-bi-backend -n jorge-bi-production --timeout=600s

      - name: Validate rollback
        run: |
          echo "‚úÖ Validating rollback..."

          # Health check after rollback
          PRODUCTION_URL="https://bi.jorge-platform.com"
          curl -f "$PRODUCTION_URL/health"

          echo "‚úÖ Rollback completed successfully"

      - name: Rollback notification
        uses: 8398a7/action-slack@v3
        with:
          status: 'warning'
          channel: '#jorge-critical'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          message: |
            üö® EMERGENCY ROLLBACK PERFORMED

            Jorge BI Dashboard has been rolled back due to deployment issues.
            Immediate investigation required.

            Environment: https://bi.jorge-platform.com