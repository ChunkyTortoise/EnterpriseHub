#!/usr/bin/env python3
"""
Simplified Token Efficiency Test - No Dependencies Required
Validates Perplexity research findings on Jorge bot workflow
"""

import tiktoken
import json
from datetime import datetime

def main():
    encoder = tiktoken.encoding_for_model('gpt-4')

    print('üß™ SIMPLIFIED TOKEN EFFICIENCY TEST')
    print('=' * 60)

    # Current approach simulation - full context loading
    current_system_prompt = """You are an expert lead intelligence analyst. Your job is to synthesize multiple data sources to create comprehensive lead profiles with strategic recommendations.

Analyze:
- Qualification scores (Jorge's 0-7 system + ML predictions)
- Behavioral patterns and engagement metrics
- Conversation history and sentiment
- Market context and competitive positioning
- Churn risk factors

Provide:
- Strategic summary of lead quality
- Behavioral insights and personality assessment
- Risk factors and opportunities
- Specific action recommendations with timing
- Expected outcomes and success metrics"""

    current_context = {
        'lead_name': 'Alice Johnson',
        'conversation_history': [
            {'role': 'user', 'content': "Hi, I'm thinking about selling my house in Phoenix"},
            {'role': 'assistant', 'content': "What's your timeline looking like?"},
            {'role': 'user', 'content': "Well, I'm not sure... maybe next year sometime"}
        ],
        'seller_temperature': 'lukewarm',
        'psychological_commitment': 45,
        'stall_detected': True,
        'detected_stall_type': 'thinking',
        'qualification_scores': {'frs': 65, 'pcs': 45},
        'property_address': '123 Main St, Phoenix AZ',
        'market_context': 'Phoenix hot market, 15% YoY appreciation',
        'competitive_analysis': 'Multiple agents in area, high competition',
        'behavioral_patterns': 'Hesitant, multiple touchpoints needed',
        'churn_risk_factors': ['timeline_uncertainty', 'price_sensitivity'],
        'semantic_memory': 'Previous interactions show price concerns, timing flexibility'
    }

    jorge_persona = """You are Jorge Salas, a high-performance real estate investor.
Your tone is: DIRECT, NO-BS, CONFRONTATIONAL when necessary.
You hate wasting time on 'Lookers'. You want 'Motivated Sellers'.

CURRENT CONTEXT:
Lead: Alice Johnson
Tone Mode: CONFRONTATIONAL (Be direct and challenge their stall)
Stall Detected: thinking
FRS Classification: Warm Lead

TASK: Generate a response to the lead's last message.
INCORPORATE THIS STALL-BREAKER: What specifically are you thinking about? The timeline, the price, or whether you actually want to sell?"""

    # Build full current prompt
    current_full_prompt = f"""{current_system_prompt}

{jorge_persona}

Context:
{json.dumps(current_context, indent=2)}

Current Time: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}"""

    current_tokens = len(encoder.encode(current_full_prompt))
    current_response_tokens = 300  # Typical response length

    print('üî• CURRENT APPROACH:')
    print(f'   System prompt: {len(encoder.encode(current_system_prompt))} tokens')
    print(f'   Jorge persona: {len(encoder.encode(jorge_persona))} tokens')
    print(f'   Context JSON: {len(encoder.encode(json.dumps(current_context, indent=2)))} tokens')
    print(f'   Total input: {current_tokens:,} tokens')
    print(f'   Response: {current_response_tokens} tokens')
    print(f'   TOTAL: {current_tokens + current_response_tokens:,} tokens')
    print()

    # Progressive skills approach
    discovery_prompt = """SKILL DISCOVERY MODE - Minimal Context Loading

Task: Jorge seller qualification workflow
Lead: Alice Johnson
Last Message: "Well, I'm not sure... maybe next year sometime"

Available Skills:
- jorge_confrontational_qualification (1200 tokens) - Handle stalls, qualification
- jorge_response_generation (800 tokens) - Generate personalized responses
- seller_intent_analysis (1000 tokens) - Analyze FRS/PCS scores

Determine: Which skills are needed for this interaction?
Response format: ["skill_name1", "skill_name2"]"""

    discovery_tokens = len(encoder.encode(discovery_prompt))
    discovery_response = 50  # Just skill names

    progressive_skill = """# Jorge Confrontational Qualification Skill

Lead: Alice Johnson
Last message: "Well, I'm not sure... maybe next year sometime"
Stall detected: "thinking" pattern

Jorge's Stall-Breaker for "thinking":
"What specifically are you thinking about? The timeline, the price, or whether you actually want to sell? Because if it's exploration, you're wasting both our time."

Instructions:
1. Use confrontational tone - Jorge doesn't chase lukewarm leads
2. Force specific commitment or disqualify immediately
3. Keep response under 160 characters (SMS compliance)

Generate Jorge's response now."""

    skill_tokens = len(encoder.encode(progressive_skill))
    skill_response = 180

    progressive_total = discovery_tokens + discovery_response + skill_tokens + skill_response

    print('üöÄ PROGRESSIVE SKILLS:')
    print(f'   Discovery: {discovery_tokens} + {discovery_response} = {discovery_tokens + discovery_response} tokens')
    print(f'   Skill execution: {skill_tokens} + {skill_response} = {skill_tokens + skill_response} tokens')
    print(f'   TOTAL: {progressive_total:,} tokens')
    print()

    print('üìä COMPARISON:')
    current_total = current_tokens + current_response_tokens
    reduction = ((current_total - progressive_total) / current_total) * 100
    cost_current = current_total * 0.003 / 1000
    cost_progressive = progressive_total * 0.003 / 1000
    cost_reduction = ((cost_current - cost_progressive) / cost_current) * 100

    print(f'   Current total: {current_total:,} tokens')
    print(f'   Progressive total: {progressive_total:,} tokens')
    print(f'   Token reduction: {reduction:.1f}%')
    print(f'   Cost reduction: {cost_reduction:.1f}%')
    print(f'   Research predicted: 98% reduction')
    print()

    print('üí∞ COST ANALYSIS:')
    print(f'   Current cost/interaction: ${cost_current:.4f}')
    print(f'   Progressive cost/interaction: ${cost_progressive:.4f}')
    print(f'   Monthly savings (1000 interactions): ${(cost_current - cost_progressive) * 1000 * 30:.2f}')
    print(f'   Annual savings: ${(cost_current - cost_progressive) * 1000 * 365:.2f}')
    print()

    # Research validation
    research_predicted = 98.0
    accuracy = 100 - abs(reduction - research_predicted) / research_predicted * 100

    print('üéØ RESEARCH VALIDATION:')
    print(f'   Research predicted: {research_predicted}% reduction')
    print(f'   Our measurement: {reduction:.1f}% reduction')
    print(f'   Validation accuracy: {accuracy:.1f}%')
    print()

    if reduction > 70:
        print(f'‚úÖ SUCCESS: {reduction:.1f}% token reduction achieved!')
        print('‚úÖ Research validation: Progressive skills work as predicted')
        print('‚úÖ RECOMMENDATION: Implement for Jorge bot immediately')
    else:
        print(f'‚ö†Ô∏è  Only {reduction:.1f}% reduction - investigate why lower than expected')

    print('=' * 60)

    # Enterprise projection
    print('üè¢ ENTERPRISE IMPACT:')
    daily_interactions = 1000
    monthly_savings = (cost_current - cost_progressive) * daily_interactions * 30
    annual_savings = (cost_current - cost_progressive) * daily_interactions * 365

    print(f'   For {daily_interactions:,} daily Jorge interactions:')
    print(f'   Monthly token cost savings: ${monthly_savings:.2f}')
    print(f'   Annual token cost savings: ${annual_savings:.2f}')
    print(f'   Plus 8.7x speed improvement from research')
    print('=' * 60)

    return {
        'token_reduction': reduction,
        'cost_reduction': cost_reduction,
        'research_accuracy': accuracy,
        'monthly_savings': monthly_savings,
        'annual_savings': annual_savings
    }

if __name__ == "__main__":
    results = main()