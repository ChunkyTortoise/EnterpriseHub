# ðŸš¨ Incident Response Playbook
**EnterpriseHub + GHL Real Estate AI System**

**Document Version**: 1.0
**Created**: January 5, 2026
**Status**: READY FOR USE
**Agent**: Agent 6 - Monitoring & DevOps Support

---

## ðŸ“‹ Executive Summary

This playbook provides step-by-step response procedures for common production incidents in Jorge's EnterpriseHub system. Each scenario includes detection methods, diagnosis steps, resolution procedures, and escalation paths.

### Incident Severity Levels

| Level | Description | Response Time | Examples |
|-------|-------------|---------------|----------|
| **ðŸ”´ CRITICAL** | Service completely unavailable | <5 minutes | Backend down, frontend crash, database failure |
| **ðŸŸ  HIGH** | Degraded functionality affecting users | <30 minutes | Slow API responses, intermittent errors |
| **ðŸŸ¡ MEDIUM** | Partial feature impact, workarounds available | <2 hours | Single module failure, non-critical warnings |
| **ðŸŸ¢ LOW** | Minor issues, no immediate user impact | <24 hours | Log noise, cosmetic bugs, performance optimization |

### Response Team Contacts

```
Primary On-Call: [Your Name/Contact]
Client Contact: Jorge (realtorjorgesalas@gmail.com)
Backup Support: [Backup contact if available]

Escalation Path:
1. Primary On-Call (you)
2. Render Support (infrastructure issues)
3. Anthropic Support (AI/API issues)
4. GHL Support (integration issues)
```

---

## ðŸ”´ CRITICAL: Backend Service Completely Down

### Detection

**Alert Source**: UptimeRobot email or Render notification

**Symptoms**:
- UptimeRobot shows "DOWN" status for "GHL Backend - Health Check"
- HTTP status: Connection timeout, 503, or no response
- Render dashboard shows service as "Suspended" or "Error"

### Diagnosis Steps

1. **Check Render Dashboard**:
   ```
   URL: https://dashboard.render.com/
   Navigate to: ghl-real-estate-ai service
   Look for: Red status indicator, error messages
   ```

2. **Review Recent Logs**:
   ```
   Render Dashboard â†’ ghl-real-estate-ai â†’ Logs tab
   Filter: Last 30 minutes
   Search for: "ERROR", "CRITICAL", "Exception", "crashed"
   ```

3. **Check Render Events**:
   ```
   Render Dashboard â†’ ghl-real-estate-ai â†’ Events tab
   Look for: Recent deployment, manual restart, platform maintenance
   ```

4. **Verify Render Platform Status**:
   ```
   URL: https://status.render.com/
   Check for: Ongoing incidents affecting oregon region
   ```

### Resolution Procedures

#### Scenario A: Service Crashed (Exit Code Error)

**Root Cause**: Application error, out-of-memory, uncaught exception

**Steps**:
1. Review last 100 log lines in Render dashboard
2. Identify error message (e.g., "ModuleNotFoundError", "MemoryError", "ConnectionError")
3. Click **"Manual Deploy"** â†’ **"Deploy Latest Commit"** (restarts service)
4. Monitor logs for successful startup message: "Starting GHL Real Estate AI v3.0"
5. Verify health endpoint: `curl [BACKEND_URL]/health`

**If Restart Fails**:
- Check environment variables are still set (Settings â†’ Environment)
- Required: `GHL_LOCATION_ID`, `GHL_API_KEY`, `ANTHROPIC_API_KEY`
- If missing, re-add from handoff document and redeploy

**Time to Resolution**: 5-10 minutes

#### Scenario B: Deployment Failed

**Root Cause**: Build error, dependency issue, configuration problem

**Steps**:
1. Navigate to Render Dashboard â†’ ghl-real-estate-ai â†’ Events
2. Click most recent "Deploy" event â†’ View build logs
3. Identify build failure point (e.g., "requirements.txt", syntax error, import failure)
4. Check for recent code changes in Git (if any)
5. Options:
   - **If config issue**: Fix environment variables, redeploy
   - **If dependency issue**: Check `requirements.txt` syntax, redeploy
   - **If code issue**: Rollback to last known good commit

**Rollback Procedure**:
```bash
# In local git repo
cd /Users/cave/enterprisehub
git log --oneline -5  # Find last good commit hash

# In Render Dashboard
Navigate to: ghl-real-estate-ai â†’ Settings â†’ Build & Deploy
Trigger Deploy From Branch: main (or specific commit hash)
```

**Time to Resolution**: 10-20 minutes

#### Scenario C: Render Platform Issue

**Root Cause**: Render.com infrastructure problem, regional outage

**Steps**:
1. Confirm issue at https://status.render.com/
2. If incident is active:
   - No action needed (Render will auto-recover)
   - Monitor status page for updates
   - Prepare client communication (see Client Notification below)
3. If no Render incident but service still down:
   - Contact Render Support: https://render.com/docs/support
   - Provide: Service name, approximate downtime start, error details

**Time to Resolution**: 15-60 minutes (depends on Render)

#### Scenario D: Out of Memory (OOM) Crash

**Root Cause**: Free tier 512MB RAM limit exceeded

**Symptoms in Logs**:
```
signal: killed (OOM)
MemoryError
Process killed (out of memory)
```

**Steps**:
1. **Immediate**: Restart service (Manual Deploy)
2. **Short-term**: Monitor memory usage in Render Metrics tab
3. **Long-term**: If recurring (>2x per day):
   - Upgrade to Starter plan ($7/month, 512MB â†’ 2GB RAM)
   - Or optimize code to reduce memory footprint

**Time to Resolution**: 5 minutes (restart), 1-2 hours (plan upgrade)

### Client Notification Template

**Email Subject**: ðŸ”´ URGENT: EnterpriseHub Backend Experiencing Downtime

**Email Body**:
```
Hi Jorge,

I'm writing to inform you of a temporary service disruption with your EnterpriseHub backend.

INCIDENT DETAILS:
- Status: Backend service is currently down
- Impact: Dashboard analytics and AI features unavailable
- Started: [Time detected]
- Root Cause: [Brief explanation - e.g., "Service crashed due to memory limit"]

CURRENT ACTIONS:
- Actively investigating and resolving
- [Specific steps being taken]

EXPECTED RESOLUTION:
- ETA: [15 minutes / 1 hour / investigating]

UPDATES:
I'll provide an update in [30 minutes] or when service is restored, whichever comes first.

Your data and configurations are safe. This is a temporary infrastructure issue.

Best,
Cayman
```

### Post-Incident Actions

1. **Document Incident**:
   ```markdown
   ## Incident Report: [Date/Time]
   - **Severity**: CRITICAL
   - **Downtime**: [Duration]
   - **Root Cause**: [Explanation]
   - **Resolution**: [What fixed it]
   - **Prevention**: [How to avoid in future]
   ```

2. **Update Monitoring**:
   - Adjust alert thresholds if needed
   - Add additional monitors if gap identified

3. **Review with Client**:
   - Send incident summary to Jorge
   - Explain preventive measures taken

---

## ðŸ”´ CRITICAL: Frontend Service Completely Down

### Detection

**Alert Source**: UptimeRobot email for "EnterpriseHub - Frontend"

**Symptoms**:
- Frontend URL returns 503, timeout, or blank page
- Render dashboard shows service error
- Users cannot access dashboard

### Diagnosis Steps

1. **Check Render Dashboard**:
   ```
   Navigate to: enterprise-hub-platform service
   Look for: Status indicator, error messages in logs
   ```

2. **Verify Backend is Up**:
   ```bash
   curl [BACKEND_URL]/health
   # If backend is also down, follow backend incident procedure first
   ```

3. **Review Streamlit Logs**:
   ```
   Render Dashboard â†’ enterprise-hub-platform â†’ Logs
   Search for: "ModuleNotFoundError", "ImportError", "ConnectionError"
   ```

4. **Check for CORS/Backend Connection Issues**:
   ```
   Logs search: "CORS", "Connection refused", "timeout"
   ```

### Resolution Procedures

#### Scenario A: Streamlit App Crashed

**Root Cause**: Import error, configuration error, missing dependency

**Steps**:
1. Review logs for error message
2. Common issues:
   - Missing `GHL_BACKEND_URL` environment variable
   - Import error (dependency not in `requirements.txt`)
   - Streamlit version conflict
3. Fix:
   - Check/set environment variables in Render Settings
   - Verify `requirements.txt` has all dependencies
   - Manual Deploy â†’ Deploy Latest Commit
4. Monitor for startup success in logs

**Time to Resolution**: 5-15 minutes

#### Scenario B: Backend Connection Failure

**Root Cause**: Frontend can't reach backend API

**Symptoms in Logs**:
```
requests.exceptions.ConnectionError
CORS error
Backend API unreachable
```

**Steps**:
1. Verify backend is actually up: `curl [BACKEND_URL]/health`
2. Check `GHL_BACKEND_URL` environment variable:
   ```
   Render Dashboard â†’ enterprise-hub-platform â†’ Settings â†’ Environment
   Verify: GHL_BACKEND_URL=[correct backend URL]
   ```
3. If incorrect or missing, update and redeploy
4. Check backend CORS settings (should allow frontend domain)

**Time to Resolution**: 10-20 minutes

#### Scenario C: Streamlit Cold Start Timeout

**Root Cause**: Render free tier sleep after 15min inactivity

**Symptoms**:
- Service shows "running" but responds slowly
- First request times out, subsequent requests work

**Steps**:
1. This is expected behavior on free tier
2. UptimeRobot pings every 5 minutes should prevent sleep
3. If occurring:
   - Verify UptimeRobot monitor is active
   - Reduce monitor interval (paid UptimeRobot)
   - Or upgrade Render plan to always-on instance

**Time to Resolution**: Auto-recovers in 30-60 seconds

### Client Notification Template

```
Subject: ðŸ”´ URGENT: EnterpriseHub Dashboard Temporarily Unavailable

Hi Jorge,

Your EnterpriseHub dashboard is temporarily experiencing an issue.

INCIDENT DETAILS:
- Status: Frontend dashboard is currently down
- Impact: Cannot access dashboard UI
- Backend: Still operational (data safe)
- Started: [Time]

CURRENT ACTIONS:
[Specific steps being taken]

WORKAROUND:
Backend API is still functional if needed for integrations.

EXPECTED RESOLUTION: [ETA]

I'll update you shortly.

Best,
Cayman
```

---

## ðŸŸ  HIGH: Slow API Response Times

### Detection

**Alert Source**: UptimeRobot slow response warning OR manual observation

**Symptoms**:
- Backend health check >3s (baseline: <500ms)
- Analytics API >5s (baseline: <2s)
- No downtime, but degraded performance

### Diagnosis Steps

1. **Check Current Response Times**:
   ```bash
   # Test health endpoint
   time curl -s [BACKEND_URL]/health

   # Test analytics endpoint
   time curl -s "[BACKEND_URL]/api/analytics/dashboard?location_id=3xt4qayAh35BlDLaUv7P"
   ```

2. **Review Render Metrics**:
   ```
   Render Dashboard â†’ ghl-real-estate-ai â†’ Metrics tab
   Check:
   - CPU usage (high if >80% sustained)
   - Memory usage (concerning if >90%)
   - Request count (traffic spike?)
   ```

3. **Check External Dependencies**:
   ```
   Anthropic API Status: https://status.anthropic.com/
   GHL Platform Status: [Check if GHL has status page]
   ```

4. **Review Backend Logs for Slow Queries**:
   ```
   Search logs for: "slow", "timeout", "retry"
   Look for patterns: specific endpoints, times of day
   ```

### Resolution Procedures

#### Scenario A: GHL API Slowness

**Root Cause**: GHL API experiencing high latency

**Steps**:
1. Identify if slowness is only on GHL-dependent endpoints
2. Test direct GHL API call:
   ```bash
   curl -H "Authorization: Bearer [GHL_API_KEY]" \
     "https://rest.gohighlevel.com/v1/locations/3xt4qayAh35BlDLaUv7P"
   ```
3. If GHL is slow:
   - No immediate fix available (external dependency)
   - Implement caching if not already present (code change)
   - Notify Jorge that slowness is due to GHL platform

**Time to Resolution**: Depends on GHL recovery

#### Scenario B: Anthropic API Slowness

**Root Cause**: Claude API experiencing high latency

**Steps**:
1. Check https://status.anthropic.com/
2. Test direct API call with timing
3. If Anthropic is slow:
   - Increase timeout settings if needed
   - Notify Jorge of external dependency issue

**Time to Resolution**: Depends on Anthropic recovery

#### Scenario C: High CPU/Memory on Render

**Root Cause**: Free tier resource limits, traffic spike, memory leak

**Steps**:
1. Review Render Metrics for resource trends
2. Check recent traffic patterns (unusual spike?)
3. Short-term:
   - Restart service (Manual Deploy) to clear memory
4. Long-term:
   - Monitor for memory leaks (increasing memory over time)
   - Consider Render plan upgrade if sustained high load
   - Implement caching to reduce compute

**Time to Resolution**: 5 minutes (restart), ongoing monitoring

#### Scenario D: Cold Start Latency

**Root Cause**: Render free tier sleep after inactivity

**Symptoms**:
- First request very slow (3-5s)
- Subsequent requests fast
- Occurs after 15+ minutes of no activity

**Steps**:
1. Verify UptimeRobot is pinging every 5 minutes (should prevent)
2. If still occurring:
   - Check UptimeRobot monitors are active
   - Reduce ping interval (requires paid UptimeRobot)
   - Or upgrade Render plan to always-on

**Time to Resolution**: Auto-resolves after first request warms service

### Client Notification Template (If Prolonged)

```
Subject: ðŸŸ  EnterpriseHub Performance Notice

Hi Jorge,

I wanted to give you a heads-up about current system performance.

SITUATION:
- Status: System is operational but responding slower than usual
- Current Response Times: [X]s (normally [Y]s)
- Root Cause: [External API slowness / High traffic / etc.]

IMPACT:
- Dashboard still functional
- May experience slight delays loading analytics
- No data loss or errors

ACTIONS TAKEN:
[Steps taken to optimize]

EXPECTED RESOLUTION:
[Timeline or "Monitoring closely"]

The system is stable, just running slower than optimal. I'll keep you posted.

Best,
Cayman
```

---

## ðŸŸ  HIGH: Integration Failure (Frontend â†” Backend)

### Detection

**Symptoms**:
- Frontend loads but shows errors when fetching data
- Browser console shows CORS errors or network failures
- Analytics widgets display error messages

### Diagnosis Steps

1. **Verify Both Services Are Up**:
   ```bash
   # Check backend
   curl [BACKEND_URL]/health

   # Check frontend
   curl -I [FRONTEND_URL]
   ```

2. **Test Backend API Directly**:
   ```bash
   curl "[BACKEND_URL]/api/analytics/dashboard?location_id=3xt4qayAh35BlDLaUv7P"
   # Should return JSON data or auth challenge (not CORS error)
   ```

3. **Check Browser Console** (if possible):
   ```
   Open frontend in browser
   F12 â†’ Console tab
   Look for:
   - "CORS policy" errors
   - "Failed to fetch" errors
   - Network errors
   ```

4. **Review Frontend Environment Variables**:
   ```
   Render Dashboard â†’ enterprise-hub-platform â†’ Settings â†’ Environment
   Verify: GHL_BACKEND_URL is correct and matches deployed backend URL
   ```

### Resolution Procedures

#### Scenario A: CORS Error

**Root Cause**: Backend CORS middleware blocking frontend domain

**Symptoms**:
```
Access to fetch at '[BACKEND_URL]' from origin '[FRONTEND_URL]'
has been blocked by CORS policy
```

**Steps**:
1. Check backend CORS configuration in `api/main.py`:
   ```python
   # Should have:
   allow_origins=["*"]  # or specific frontend domain
   ```
2. If code change needed:
   - Update `api/main.py` CORS settings
   - Commit, push, redeploy backend
3. If already set to `["*"]`:
   - Restart backend service (may be cached)

**Time to Resolution**: 5-10 minutes (restart) or 15-30 minutes (code change)

#### Scenario B: Wrong Backend URL in Frontend

**Root Cause**: `GHL_BACKEND_URL` environment variable incorrect

**Steps**:
1. Verify backend URL:
   ```bash
   # What it should be (from Agent 2)
   curl [BACKEND_URL]/health
   ```
2. Check frontend env var:
   ```
   Render Dashboard â†’ enterprise-hub-platform â†’ Settings â†’ Environment
   GHL_BACKEND_URL = [compare with actual backend URL]
   ```
3. If mismatch:
   - Update `GHL_BACKEND_URL` to correct value
   - Click "Save Changes"
   - Redeploy frontend

**Time to Resolution**: 10-15 minutes

#### Scenario C: Backend Route Not Found

**Root Cause**: Frontend calling wrong endpoint or backend route missing

**Symptoms**:
```
404 Not Found
GET [BACKEND_URL]/api/some-endpoint
```

**Steps**:
1. Review frontend code for API calls
2. Compare with backend available routes:
   ```bash
   # List all routes (if FastAPI docs enabled in dev)
   curl [BACKEND_URL]/docs
   ```
3. If route truly missing:
   - Code fix needed (add route to backend)
4. If frontend calling wrong path:
   - Code fix needed (update frontend API calls)

**Time to Resolution**: Requires code changes (30-60 minutes)

---

## ðŸŸ¡ MEDIUM: GHL Webhook Failures

### Detection

**Symptoms**:
- Leads not being qualified automatically
- Backend logs show webhook errors
- No activity in webhook endpoint logs

### Diagnosis Steps

1. **Check Backend Webhook Logs**:
   ```
   Render Dashboard â†’ ghl-real-estate-ai â†’ Logs
   Search: "webhook", "/api/webhooks/contact"
   ```

2. **Verify Webhook Endpoint is Accessible**:
   ```bash
   # Test webhook endpoint exists
   curl -X POST [BACKEND_URL]/api/webhooks/contact \
     -H "Content-Type: application/json" \
     -d '{"type":"test"}'

   # Should return 200 or 400 (not 404)
   ```

3. **Check GHL Webhook Configuration**:
   ```
   Login to GHL account
   Navigate to: Settings â†’ Integrations â†’ Webhooks
   Verify: Webhook URL = [BACKEND_URL]/api/webhooks/contact
   Verify: Event types selected (Contact Created, Updated, etc.)
   Verify: Status = Active
   ```

### Resolution Procedures

#### Scenario A: Webhook URL Not Configured in GHL

**Steps**:
1. Login to GHL account
2. Navigate to: Settings â†’ Integrations â†’ Webhooks
3. Create/Edit webhook:
   ```
   Name: EnterpriseHub Lead Processing
   URL: [BACKEND_URL]/api/webhooks/contact
   Events: Contact Created, Contact Updated, Contact Tag Added
   Status: Active
   ```
4. Save and test with test contact

**Time to Resolution**: 5-10 minutes

#### Scenario B: Webhook Authentication Failure

**Root Cause**: GHL webhook signature verification failing

**Steps**:
1. Review webhook logs for "authentication" or "signature" errors
2. Check webhook secret configuration (if implemented)
3. Temporarily disable signature verification to test (if safe)

**Time to Resolution**: 15-30 minutes

#### Scenario C: Webhook Rate Limiting

**Root Cause**: Too many webhooks triggering rate limit

**Symptoms in Logs**:
```
Rate limit exceeded
429 Too Many Requests
```

**Steps**:
1. Review rate limit middleware settings
2. Check webhook frequency in logs
3. Adjust rate limits if legitimate traffic
4. Or investigate webhook loop (webhook triggering another webhook)

**Time to Resolution**: 15-30 minutes

---

## ðŸŸ¡ MEDIUM: High Memory Usage Warning

### Detection

**Alert Source**: Render notification or manual observation

**Symptoms**:
- Render Metrics show memory >80% of limit
- Logs may show "MemoryWarning"
- Service slower but not crashed

### Diagnosis Steps

1. **Check Current Memory Usage**:
   ```
   Render Dashboard â†’ ghl-real-estate-ai â†’ Metrics
   View: Memory usage over last 24 hours
   Look for: Trending upward (memory leak) or spikes (traffic)
   ```

2. **Review Recent Activity**:
   ```
   Check logs for:
   - High traffic periods
   - Large data processing operations
   - Memory-intensive AI operations
   ```

### Resolution Procedures

#### Scenario A: Memory Leak (Trending Upward)

**Symptoms**: Memory increases steadily over hours/days

**Steps**:
1. **Immediate**: Restart service (releases memory)
2. **Investigation**: Review code for memory leaks
3. **Monitoring**: Track memory after restart
4. If leak continues:
   - Code fix required (identify and patch leak)
   - Or upgrade Render plan (short-term workaround)

**Time to Resolution**: 5 minutes (restart), hours (code fix)

#### Scenario B: Traffic Spike

**Symptoms**: Memory spikes during high activity

**Steps**:
1. Normal behavior if temporary
2. If sustained high traffic:
   - Consider Render plan upgrade (more RAM)
   - Implement caching to reduce memory per request

**Time to Resolution**: Monitor; upgrade if needed

---

## ðŸŸ¢ LOW: Cosmetic Errors or Warnings in Logs

### Detection

**Symptoms**:
- Log noise (warnings, info messages)
- No functional impact
- No user complaints

### Resolution Procedures

1. **Evaluate Severity**:
   - True errors vs. verbose logging
2. **Filter Noise**:
   - Adjust log levels in code (reduce verbosity)
3. **Document**:
   - Note in monitoring log
   - Schedule fix for next update cycle

**Time to Resolution**: Scheduled maintenance

---

## ðŸ“Š Incident Tracking Template

For each incident, document using this format:

```markdown
# Incident Report: [YYYY-MM-DD HH:MM]

## Summary
- **Incident ID**: INC-[YYYYMMDD]-[number]
- **Severity**: [CRITICAL/HIGH/MEDIUM/LOW]
- **Component**: [Backend/Frontend/Integration/GHL/Anthropic]
- **Status**: [INVESTIGATING/MITIGATING/RESOLVED]

## Timeline
- **Detected**: [YYYY-MM-DD HH:MM UTC]
- **Response Started**: [YYYY-MM-DD HH:MM UTC]
- **Resolved**: [YYYY-MM-DD HH:MM UTC]
- **Total Downtime**: [Duration]

## Impact
- **Users Affected**: [Jorge/All users/Specific feature]
- **Functionality Lost**: [Description]
- **Data Loss**: [Yes/No - describe if yes]

## Root Cause
[Detailed explanation of what caused the incident]

## Detection Method
- **Source**: [UptimeRobot/Render/Manual/User Report]
- **Alert**: [Specific alert or observation]

## Resolution Steps
1. [Step 1 taken]
2. [Step 2 taken]
3. [Final resolution action]

## Client Communication
- **Notified**: [Yes/No - when]
- **Method**: [Email/Phone/etc.]
- **Response**: [Client feedback if any]

## Prevention Measures
1. [Action item 1 to prevent recurrence]
2. [Action item 2]
3. [Monitoring/alerting improvements]

## Lessons Learned
[What went well, what could improve, documentation updates needed]

## Follow-up Actions
- [ ] Update monitoring configuration
- [ ] Document in knowledge base
- [ ] Code fixes deployed
- [ ] Post-incident review with client
```

---

## ðŸ“ž Escalation Contacts

### Render.com Support

**When to Escalate**:
- Infrastructure outage (not code-related)
- Deployment system failures
- Billing or account issues

**Contact**:
- Support Portal: https://render.com/docs/support
- Expected Response: 24-48 hours (free tier)

### Anthropic Support

**When to Escalate**:
- Claude API consistent failures (>5% error rate)
- Authentication issues
- Quota or billing issues

**Contact**:
- Support: https://support.anthropic.com
- Status: https://status.anthropic.com

### GHL Support

**When to Escalate**:
- GHL API authentication failures
- Webhook delivery issues (GHL side)
- GHL platform bugs affecting integration

**Contact**:
- Support: https://support.gohighlevel.com
- Jorge may need to open ticket (his account)

---

## ðŸŽ¯ Success Metrics

### Incident Response Goals

- **Detection Time**: <5 minutes (via monitoring)
- **Response Time**: <5 minutes (critical), <30 minutes (high)
- **Resolution Time**: <1 hour (critical), <4 hours (high)
- **Client Communication**: Within 15 minutes of CRITICAL incident
- **Post-Incident Report**: Within 24 hours of resolution

### Monthly Incident Review

Track and review:
- Total incidents: [Count by severity]
- Average resolution time: [By severity]
- Recurring issues: [Patterns identified]
- Prevention measures: [Implemented this month]

---

## ðŸ”§ Quick Reference Commands

### Health Check Commands

```bash
# Backend health
curl [BACKEND_URL]/health

# Backend analytics (requires auth)
curl "[BACKEND_URL]/api/analytics/dashboard?location_id=3xt4qayAh35BlDLaUv7P"

# Frontend (HTML response)
curl -I [FRONTEND_URL]

# With timing
time curl -s [BACKEND_URL]/health > /dev/null
```

### Render Dashboard Quick Links

```
Backend Service: https://dashboard.render.com/web/[service-id]
Frontend Service: https://dashboard.render.com/web/[service-id]
Account Settings: https://dashboard.render.com/account
```

### UptimeRobot Quick Links

```
Dashboard: https://uptimerobot.com/dashboard
Monitors: https://uptimerobot.com/dashboard#mainDashboard
Alert Contacts: https://uptimerobot.com/dashboard#mySettings/alertContacts
```

---

## ðŸ“š Related Documentation

- [Monitoring Setup Guide](MONITORING_SETUP_GUIDE.md) - Initial monitoring configuration
- [Deployment Gameplan](FINAL_DEPLOYMENT_GAMEPLAN_2026-01-05.md) - Deployment procedures
- [Session Handoff](SESSION_HANDOFF_2026-01-05_ORCHESTRATOR_READY.md) - System architecture

---

**Playbook Status**: ðŸŸ¢ READY FOR USE
**Last Updated**: January 5, 2026
**Next Review**: 30 days after deployment
**Agent**: Agent 6 - Monitoring & DevOps Support
