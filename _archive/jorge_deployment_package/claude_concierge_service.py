#!/usr/bin/env python3
"""
Claude Concierge Service - AI-Powered Business Intelligence

Advanced AI service that provides real-time insights, pattern analysis, and strategic
recommendations for Jorge's Enhanced AI Bot Platform. Integrates with Claude API
to deliver contextual business intelligence and operational optimization.

Key Features:
- Real-time conversation pattern analysis
- Strategic business recommendations
- Performance trend identification
- Jorge-specific methodology optimization
- Market intelligence insights

Author: Claude Code Assistant
Created: January 23, 2026
"""

import os
import sys
import asyncio
import logging
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum

# Add paths for existing components
sys.path.append("../ghl_real_estate_ai")
sys.path.append(".")

try:
    from anthropic import Anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    from seller_models import (
        SellerTemperature, SellerPriority, SellerAnalysisResponse
    )
    SELLER_MODELS_AVAILABLE = True
except ImportError:
    SELLER_MODELS_AVAILABLE = False

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class InsightType(str, Enum):
    """Types of insights generated by Claude Concierge"""
    PATTERN_ANALYSIS = "pattern_analysis"
    PERFORMANCE_OPTIMIZATION = "performance_optimization"
    BUSINESS_STRATEGY = "business_strategy"
    MARKET_INTELLIGENCE = "market_intelligence"
    CONVERSATION_IMPROVEMENT = "conversation_improvement"
    ROI_ANALYSIS = "roi_analysis"


class InsightPriority(str, Enum):
    """Priority levels for insights"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


@dataclass
class ConciergeInsight:
    """Individual insight from Claude Concierge"""
    type: InsightType
    priority: InsightPriority
    title: str
    description: str
    recommendation: str
    confidence_score: float
    data_points: Dict[str, Any]
    action_items: List[str]
    roi_impact: Optional[str]
    timestamp: datetime

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization"""
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data


@dataclass
class ConversationPattern:
    """Identified conversation pattern"""
    pattern_name: str
    frequency: int
    success_rate: float
    avg_response_time: float
    temperature_correlation: Dict[str, float]
    keywords: List[str]
    examples: List[str]
    recommendations: List[str]


@dataclass
class PerformanceTrend:
    """Performance trend analysis"""
    metric_name: str
    current_value: float
    trend_direction: str  # "improving", "declining", "stable"
    percentage_change: float
    time_period: str
    prediction: Optional[float]
    contributing_factors: List[str]


class ClaudeConciergeService:
    """AI-powered business intelligence and insights service"""

    def __init__(self):
        self.anthropic_client = None
        self.insights_cache: Dict[str, List[ConciergeInsight]] = {}
        self.conversation_patterns: List[ConversationPattern] = []
        self.performance_trends: List[PerformanceTrend] = []
        self.jorge_business_context = self._load_jorge_business_context()

        # Initialize Claude API if available
        if ANTHROPIC_AVAILABLE:
            api_key = os.getenv("CLAUDE_API_KEY")
            if api_key:
                self.anthropic_client = Anthropic(api_key=api_key)
                logger.info("Claude Concierge: Anthropic client initialized")
            else:
                logger.warning("Claude Concierge: CLAUDE_API_KEY not found - using mock responses")
        else:
            logger.warning("Claude Concierge: Anthropic library not available")

    def _load_jorge_business_context(self) -> Dict[str, Any]:
        """Load Jorge's business rules and methodology for context"""
        return {
            "service_areas": ["Dallas", "Plano", "Frisco", "McKinney", "Allen", "Richardson"],
            "budget_range": {"min": 200000, "max": 800000},
            "target_response_time": 300,  # 5 minutes
            "commission_rate": 0.06,
            "confrontational_style": True,
            "four_question_methodology": [
                "What's your timeline for selling?",
                "What's your target sale price?",
                "What condition is your property in?",
                "Are you working with any other agents?"
            ],
            "hot_seller_criteria": {
                "timeline": "immediate_30_days",
                "motivation_score": 80,
                "budget_qualified": True,
                "area_qualified": True
            }
        }

    async def analyze_conversation_batch(
        self,
        conversations: List[Dict[str, Any]],
        timeframe: str = "24h"
    ) -> List[ConciergeInsight]:
        """Analyze a batch of conversations for patterns and insights"""

        if not conversations:
            return []

        insights = []

        # Pattern Analysis
        pattern_insights = await self._analyze_conversation_patterns(conversations)
        insights.extend(pattern_insights)

        # Performance Analysis
        performance_insights = await self._analyze_performance_trends(conversations)
        insights.extend(performance_insights)

        # Business Strategy Analysis
        strategy_insights = await self._analyze_business_strategy(conversations)
        insights.extend(strategy_insights)

        # ROI Analysis
        roi_insights = await self._analyze_roi_opportunities(conversations)
        insights.extend(roi_insights)

        # Cache insights
        cache_key = f"insights_{timeframe}_{int(time.time() / 3600)}"  # Hourly cache
        self.insights_cache[cache_key] = insights

        return sorted(insights, key=lambda x: (x.priority.value, -x.confidence_score))

    async def _analyze_conversation_patterns(
        self,
        conversations: List[Dict[str, Any]]
    ) -> List[ConciergeInsight]:
        """Identify patterns in successful vs failed conversations"""

        if not self.anthropic_client:
            return self._generate_mock_pattern_insights()

        # Prepare conversation data for analysis
        successful_convos = [c for c in conversations if c.get('temperature') == 'HOT']
        failed_convos = [c for c in conversations if c.get('temperature') == 'COLD']

        if len(successful_convos) < 2 or len(failed_convos) < 2:
            return self._generate_mock_pattern_insights()

        try:
            # Create AI prompt for pattern analysis
            prompt = self._create_pattern_analysis_prompt(successful_convos, failed_convos)

            # Get insights from Claude
            response = await self._query_claude_async(prompt)

            # Parse response into insights
            return self._parse_pattern_insights(response)

        except Exception as e:
            logger.error(f"Pattern analysis failed: {e}")
            return self._generate_mock_pattern_insights()

    async def _analyze_performance_trends(
        self,
        conversations: List[Dict[str, Any]]
    ) -> List[ConciergeInsight]:
        """Analyze performance trends and identify optimization opportunities"""

        insights = []

        # Response time trend analysis
        response_times = [c.get('response_time_ms', 0) for c in conversations]
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0

        if avg_response_time > self.jorge_business_context["target_response_time"] * 1000:
            insights.append(ConciergeInsight(
                type=InsightType.PERFORMANCE_OPTIMIZATION,
                priority=InsightPriority.HIGH,
                title="Response Time Above Target",
                description=f"Average response time ({avg_response_time:.0f}ms) exceeds 5-minute target",
                recommendation="Optimize seller analysis pipeline and enable caching",
                confidence_score=0.9,
                data_points={
                    "avg_response_time_ms": avg_response_time,
                    "target_ms": self.jorge_business_context["target_response_time"] * 1000,
                    "samples": len(response_times)
                },
                action_items=[
                    "Enable response caching for similar queries",
                    "Optimize Claude API response time",
                    "Implement async processing for non-critical tasks"
                ],
                roi_impact="$12K+ monthly in time savings",
                timestamp=datetime.now()
            ))

        # Conversion rate analysis
        hot_sellers = len([c for c in conversations if c.get('temperature') == 'HOT'])
        conversion_rate = hot_sellers / len(conversations) if conversations else 0

        if conversion_rate < 0.15:  # Below 15% hot conversion
            insights.append(ConciergeInsight(
                type=InsightType.BUSINESS_STRATEGY,
                priority=InsightPriority.MEDIUM,
                title="Low Hot Seller Conversion Rate",
                description=f"Only {conversion_rate:.1%} of sellers reach HOT status",
                recommendation="Refine qualification criteria and improve messaging",
                confidence_score=0.85,
                data_points={
                    "conversion_rate": conversion_rate,
                    "hot_sellers": hot_sellers,
                    "total_conversations": len(conversations),
                    "target_rate": 0.20
                },
                action_items=[
                    "A/B test more engaging opening messages",
                    "Adjust HOT criteria based on Jorge feedback",
                    "Implement urgency triggers in conversation flow"
                ],
                roi_impact="$25K+ monthly in additional qualified leads",
                timestamp=datetime.now()
            ))

        return insights

    async def _analyze_business_strategy(
        self,
        conversations: List[Dict[str, Any]]
    ) -> List[ConciergeInsight]:
        """Analyze business strategy optimization opportunities"""

        insights = []

        # Service area analysis
        area_performance = {}
        for conv in conversations:
            location = self._extract_location(conv.get('message', ''))
            if location:
                if location not in area_performance:
                    area_performance[location] = {'count': 0, 'hot_count': 0}
                area_performance[location]['count'] += 1
                if conv.get('temperature') == 'HOT':
                    area_performance[location]['hot_count'] += 1

        # Find highest performing areas
        if area_performance:
            best_area = max(
                area_performance.items(),
                key=lambda x: x[1]['hot_count'] / max(x[1]['count'], 1)
            )

            if best_area[1]['count'] >= 3:  # Minimum sample size
                insights.append(ConciergeInsight(
                    type=InsightType.MARKET_INTELLIGENCE,
                    priority=InsightPriority.MEDIUM,
                    title=f"High Performance in {best_area[0]}",
                    description=f"{best_area[0]} showing {best_area[1]['hot_count']}/{best_area[1]['count']} hot conversion",
                    recommendation=f"Increase marketing focus in {best_area[0]} area",
                    confidence_score=0.75,
                    data_points={
                        "top_area": best_area[0],
                        "conversion_rate": best_area[1]['hot_count'] / best_area[1]['count'],
                        "sample_size": best_area[1]['count'],
                        "area_performance": area_performance
                    },
                    action_items=[
                        f"Increase ad spend in {best_area[0]}",
                        f"Research what makes {best_area[0]} leads more qualified",
                        "Replicate successful patterns in other areas"
                    ],
                    roi_impact="15-30% increase in lead quality",
                    timestamp=datetime.now()
                ))

        return insights

    async def _analyze_roi_opportunities(
        self,
        conversations: List[Dict[str, Any]]
    ) -> List[ConciergeInsight]:
        """Analyze ROI optimization opportunities"""

        insights = []

        # Commission potential analysis
        total_commission_potential = 0
        high_value_count = 0

        for conv in conversations:
            estimated_value = self._extract_property_value(conv.get('message', ''))
            if estimated_value:
                commission = estimated_value * self.jorge_business_context["commission_rate"]
                total_commission_potential += commission

                if estimated_value > 500000:
                    high_value_count += 1

        if total_commission_potential > 0:
            avg_commission = total_commission_potential / len(conversations)

            insights.append(ConciergeInsight(
                type=InsightType.ROI_ANALYSIS,
                priority=InsightPriority.HIGH,
                title="Commission Pipeline Analysis",
                description=f"${total_commission_potential:,.0f} total pipeline, ${avg_commission:,.0f} avg per lead",
                recommendation="Focus on high-value properties and optimize conversion funnel",
                confidence_score=0.8,
                data_points={
                    "total_pipeline": total_commission_potential,
                    "avg_commission": avg_commission,
                    "high_value_count": high_value_count,
                    "total_leads": len(conversations)
                },
                action_items=[
                    "Prioritize leads with >$500K property values",
                    "Implement value-based follow-up sequences",
                    "Track commission conversion rates by value tier"
                ],
                roi_impact=f"${total_commission_potential * 0.1:,.0f} potential monthly increase",
                timestamp=datetime.now()
            ))

        return insights

    async def get_real_time_recommendations(
        self,
        current_conversation: Dict[str, Any]
    ) -> List[str]:
        """Get real-time recommendations for active conversation"""

        recommendations = []

        # Analyze current conversation context
        message = current_conversation.get('message', '').lower()
        contact_data = current_conversation.get('contact_data', {})

        # Timeline urgency detection
        if any(word in message for word in ['urgent', 'quickly', 'fast', 'asap', 'soon']):
            recommendations.append(
                "üî• URGENCY DETECTED: Prioritize immediate response and schedule same-day call"
            )

        # Budget qualification
        budget_mentioned = self._extract_property_value(message)
        if budget_mentioned:
            if budget_mentioned < self.jorge_business_context["budget_range"]["min"]:
                recommendations.append(
                    "üí∞ BELOW TARGET: Property value below $200K - consider referring to partner agent"
                )
            elif budget_mentioned > self.jorge_business_context["budget_range"]["max"]:
                recommendations.append(
                    "üéØ HIGH VALUE: Premium property - engage luxury services team"
                )
            else:
                recommendations.append(
                    "‚úÖ QUALIFIED: Property in target range - proceed with Jorge's methodology"
                )

        # Area qualification
        location = self._extract_location(message)
        if location and location not in self.jorge_business_context["service_areas"]:
            recommendations.append(
                f"üìç OUT OF AREA: {location} outside service area - potential referral opportunity"
            )

        # Conversation stage recommendations
        questions_answered = current_conversation.get('questions_answered', 0)
        if questions_answered == 0:
            recommendations.append(
                "‚ùì START QUALIFICATION: Begin with timeline question - Jorge's 4-question method"
            )
        elif questions_answered < 4:
            recommendations.append(
                f"üìù CONTINUE FLOW: {4-questions_answered} questions remaining for full qualification"
            )

        return recommendations

    async def _query_claude_async(self, prompt: str) -> str:
        """Query Claude API asynchronously"""
        if not self.anthropic_client:
            return "Mock Claude response for development"

        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-sonnet-20241022",
                max_tokens=2000,
                temperature=0.3,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.content[0].text
        except Exception as e:
            logger.error(f"Claude API query failed: {e}")
            return "Error querying Claude API"

    def _create_pattern_analysis_prompt(
        self,
        successful: List[Dict],
        failed: List[Dict]
    ) -> str:
        """Create prompt for pattern analysis"""
        return f"""
        Analyze these real estate seller conversations for Jorge's business optimization:

        SUCCESSFUL CONVERSATIONS (HOT sellers):
        {json.dumps(successful[:3], indent=2)}

        FAILED CONVERSATIONS (COLD sellers):
        {json.dumps(failed[:3], indent=2)}

        Jorge's Context:
        - Target: $200K-$800K properties in Dallas area
        - Uses confrontational selling style
        - 4-question qualification methodology
        - 5-minute response time goal

        Identify:
        1. What patterns distinguish successful vs failed conversations?
        2. What keywords/phrases correlate with HOT sellers?
        3. What timing patterns lead to better outcomes?
        4. Specific recommendations for Jorge's methodology

        Format as JSON with insights array containing pattern name, success correlation, and specific recommendations.
        """

    def _parse_pattern_insights(self, claude_response: str) -> List[ConciergeInsight]:
        """Parse Claude's pattern analysis into structured insights"""
        try:
            # Try to extract JSON from response
            if '{' in claude_response:
                json_start = claude_response.find('{')
                json_end = claude_response.rfind('}') + 1
                data = json.loads(claude_response[json_start:json_end])

                insights = []
                for pattern in data.get('insights', []):
                    insights.append(ConciergeInsight(
                        type=InsightType.PATTERN_ANALYSIS,
                        priority=InsightPriority.MEDIUM,
                        title=pattern.get('pattern_name', 'Conversation Pattern'),
                        description=pattern.get('description', ''),
                        recommendation=pattern.get('recommendation', ''),
                        confidence_score=pattern.get('confidence', 0.7),
                        data_points=pattern,
                        action_items=pattern.get('action_items', []),
                        roi_impact=pattern.get('roi_impact'),
                        timestamp=datetime.now()
                    ))
                return insights

        except json.JSONDecodeError:
            logger.warning("Failed to parse Claude response as JSON")

        return self._generate_mock_pattern_insights()

    def _generate_mock_pattern_insights(self) -> List[ConciergeInsight]:
        """Generate mock insights for development/demo"""
        return [
            ConciergeInsight(
                type=InsightType.PATTERN_ANALYSIS,
                priority=InsightPriority.HIGH,
                title="Urgency Keywords Drive Conversion",
                description="Messages containing urgency keywords have 67% higher HOT conversion rate",
                recommendation="Add urgency detection triggers and prioritize urgent leads",
                confidence_score=0.89,
                data_points={
                    "urgency_keywords": ["urgent", "quickly", "asap", "soon", "immediate"],
                    "conversion_lift": 0.67,
                    "sample_size": 45
                },
                action_items=[
                    "Implement urgency keyword detection in analysis pipeline",
                    "Create priority queue for urgent leads",
                    "Train voice AI to recognize urgency signals"
                ],
                roi_impact="$15K+ monthly from faster urgent lead conversion",
                timestamp=datetime.now()
            )
        ]

    def _extract_location(self, message: str) -> Optional[str]:
        """Extract location mentions from message"""
        locations = self.jorge_business_context["service_areas"]
        message_lower = message.lower()

        for location in locations:
            if location.lower() in message_lower:
                return location
        return None

    def _extract_property_value(self, message: str) -> Optional[float]:
        """Extract property value mentions from message"""
        import re

        # Look for price patterns like $500k, $500,000, 500k, etc.
        patterns = [
            r'\$?(\d{1,3})[k]',  # 500k
            r'\$?(\d{1,3}),?(\d{3}),?(\d{3})',  # $500,000 or 500,000
            r'\$?(\d{1,3}),?(\d{3})'  # $500k or 500,000
        ]

        for pattern in patterns:
            matches = re.findall(pattern, message, re.IGNORECASE)
            if matches:
                try:
                    if 'k' in message.lower():
                        return float(matches[0][0] if isinstance(matches[0], tuple) else matches[0]) * 1000
                    else:
                        # Handle full number formats
                        if isinstance(matches[0], tuple):
                            # Multi-part number like (500, 000)
                            return float(''.join(matches[0]))
                        return float(matches[0])
                except (ValueError, IndexError):
                    continue

        return None

    async def get_cached_insights(self, timeframe: str = "24h") -> List[ConciergeInsight]:
        """Get cached insights for timeframe"""
        cache_key = f"insights_{timeframe}_{int(time.time() / 3600)}"
        return self.insights_cache.get(cache_key, [])

    async def generate_executive_summary(
        self,
        insights: List[ConciergeInsight]
    ) -> Dict[str, Any]:
        """Generate executive summary of insights for Jorge"""

        critical_insights = [i for i in insights if i.priority == InsightPriority.CRITICAL]
        high_insights = [i for i in insights if i.priority == InsightPriority.HIGH]

        roi_impact = sum([
            float(i.roi_impact.replace('$', '').replace('K', '000').replace('+', '').replace(',', '').split()[0])
            for i in insights
            if i.roi_impact and any(c.isdigit() for c in i.roi_impact)
        ])

        return {
            "timestamp": datetime.now().isoformat(),
            "total_insights": len(insights),
            "critical_count": len(critical_insights),
            "high_priority_count": len(high_insights),
            "estimated_monthly_roi": roi_impact,
            "top_recommendations": [i.recommendation for i in insights[:3]],
            "key_patterns": [
                i.title for i in insights
                if i.type == InsightType.PATTERN_ANALYSIS
            ][:3],
            "action_items": [
                item for insight in insights[:5]
                for item in insight.action_items
            ],
            "confidence_score": sum([i.confidence_score for i in insights]) / len(insights) if insights else 0
        }


# Async helper functions for integration
async def get_concierge_insights(conversations: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Main entry point for getting insights from conversations"""
    service = ClaudeConciergeService()
    insights = await service.analyze_conversation_batch(conversations)
    return [insight.to_dict() for insight in insights]


async def get_real_time_suggestions(conversation: Dict[str, Any]) -> List[str]:
    """Get real-time suggestions for active conversation"""
    service = ClaudeConciergeService()
    return await service.get_real_time_recommendations(conversation)


if __name__ == "__main__":
    # Test the service
    import asyncio

    async def test_service():
        service = ClaudeConciergeService()

        # Mock conversation data
        test_conversations = [
            {
                "contact_id": "test_1",
                "message": "I need to sell my house in Plano quickly for around $450k",
                "temperature": "HOT",
                "response_time_ms": 245,
                "questions_answered": 3
            },
            {
                "contact_id": "test_2",
                "message": "Just looking at options maybe next year",
                "temperature": "COLD",
                "response_time_ms": 2500,
                "questions_answered": 1
            }
        ]

        insights = await service.analyze_conversation_batch(test_conversations)
        print(f"\nüß† Generated {len(insights)} insights:")

        for insight in insights:
            print(f"\n{insight.priority.value.upper()}: {insight.title}")
            print(f"   {insight.description}")
            print(f"   üí° {insight.recommendation}")
            if insight.roi_impact:
                print(f"   üí∞ {insight.roi_impact}")

        # Test real-time recommendations
        recommendations = await service.get_real_time_recommendations(test_conversations[0])
        print(f"\nüéØ Real-time recommendations:")
        for rec in recommendations:
            print(f"   {rec}")

    asyncio.run(test_service())