"""
Smart Forecast Engine Module.

Uses Machine Learning (scikit-learn) to predict future asset prices
based on historical technical indicators.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from datetime import timedelta
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from typing import Tuple, Optional

import utils.ui as ui
from utils.data_loader import get_stock_data, calculate_indicators
from utils.logger import get_logger

logger = get_logger(__name__)


def render() -> None:
    """Render the Smart Forecast Engine interface."""
    ui.section_header("ðŸ§  Smart Forecast Engine", "AI-Powered Price Prediction")

    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        ticker = st.text_input("Asset Ticker", value="MSFT").upper()
    with col2:
        days_to_predict = st.slider("Forecast Horizon (Days)", 7, 90, 30)

    if st.button("ðŸ”® Generate Forecast", type="primary"):
        with st.spinner(f"Training AI models on {ticker} historical data..."):
            try:
                # 1. Get Data
                df = get_stock_data(ticker, period="2y", interval="1d")
                if df is None or df.empty:
                    st.error("No data found.")
                    return

                # 2. Prepare Data (Feature Engineering)
                df = calculate_indicators(df)
                df = _prepare_features(df)

                # 3. Train Model
                model, metrics, prediction_df = _train_and_predict(df, days_to_predict)

                # 4. Visualize
                _render_results(df, prediction_df, metrics, ticker)

            except Exception as e:
                logger.error(f"Forecast failed: {e}", exc_info=True)
                st.error(f"Forecasting error: {e}")


def _prepare_features(df: pd.DataFrame) -> pd.DataFrame:
    """Create ML features from technical indicators."""
    data = df.copy()

    # Create Lag Features (Past performance predicts future)
    for lag in [1, 2, 3, 5]:
        data[f"Close_Lag_{lag}"] = data["Close"].shift(lag)

    # Drop NaN values created by lags/indicators
    data = data.dropna()

    # Target: Close price shifted into the future (but we forecast step-by-step)
    # Actually for direct regression we usually predict 'Next Day Close'
    # For this demo, we'll train to predict 'Next Day' and iterate.

    return data


def _train_and_predict(
    df: pd.DataFrame, future_days: int
) -> Tuple[RandomForestRegressor, dict, pd.DataFrame]:
    """
    Train Random Forest and generate future predictions with confidence intervals.

    Uses individual tree predictions from RandomForest to calculate uncertainty measures.
    Returns prediction intervals at Â±1Ïƒ and Â±2Ïƒ confidence levels.

    Args:
        df: Historical data with features
        future_days: Number of days to forecast

    Returns:
        model: Trained RandomForestRegressor
        metrics: Dict with MAE, RMSE, R2, directional_accuracy, last_price
        prediction_df: DataFrame with columns [price, lower_1sigma, upper_1sigma,
                       lower_2sigma, upper_2sigma]
    """
    # Features to use for training
    feature_cols = ["RSI", "MACD", "Signal_Line", "SMA_20", "SMA_50", "Volume"]
    # Add Lag columns
    feature_cols += [c for c in df.columns if "Lag" in c]

    # Target: Next Day's Close
    df["Target"] = df["Close"].shift(-1)
    train_df = df.dropna()

    X = train_df[feature_cols]
    y = train_df["Target"]

    # Split for validation
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Model: Random Forest (Ensemble)
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)

    # Validation Metrics
    y_pred_test = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    r2 = r2_score(y_test, y_pred_test)

    # Directional Accuracy (% of correct up/down predictions)
    y_test_direction = np.diff(y_test.values) > 0
    y_pred_direction = np.diff(y_pred_test) > 0
    directional_accuracy = np.mean(y_test_direction == y_pred_direction) * 100

    metrics = {
        "MAE": mae,
        "RMSE": rmse,
        "R2": r2,
        "Directional_Accuracy": directional_accuracy,
        "Last_Price": df.iloc[-1]["Close"],
    }

    # --- FUTURE FORECASTING WITH CONFIDENCE INTERVALS ---
    future_dates = []
    future_prices = []
    lower_1sigma = []
    upper_1sigma = []
    lower_2sigma = []
    upper_2sigma = []

    # Start with the last known data point
    current_features = df.iloc[-1][feature_cols].values.reshape(1, -1)
    current_date = df.index[-1]

    for i in range(future_days):
        # Get predictions from all individual trees
        tree_predictions = np.array(
            [tree.predict(current_features)[0] for tree in model.estimators_]
        )

        # Calculate mean and std dev across trees
        pred_price = np.mean(tree_predictions)
        pred_std = np.std(tree_predictions)

        # Confidence intervals (assuming normal distribution)
        # Â±1Ïƒ â‰ˆ 68% confidence, Â±2Ïƒ â‰ˆ 95% confidence
        lower_1sigma.append(pred_price - pred_std)
        upper_1sigma.append(pred_price + pred_std)
        lower_2sigma.append(pred_price - 2 * pred_std)
        upper_2sigma.append(pred_price + 2 * pred_std)

        # Add date
        current_date += timedelta(days=1)
        # Skip weekends
        while current_date.weekday() > 4:
            current_date += timedelta(days=1)

        future_dates.append(current_date)
        future_prices.append(pred_price)

        # Update features for next step (Approximation)
        # Keep indicators stable for short-term forecast
        # This is a simplification; in production we'd recalculate all indicators

    prediction_df = pd.DataFrame(
        {
            "Date": future_dates,
            "Predicted_Close": future_prices,
            "Lower_1Sigma": lower_1sigma,
            "Upper_1Sigma": upper_1sigma,
            "Lower_2Sigma": lower_2sigma,
            "Upper_2Sigma": upper_2sigma,
        }
    ).set_index("Date")

    return model, metrics, prediction_df


@st.cache_data(ttl=300)
def _run_rolling_backtest(
    df: pd.DataFrame, window_size: int = 90, horizon: int = 30
) -> Optional[pd.DataFrame]:
    """
    Run rolling window backtest to evaluate model performance on historical data.

    For each day in the test period, train on past window_size days and predict
    next horizon days. Compare predictions to actual prices.

    Args:
        df: Historical data with features
        window_size: Number of days to use for training (default: 90)
        horizon: Number of days to forecast ahead (default: 30)

    Returns:
        DataFrame with columns [date, actual_price, predicted_price, error, abs_error]
        or None if insufficient data
    """
    if len(df) < window_size + horizon + 50:
        logger.warning(
            f"Insufficient data for backtest: {len(df)} rows. "
            f"Need at least {window_size + horizon + 50}."
        )
        return None

    feature_cols = ["RSI", "MACD", "Signal_Line", "SMA_20", "SMA_50", "Volume"]
    feature_cols += [c for c in df.columns if "Lag" in c]

    # Prepare target
    df_copy = df.copy()
    df_copy["Target"] = df_copy["Close"].shift(-1)
    df_copy = df_copy.dropna()

    backtest_results = []

    # Start backtesting from window_size to len(df) - horizon
    test_start = window_size
    test_end = len(df_copy) - horizon

    # Use step size to avoid too many iterations (every 5 days)
    step_size = 5

    for i in range(test_start, test_end, step_size):
        # Train on past window_size days
        train_data = df_copy.iloc[i - window_size : i]

        X_train = train_data[feature_cols]
        y_train = train_data["Target"]

        # Train model
        model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
        model.fit(X_train, y_train)

        # Predict next day (1-day ahead)
        if i < len(df_copy):
            test_features = df_copy.iloc[i][feature_cols].values.reshape(1, -1)
            prediction = model.predict(test_features)[0]
            actual = df_copy.iloc[i]["Close"]

            backtest_results.append(
                {
                    "date": df_copy.index[i],
                    "actual_price": actual,
                    "predicted_price": prediction,
                    "error": prediction - actual,
                    "abs_error": abs(prediction - actual),
                }
            )

    if not backtest_results:
        return None

    return pd.DataFrame(backtest_results)


def _render_results(
    hist_df: pd.DataFrame, pred_df: pd.DataFrame, metrics: dict, ticker: str
) -> None:
    """Visualize the forecast with confidence intervals and performance metrics."""

    # 1. Enhanced Metrics Dashboard (4 columns)
    st.markdown("### Model Performance Metrics")
    m1, m2, m3, m4 = st.columns(4)

    with m1:
        ui.card_metric("RÂ² Score", f"{metrics['R2']:.1%}", "Model Accuracy")
    with m2:
        ui.card_metric("MAE", f"${metrics['MAE']:.2f}", "Mean Absolute Error")
    with m3:
        ui.card_metric("RMSE", f"${metrics['RMSE']:.2f}", "Root Mean Squared Error")
    with m4:
        ui.card_metric(
            "Directional Accuracy",
            f"{metrics['Directional_Accuracy']:.1f}%",
            "Up/Down Predictions",
        )

    st.markdown("---")

    # 2. Forecast Summary
    st.markdown("### Forecast Summary")
    f1, f2, f3 = st.columns(3)
    with f1:
        ui.card_metric("Current Price", f"${metrics['Last_Price']:.2f}", ticker)
    with f2:
        final_pred = pred_df.iloc[-1]["Predicted_Close"]
        delta = ((final_pred - metrics["Last_Price"]) / metrics["Last_Price"]) * 100
        ui.card_metric(
            f"Forecast ({len(pred_df)} Days)",
            f"${final_pred:.2f}",
            f"{delta:+.2f}%",
        )
    with f3:
        # Show confidence range width
        final_upper = pred_df.iloc[-1]["Upper_1Sigma"]
        final_lower = pred_df.iloc[-1]["Lower_1Sigma"]
        confidence_range = final_upper - final_lower
        ui.card_metric(
            "Confidence Range (Â±1Ïƒ)",
            f"${confidence_range:.2f}",
            "68% Probability Band",
        )

    st.markdown("---")

    # 3. Enhanced Forecast Chart with Confidence Bands
    st.markdown("### Price Forecast with Confidence Intervals")

    fig = go.Figure()

    # Historical Data (Last 90 days)
    display_hist = hist_df.iloc[-90:]
    fig.add_trace(
        go.Scatter(
            x=display_hist.index,
            y=display_hist["Close"],
            mode="lines",
            name="Historical Price",
            line=dict(color="#64748B", width=2),
            hovertemplate="<b>Historical</b><br>Date: %{x}<br>Price: $%{y:.2f}<extra></extra>",
        )
    )

    # Confidence Band Â±2Ïƒ (95% confidence) - Outer band
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Upper_2Sigma"],
            mode="lines",
            name="Â±2Ïƒ (95%)",
            line=dict(width=0),
            showlegend=False,
            hoverinfo="skip",
        )
    )
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Lower_2Sigma"],
            mode="lines",
            name="95% Confidence",
            fill="tonexty",
            fillcolor="rgba(79, 70, 229, 0.15)",
            line=dict(width=0),
            hovertemplate="<b>95% Confidence</b><br>Upper: $%{y:.2f}<extra></extra>",
        )
    )

    # Confidence Band Â±1Ïƒ (68% confidence) - Inner band
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Upper_1Sigma"],
            mode="lines",
            name="Â±1Ïƒ (68%)",
            line=dict(width=0),
            showlegend=False,
            hoverinfo="skip",
        )
    )
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Lower_1Sigma"],
            mode="lines",
            name="68% Confidence",
            fill="tonexty",
            fillcolor="rgba(79, 70, 229, 0.3)",
            line=dict(width=0),
            hovertemplate="<b>68% Confidence</b><br>Lower: $%{y:.2f}<extra></extra>",
        )
    )

    # Forecast Line (on top)
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Predicted_Close"],
            mode="lines+markers",
            name="AI Forecast",
            line=dict(color="#4F46E5", width=3, dash="dash"),
            marker=dict(size=6, color="#4F46E5"),
            hovertemplate="<b>Forecast</b><br>Date: %{x}<br>Price: $%{y:.2f}<extra></extra>",
        )
    )

    fig.update_layout(
        title=f"AI Price Prediction with Confidence Intervals: {ticker}",
        xaxis_title="Date",
        yaxis_title="Price ($)",
        template="plotly_white",
        hovermode="x unified",
        height=550,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
    )

    st.plotly_chart(fig, use_container_width=True)

    # Add explanation
    with st.expander("ðŸ“Š Understanding Confidence Intervals"):
        st.markdown(
            """
        **Confidence intervals** represent the uncertainty in our predictions:

        - **Â±1Ïƒ band (dark blue)**: 68% probability the actual price falls within this range
        - **Â±2Ïƒ band (light blue)**: 95% probability the actual price falls within this range

        The bands are calculated using the standard deviation of predictions from all 100
        decision trees in the Random Forest model. Wider bands indicate higher uncertainty.

        **Interpretation:**
        - Narrow bands = High model confidence
        - Wide bands = High uncertainty (volatile asset or challenging forecast period)
        """
        )

    st.markdown("---")

    # 4. Rolling Backtest Section
    st.markdown("### Historical Model Performance (Rolling Backtest)")

    with st.spinner("Running rolling backtest on historical data..."):
        backtest_df = _run_rolling_backtest(hist_df, window_size=90, horizon=30)

    if backtest_df is not None and not backtest_df.empty:
        # Backtest metrics
        bt_mae = backtest_df["abs_error"].mean()
        bt_rmse = np.sqrt((backtest_df["error"] ** 2).mean())
        bt_r2 = 1 - (
            (backtest_df["error"] ** 2).sum()
            / ((backtest_df["actual_price"] - backtest_df["actual_price"].mean()) ** 2).sum()
        )

        # Directional accuracy for backtest
        actual_direction = np.diff(backtest_df["actual_price"].values) > 0
        pred_direction = np.diff(backtest_df["predicted_price"].values) > 0
        bt_directional = np.mean(actual_direction == pred_direction) * 100

        # Display backtest metrics
        bt1, bt2, bt3, bt4 = st.columns(4)
        with bt1:
            ui.card_metric("Backtest MAE", f"${bt_mae:.2f}", "Historical Average Error")
        with bt2:
            ui.card_metric("Backtest RMSE", f"${bt_rmse:.2f}", "Historical RMSE")
        with bt3:
            ui.card_metric("Backtest RÂ²", f"{bt_r2:.1%}", "Historical Accuracy")
        with bt4:
            ui.card_metric(
                "Backtest Directional",
                f"{bt_directional:.1f}%",
                "Historical Up/Down Accuracy",
            )

        # Backtest visualization: Actual vs Predicted
        fig_backtest = go.Figure()

        fig_backtest.add_trace(
            go.Scatter(
                x=backtest_df["date"],
                y=backtest_df["actual_price"],
                mode="lines",
                name="Actual Price",
                line=dict(color="#10B981", width=2),
                hovertemplate="<b>Actual</b><br>Date: %{x}<br>Price: $%{y:.2f}<extra></extra>",
            )
        )

        fig_backtest.add_trace(
            go.Scatter(
                x=backtest_df["date"],
                y=backtest_df["predicted_price"],
                mode="lines",
                name="Predicted Price",
                line=dict(color="#4F46E5", width=2, dash="dot"),
                hovertemplate="<b>Predicted</b><br>Date: %{x}<br>Price: $%{y:.2f}<extra></extra>",
            )
        )

        fig_backtest.update_layout(
            title=f"Backtest Results: Actual vs Predicted Prices ({ticker})",
            xaxis_title="Date",
            yaxis_title="Price ($)",
            template="plotly_white",
            hovermode="x unified",
            height=450,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        )

        st.plotly_chart(fig_backtest, use_container_width=True)

        # Error distribution histogram
        with st.expander("ðŸ“ˆ View Error Distribution"):
            fig_error = go.Figure()

            fig_error.add_trace(
                go.Histogram(
                    x=backtest_df["error"],
                    nbinsx=30,
                    name="Prediction Errors",
                    marker=dict(color="#4F46E5", opacity=0.7),
                    hovertemplate="<b>Error Range</b><br>%{x:.2f}<br>Count: %{y}<extra></extra>",
                )
            )

            fig_error.update_layout(
                title="Distribution of Prediction Errors (Backtest)",
                xaxis_title="Error ($)",
                yaxis_title="Frequency",
                template="plotly_white",
                height=350,
                showlegend=False,
            )

            st.plotly_chart(fig_error, use_container_width=True)

            st.markdown(
                f"""
            **Error Statistics:**
            - Mean Error: ${backtest_df["error"].mean():.2f}
            - Median Error: ${backtest_df["error"].median():.2f}
            - Std Dev: ${backtest_df["error"].std():.2f}

            A centered distribution around $0 indicates unbiased predictions.
            """
            )
    else:
        st.info(
            "Insufficient historical data for backtest. "
            "Need at least 180 days of data to run rolling backtest."
        )

    st.markdown("---")

    # 5. Model Explanation
    with st.expander("ðŸ§  How this model works"):
        st.write("""
        This module uses a **Random Forest Regressor**
        (an ensemble of decision trees) trained on:
        - **Technical Indicators:** RSI, MACD, Signal Line,
          Moving Averages (20, 50).
        - **Lag Features:** Previous day prices to capture autocorrelation.
        - **Volume:** Trading volume trends.

        The model learns the complex non-linear relationships between
        these indicators and the next day's price. For the forecast,
        it projects these patterns forward.

        **Confidence Intervals:** Calculated using the standard deviation of
        predictions from all 100 trees in the ensemble. This provides a
        statistically rigorous measure of prediction uncertainty.

        *Note: Financial forecasting is inherently probabilistic.
        Do not use for actual trading.*
        """)
