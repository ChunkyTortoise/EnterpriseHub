"""
Smart Forecast Engine Module.

Uses Machine Learning (scikit-learn) to predict future asset prices
based on historical technical indicators.
"""

from datetime import datetime, timedelta
from io import BytesIO
from typing import Optional, Tuple

import numpy as np
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

import utils.ui as ui
from utils.data_loader import calculate_indicators, get_stock_data
from utils.logger import get_logger

logger = get_logger(__name__)


def render() -> None:
    """Render the Smart Forecast Engine interface."""
    ui.section_header("üß† Smart Forecast Engine", "AI-Powered Price Prediction")

    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        ticker = st.text_input("Asset Ticker", value="MSFT").upper()
    with col2:
        days_to_predict = st.slider("Forecast Horizon (Days)", 7, 90, 30)

    if st.button("üîÆ Generate Forecast", type="primary"):
        with st.spinner(f"Training AI models on {ticker} historical data..."):
            try:
                # 1. Get Data
                df = get_stock_data(ticker, period="2y", interval="1d")
                if df is None or df.empty:
                    st.error("No data found.")
                    return

                # 2. Prepare Data (Feature Engineering)
                df = calculate_indicators(df)
                df = _prepare_features(df)

                # 3. Train Model
                model, metrics, prediction_df = _train_and_predict(df, days_to_predict)

                # 4. Visualize
                _render_results(df, prediction_df, metrics, ticker)

            except Exception as e:
                logger.error(f"Forecast failed: {e}", exc_info=True)
                st.error(f"Forecasting error: {e}")


def _prepare_features(df: pd.DataFrame) -> pd.DataFrame:
    """Create ML features from technical indicators."""
    data = df.copy()

    # Create Lag Features (Past performance predicts future)
    for lag in [1, 2, 3, 5]:
        data[f"Close_Lag_{lag}"] = data["Close"].shift(lag)

    # Drop NaN values created by lags/indicators
    data = data.dropna()

    # Target: Close price shifted into the future (but we forecast step-by-step)
    # Actually for direct regression we usually predict 'Next Day Close'
    # For this demo, we'll train to predict 'Next Day' and iterate.

    return data


def _train_and_predict(
    df: pd.DataFrame, future_days: int
) -> Tuple[RandomForestRegressor, dict, pd.DataFrame]:
    """
    Train Random Forest and generate future predictions with confidence intervals.

    Uses individual tree predictions from RandomForest to calculate uncertainty measures.
    Returns prediction intervals at ¬±1œÉ and ¬±2œÉ confidence levels.

    Args:
        df: Historical data with features
        future_days: Number of days to forecast

    Returns:
        model: Trained RandomForestRegressor
        metrics: Dict with MAE, RMSE, R2, directional_accuracy, last_price
        prediction_df: DataFrame with columns [price, lower_1sigma, upper_1sigma,
                       lower_2sigma, upper_2sigma]
    """
    # Features to use for training
    feature_cols = ["RSI", "MACD", "Signal_Line", "SMA_20", "SMA_50", "Volume"]
    # Add Lag columns
    feature_cols += [c for c in df.columns if "Lag" in c]

    # Target: Next Day's Close
    df["Target"] = df["Close"].shift(-1)
    train_df = df.dropna()

    X = train_df[feature_cols]
    y = train_df["Target"]

    # Split for validation
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

    # Model: Random Forest (Ensemble)
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)

    # Validation Metrics
    y_pred_test = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred_test)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
    r2 = r2_score(y_test, y_pred_test)

    # Directional Accuracy (% of correct up/down predictions)
    y_test_direction = np.diff(y_test.values) > 0
    y_pred_direction = np.diff(y_pred_test) > 0
    directional_accuracy = np.mean(y_test_direction == y_pred_direction) * 100

    metrics = {
        "MAE": mae,
        "RMSE": rmse,
        "R2": r2,
        "Directional_Accuracy": directional_accuracy,
        "Last_Price": df.iloc[-1]["Close"],
    }

    # --- FUTURE FORECASTING WITH CONFIDENCE INTERVALS ---
    future_dates = []
    future_prices = []
    lower_1sigma = []
    upper_1sigma = []
    lower_2sigma = []
    upper_2sigma = []

    # Start with the last known data point
    current_features = df.iloc[-1][feature_cols].values.reshape(1, -1)
    current_date = df.index[-1]

    for i in range(future_days):
        # Get predictions from all individual trees
        tree_predictions = np.array(
            [tree.predict(current_features)[0] for tree in model.estimators_]
        )

        # Calculate mean and std dev across trees
        pred_price = np.mean(tree_predictions)
        pred_std = np.std(tree_predictions)

        # Confidence intervals (assuming normal distribution)
        # ¬±1œÉ ‚âà 68% confidence, ¬±2œÉ ‚âà 95% confidence
        lower_1sigma.append(pred_price - pred_std)
        upper_1sigma.append(pred_price + pred_std)
        lower_2sigma.append(pred_price - 2 * pred_std)
        upper_2sigma.append(pred_price + 2 * pred_std)

        # Add date
        current_date += timedelta(days=1)
        # Skip weekends
        while current_date.weekday() > 4:
            current_date += timedelta(days=1)

        future_dates.append(current_date)
        future_prices.append(pred_price)

        # Update features for next step (Approximation)
        # Keep indicators stable for short-term forecast
        # This is a simplification; in production we'd recalculate all indicators

    prediction_df = pd.DataFrame(
        {
            "Date": future_dates,
            "Predicted_Close": future_prices,
            "Lower_1Sigma": lower_1sigma,
            "Upper_1Sigma": upper_1sigma,
            "Lower_2Sigma": lower_2sigma,
            "Upper_2Sigma": upper_2sigma,
        }
    ).set_index("Date")

    return model, metrics, prediction_df


@st.cache_data(ttl=300)
def _run_rolling_backtest(
    df: pd.DataFrame, window_size: int = 90, horizon: int = 30
) -> Optional[pd.DataFrame]:
    """
    Run rolling window backtest to evaluate model performance on historical data.

    For each day in the test period, train on past window_size days and predict
    next horizon days. Compare predictions to actual prices.

    Args:
        df: Historical data with features
        window_size: Number of days to use for training (default: 90)
        horizon: Number of days to forecast ahead (default: 30)

    Returns:
        DataFrame with columns [date, actual_price, predicted_price, error, abs_error]
        or None if insufficient data
    """
    if len(df) < window_size + horizon + 50:
        logger.warning(
            f"Insufficient data for backtest: {len(df)} rows. "
            f"Need at least {window_size + horizon + 50}."
        )
        return None

    feature_cols = ["RSI", "MACD", "Signal_Line", "SMA_20", "SMA_50", "Volume"]
    feature_cols += [c for c in df.columns if "Lag" in c]

    # Prepare target
    df_copy = df.copy()
    df_copy["Target"] = df_copy["Close"].shift(-1)
    df_copy = df_copy.dropna()

    backtest_results = []

    # Start backtesting from window_size to len(df) - horizon
    test_start = window_size
    test_end = len(df_copy) - horizon

    # Use step size to avoid too many iterations (every 5 days)
    step_size = 5

    for i in range(test_start, test_end, step_size):
        # Train on past window_size days
        train_data = df_copy.iloc[i - window_size : i]

        X_train = train_data[feature_cols]
        y_train = train_data["Target"]

        # Train model
        model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
        model.fit(X_train, y_train)

        # Predict next day (1-day ahead)
        if i < len(df_copy):
            test_features = df_copy.iloc[i][feature_cols].values.reshape(1, -1)
            prediction = model.predict(test_features)[0]
            actual = df_copy.iloc[i]["Close"]

            backtest_results.append(
                {
                    "date": df_copy.index[i],
                    "actual_price": actual,
                    "predicted_price": prediction,
                    "error": prediction - actual,
                    "abs_error": abs(prediction - actual),
                }
            )

    if not backtest_results:
        return None

    return pd.DataFrame(backtest_results)


def _render_results(
    hist_df: pd.DataFrame, pred_df: pd.DataFrame, metrics: dict, ticker: str
) -> None:
    """Visualize the forecast with confidence intervals and performance metrics."""

    # 1. Enhanced Metrics Dashboard (4 columns)
    st.markdown("### Model Performance Metrics")
    m1, m2, m3, m4 = st.columns(4)
    plotly_template = ui.get_plotly_template()

    with m1:
        ui.animated_metric("R¬≤ Score", f"{metrics['R2']:.1%}", icon="üéØ", color="success")
    with m2:
        ui.animated_metric("MAE", f"${metrics['MAE']:.2f}", icon="üìâ", color="primary")
    with m3:
        ui.animated_metric("RMSE", f"${metrics['RMSE']:.2f}", icon="üìä", color="primary")
    with m4:
        ui.animated_metric(
            "Directional Accuracy",
            f"{metrics['Directional_Accuracy']:.1f}%",
            icon="‚ÜïÔ∏è",
            color="success" if metrics['Directional_Accuracy'] > 50 else "warning"
        )

    st.markdown("---")

    # 2. Forecast Summary
    st.markdown("### Forecast Summary")
    f1, f2, f3 = st.columns(3)
    with f1:
        ui.animated_metric("Current Price", f"${metrics['Last_Price']:.2f}", icon="üíµ")
    with f2:
        final_pred = pred_df.iloc[-1]["Predicted_Close"]
        delta = ((final_pred - metrics["Last_Price"]) / metrics["Last_Price"]) * 100
        ui.animated_metric(
            f"Forecast ({len(pred_df)} Days)",
            f"${final_pred:.2f}",
            delta=f"{delta:+.2f}%",
            icon="üîÆ"
        )
    with f3:
        # Show confidence range width
        final_upper = pred_df.iloc[-1]["Upper_1Sigma"]
        final_lower = pred_df.iloc[-1]["Lower_1Sigma"]
        confidence_range = final_upper - final_lower
        ui.animated_metric(
            "Confidence Range (¬±1œÉ)",
            f"${confidence_range:.2f}",
            icon="üõ°Ô∏è"
        )

    st.markdown("---")

    # 3. Enhanced Forecast Chart with Confidence Bands
    st.markdown("### Price Forecast with Confidence Intervals")

    fig = go.Figure()

    # Historical Data (Last 90 days)
    display_hist = hist_df.iloc[-90:]
    fig.add_trace(
        go.Scatter(
            x=display_hist.index,
            y=display_hist["Close"],
            mode="lines",
            name="Historical Price",
            line=dict(color=ui.THEME["secondary"], width=2),
            hovertemplate="<b>Historical</b><br>Date: %{x}<br>Price: $%{y:.2f}<extra></extra>",
        )
    )

    # Confidence Band ¬±2œÉ (95% confidence) - Outer band
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Upper_2Sigma"],
            mode="lines",
            name="¬±2œÉ (95%)",
            line=dict(width=0),
            showlegend=False,
            hoverinfo="skip",
        )
    )
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Lower_2Sigma"],
            mode="lines",
            name="95% Confidence",
            fill="tonexty",
            fillcolor=f"{ui.THEME['primary']}20",
            line=dict(width=0),
            hovertemplate="<b>95% Confidence</b><br>Upper: $%{y:.2f}<extra></extra>",
        )
    )

    # Confidence Band ¬±1œÉ (68% confidence) - Inner band
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Upper_1Sigma"],
            mode="lines",
            name="¬±1œÉ (68%)",
            line=dict(width=0),
            showlegend=False,
            hoverinfo="skip",
        )
    )
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Lower_1Sigma"],
            mode="lines",
            name="68% Confidence",
            fill="tonexty",
            fillcolor=f"{ui.THEME['primary']}40",
            line=dict(width=0),
            hovertemplate="<b>68% Confidence</b><br>Lower: $%{y:.2f}<extra></extra>",
        )
    )

    # Forecast Line (on top)
    fig.add_trace(
        go.Scatter(
            x=pred_df.index,
            y=pred_df["Predicted_Close"],
            mode="lines+markers",
            name="AI Forecast",
            line=dict(color=ui.THEME["accent"], width=3, dash="dash"),
            marker=dict(size=6, color=ui.THEME["accent"]),
            hovertemplate="<b>Forecast</b><br>Date: %{x}<br>Price: $%{y:.2f}<extra></extra>",
        )
    )

    fig.update_layout(
        template=plotly_template,
        title=f"AI Price Prediction with Confidence Intervals: {ticker}",
        xaxis_title="Date",
        yaxis_title="Price ($)",
        hovermode="x unified",
        height=550,
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
    )

    st.plotly_chart(fig, use_container_width=True)

    # Add explanation
    ui.glassmorphic_card(
        title="üìä Understanding Confidence Intervals",
        content="""
        **Confidence intervals** represent the uncertainty in our predictions:

        - **¬±1œÉ band (darker)**: 68% probability the actual price falls within this range
        - **¬±2œÉ band (lighter)**: 95% probability the actual price falls within this range

        The bands are calculated using the standard deviation of predictions from all 100
        decision trees in the Random Forest model. Wider bands indicate higher uncertainty.
        """
    )

    st.markdown("---")

    # 4. Rolling Backtest Section
    st.markdown("### Historical Model Performance (Rolling Backtest)")

    with st.spinner("Running rolling backtest on historical data..."):
        backtest_df = _run_rolling_backtest(hist_df, window_size=90, horizon=30)

    if backtest_df is not None and not backtest_df.empty:
        # Backtest metrics
        bt_mae = backtest_df["abs_error"].mean()
        bt_rmse = np.sqrt((backtest_df["error"] ** 2).mean())
        bt_r2 = 1 - (
            (backtest_df["error"] ** 2).sum()
            / ((backtest_df["actual_price"] - backtest_df["actual_price"].mean()) ** 2).sum()
        )

        # Directional accuracy for backtest
        actual_direction = np.diff(backtest_df["actual_price"].values) > 0
        pred_direction = np.diff(backtest_df["predicted_price"].values) > 0
        bt_directional = np.mean(actual_direction == pred_direction) * 100

        # Display backtest metrics
        bt1, bt2, bt3, bt4 = st.columns(4)
        with bt1:
            ui.animated_metric("Backtest MAE", f"${bt_mae:.2f}", icon="üìä")
        with bt2:
            ui.animated_metric("Backtest RMSE", f"${bt_rmse:.2f}", icon="üìà")
        with bt3:
            ui.animated_metric("Backtest R¬≤", f"{bt_r2:.1%}", icon="üéØ")
        with bt4:
            ui.animated_metric(
                "Backtest Directional",
                f"{bt_directional:.1f}%",
                icon="‚ÜïÔ∏è"
            )

        # Backtest visualization: Actual vs Predicted
        fig_backtest = go.Figure()

        fig_backtest.add_trace(
            go.Scatter(
                x=backtest_df["date"],
                y=backtest_df["actual_price"],
                mode="lines",
                name="Actual Price",
                line=dict(color=ui.THEME["success"], width=2),
                hovertemplate="<b>Actual</b><br>Date: %{x}<br>Price: $%{y:.2f}<extra></extra>",
            )
        )

        fig_backtest.add_trace(
            go.Scatter(
                x=backtest_df["date"],
                y=backtest_df["predicted_price"],
                mode="lines",
                name="Predicted Price",
                line=dict(color=ui.THEME["accent"], width=2, dash="dot"),
                hovertemplate="<b>Predicted</b><br>Date: %{x}<br>Price: $%{y:.2f}<extra></extra>",
            )
        )

        fig_backtest.update_layout(
            template=plotly_template,
            title=f"Backtest Results: Actual vs Predicted Prices ({ticker})",
            xaxis_title="Date",
            yaxis_title="Price ($)",
            hovermode="x unified",
            height=450,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        )

        st.plotly_chart(fig_backtest, use_container_width=True)

        # Error distribution histogram
        with st.expander("üìà View Error Distribution"):
            fig_error = go.Figure()

            fig_error.add_trace(
                go.Histogram(
                    x=backtest_df["error"],
                    nbinsx=30,
                    name="Prediction Errors",
                    marker=dict(color=ui.THEME["accent"], opacity=0.7),
                    hovertemplate="<b>Error Range</b><br>%{x:.2f}<br>Count: %{y}<extra></extra>",
                )
            )

            fig_error.update_layout(
                template=plotly_template,
                title="Distribution of Prediction Errors (Backtest)",
                xaxis_title="Error ($)",
                yaxis_title="Frequency",
                height=350,
                showlegend=False,
            )

            st.plotly_chart(fig_error, use_container_width=True)

            st.markdown(
                f"""
            **Error Statistics:**
            - Mean Error: ${backtest_df["error"].mean():.2f}
            - Median Error: ${backtest_df["error"].median():.2f}
            - Std Dev: ${backtest_df["error"].std():.2f}

            A centered distribution around $0 indicates unbiased predictions.
            """
            )
    else:
        st.info(
            "Insufficient historical data for backtest. "
            "Need at least 180 days of data to run rolling backtest."
        )

    st.markdown("---")

    # 5. Export Options
    _display_export_options(pred_df, backtest_df if backtest_df is not None else None, ticker)

    st.markdown("---")

    # 6. Model Explanation
    ui.glassmorphic_card(
        title="üß† How this model works",
        content="""
        This module uses a **Random Forest Regressor**
        (an ensemble of decision trees) trained on:
        - **Technical Indicators:** RSI, MACD, Signal Line,
          Moving Averages (20, 50).
        - **Lag Features:** Previous day prices to capture autocorrelation.
        - **Volume:** Trading volume trends.

        The model learns the complex non-linear relationships between
        these indicators and the next day's price. For the forecast,
        it projects these patterns forward.

        **Confidence Intervals:** Calculated using the standard deviation of
        predictions from all 100 trees in the ensemble. This provides a
        statistically rigorous measure of prediction uncertainty.
        """
    )


def _display_export_options(
    pred_df: pd.DataFrame, backtest_df: Optional[pd.DataFrame], ticker: str
) -> None:
    """
    Display export options for forecast results.

    Args:
        pred_df: DataFrame with forecast predictions and confidence intervals
        backtest_df: DataFrame with backtest results (optional)
        ticker: Stock ticker symbol
    """
    st.subheader("üì• Export Forecast Data")

    col1, col2 = st.columns(2)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    with col1:
        # Prepare forecast export data
        forecast_export = pred_df.copy()
        forecast_export.index.name = "Date"

        # CSV Export for Forecast
        csv_data = forecast_export.to_csv().encode("utf-8")
        st.download_button(
            label="üìÑ Download Forecast CSV",
            data=csv_data,
            file_name=f"smart_forecast_{ticker}_{timestamp}.csv",
            mime="text/csv",
            help="Download AI forecast predictions with confidence intervals",
        )

    with col2:
        # Excel Export with multiple sheets
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            # Forecast sheet
            forecast_export = pred_df.copy()
            forecast_export.index.name = "Date"
            forecast_export.to_excel(writer, sheet_name="Forecast")

            # Backtest sheet (if available)
            if backtest_df is not None and not backtest_df.empty:
                backtest_df.to_excel(writer, sheet_name="Backtest", index=False)

        excel_data = buffer.getvalue()

        st.download_button(
            label="üìä Download Excel Report",
            data=excel_data,
            file_name=f"smart_forecast_report_{ticker}_{timestamp}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            help="Download comprehensive forecast report with backtest results",
        )
