# =========================================================================
# NGINX Horizontal Scaling Configuration for Jorge's Real Estate AI Platform
# =========================================================================
# Enhanced for 10,000+ concurrent users with:
# - WebSocket and Socket.IO support
# - Frontend and API load balancing
# - Session affinity for WebSocket connections
# - Advanced caching and compression
# - Real-time metrics and monitoring
# =========================================================================

user nginx;
worker_processes auto;  # Auto-detect CPU cores
worker_rlimit_nofile 65535;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 8192;  # Increased for high concurrency
    use epoll;  # Efficient event model for Linux
    multi_accept on;  # Accept multiple connections at once
    accept_mutex off;  # Disable for better performance under high load
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # =========================================================================
    # Logging Configuration
    # =========================================================================
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    log_format websocket '$remote_addr - [$time_local] "$request" '
                        'status=$status bytes=$bytes_sent '
                        'upgrade="$http_upgrade" connection="$http_connection" '
                        'upstream_addr=$upstream_addr '
                        'upstream_time=$upstream_response_time '
                        'session_id=$cookie_sessionid';

    access_log /var/log/nginx/access.log main;
    access_log /var/log/nginx/websocket.log websocket;

    # =========================================================================
    # Performance Optimizations for High Concurrency
    # =========================================================================
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 75;
    keepalive_requests 1000;  # Increased for persistent connections
    types_hash_max_size 2048;
    server_tokens off;  # Hide nginx version

    # Enhanced buffer sizes for WebSocket and large payloads
    client_body_buffer_size 256k;
    client_max_body_size 50m;  # Increased for file uploads
    client_header_buffer_size 2k;
    large_client_header_buffers 8 32k;
    output_buffers 2 64k;
    postpone_output 1460;

    # Optimized timeouts for WebSocket connections
    client_body_timeout 20;
    client_header_timeout 20;
    send_timeout 30;
    reset_timedout_connection on;

    # Proxy timeouts for long-running requests
    proxy_connect_timeout 10s;
    proxy_send_timeout 300s;    # Extended for ML operations
    proxy_read_timeout 300s;
    proxy_buffering on;
    proxy_buffer_size 8k;
    proxy_buffers 16 8k;
    proxy_busy_buffers_size 16k;

    # =========================================================================
    # Advanced Gzip Compression
    # =========================================================================
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_min_length 1000;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/rss+xml
        application/atom+xml
        font/truetype
        font/opentype
        application/vnd.ms-fontobject
        image/svg+xml
        application/wasm;
    gzip_disable "MSIE [1-6]\.";

    # =========================================================================
    # Rate Limiting for Scalability
    # =========================================================================
    # General web traffic
    limit_req_zone $binary_remote_addr zone=general:20m rate=200r/s;

    # API requests
    limit_req_zone $binary_remote_addr zone=api:20m rate=100r/s;

    # WebSocket connections
    limit_req_zone $binary_remote_addr zone=websocket:10m rate=50r/s;

    # Resource-intensive ML operations
    limit_req_zone $binary_remote_addr zone=ml_operations:10m rate=20r/s;

    # Connection limits
    limit_conn_zone $binary_remote_addr zone=addr:10m;
    limit_conn_zone $server_name zone=perserver:10m;

    # Rate limit status
    limit_req_status 429;
    limit_conn_status 429;

    # =========================================================================
    # Advanced Cache Configuration
    # =========================================================================
    proxy_cache_path /var/cache/nginx/api_cache
                     levels=1:2
                     keys_zone=api_cache:200m
                     max_size=2g
                     inactive=60m
                     use_temp_path=off;

    proxy_cache_path /var/cache/nginx/static_cache
                     levels=1:2
                     keys_zone=static_cache:100m
                     max_size=1g
                     inactive=30d
                     use_temp_path=off;

    proxy_cache_path /var/cache/nginx/frontend_cache
                     levels=1:2
                     keys_zone=frontend_cache:100m
                     max_size=1g
                     inactive=1h
                     use_temp_path=off;

    # Enhanced cache key with session affinity
    proxy_cache_key "$scheme$request_method$host$request_uri$http_authorization";

    # =========================================================================
    # Upstream Backend Servers (API Instances with Session Affinity)
    # =========================================================================
    upstream jorge_api_backend {
        # Use ip_hash for session affinity (important for WebSocket connections)
        ip_hash;

        # FastAPI instances with health checks
        server api-instance-1:8000 max_fails=3 fail_timeout=30s weight=1;
        server api-instance-2:8000 max_fails=3 fail_timeout=30s weight=1;
        server api-instance-3:8000 max_fails=3 fail_timeout=30s weight=1;
        server api-instance-4:8000 max_fails=3 fail_timeout=30s weight=1;
        server api-instance-5:8000 max_fails=3 fail_timeout=30s weight=1;

        # Enhanced keepalive settings
        keepalive 64;
        keepalive_requests 1000;
        keepalive_timeout 120s;
    }

    # =========================================================================
    # Upstream Frontend Servers (Next.js Instances)
    # =========================================================================
    upstream jorge_frontend_backend {
        # Round-robin for static content
        least_conn;

        # Next.js instances
        server frontend-1:3000 max_fails=2 fail_timeout=20s weight=1;
        server frontend-2:3000 max_fails=2 fail_timeout=20s weight=1;
        server frontend-3:3000 max_fails=2 fail_timeout=20s weight=1;

        # Keepalive for frontend connections
        keepalive 32;
        keepalive_requests 500;
        keepalive_timeout 60s;
    }

    # =========================================================================
    # Main Server Block
    # =========================================================================
    server {
        listen 80 default_server;
        listen [::]:80 default_server;
        server_name _;

        # Connection limits
        limit_conn addr 20;  # Increased for high concurrency
        limit_conn perserver 5000;  # Server-wide limit

        # =====================================================================
        # Health Check Endpoint (No rate limiting)
        # =====================================================================
        location = /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
            add_header X-Jorge-Platform "Scaling-Ready";
        }

        # =====================================================================
        # Socket.IO WebSocket Endpoints with Session Affinity
        # =====================================================================
        location /socket.io/ {
            # Rate limiting for WebSocket connections
            limit_req zone=websocket burst=10 nodelay;

            # Proxy to API backend with WebSocket support
            proxy_pass http://jorge_api_backend;
            proxy_http_version 1.1;

            # WebSocket upgrade headers
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";

            # Standard proxy headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket-specific settings
            proxy_buffering off;
            proxy_cache off;

            # Extended timeouts for persistent connections
            proxy_connect_timeout 10s;
            proxy_send_timeout 86400s;    # 24 hours for persistent WebSocket
            proxy_read_timeout 86400s;    # 24 hours for persistent WebSocket

            # Add WebSocket headers
            add_header X-WebSocket-Server $upstream_addr;
            add_header X-Connection-Type "websocket";
        }

        # =====================================================================
        # Native WebSocket Endpoints (/api/websocket/)
        # =====================================================================
        location /api/websocket/ {
            # Rate limiting
            limit_req zone=websocket burst=10 nodelay;

            # Proxy with WebSocket support
            proxy_pass http://jorge_api_backend;
            proxy_http_version 1.1;

            # WebSocket upgrade headers
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;

            # Standard headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;

            # WebSocket optimizations
            proxy_buffering off;
            proxy_cache off;
            proxy_connect_timeout 10s;
            proxy_send_timeout 86400s;
            proxy_read_timeout 86400s;
        }

        # =====================================================================
        # API Endpoints (Enhanced for Horizontal Scaling)
        # =====================================================================
        location /api/ {
            # Rate limiting with burst for API calls
            limit_req zone=api burst=50 nodelay;

            # Proxy settings
            proxy_pass http://jorge_api_backend;
            proxy_http_version 1.1;

            # Headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection "";

            # Enhanced caching strategy
            proxy_cache api_cache;
            proxy_cache_methods GET HEAD;
            proxy_cache_valid 200 5m;    # Increased cache time
            proxy_cache_valid 404 1m;
            proxy_cache_valid 500 502 503 504 30s;
            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;
            proxy_cache_background_update on;
            proxy_cache_lock on;
            proxy_cache_lock_timeout 5s;

            # Cache bypass for authenticated requests
            proxy_cache_bypass $http_authorization $arg_nocache;
            proxy_no_cache $http_authorization;

            # Performance headers
            add_header X-Cache-Status $upstream_cache_status;
            add_header X-Response-Time $request_time;
            add_header X-Upstream-Server $upstream_addr;
            add_header X-Jorge-Instance $upstream_http_x_instance_id;
        }

        # =====================================================================
        # ML Operations with Extended Timeouts
        # =====================================================================
        location ~ /api/(golden-leads|predictive|ml-scoring|intent-decoder)/ {
            # Stricter rate limiting for ML operations
            limit_req zone=ml_operations burst=10 nodelay;

            proxy_pass http://jorge_api_backend;
            proxy_http_version 1.1;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection "";

            # Extended timeouts for ML processing
            proxy_connect_timeout 10s;
            proxy_send_timeout 300s;  # 5 minutes for complex ML operations
            proxy_read_timeout 300s;

            # No caching for ML operations (real-time data)
            proxy_cache off;

            add_header X-Response-Time $request_time;
            add_header X-ML-Processing "true";
        }

        # =====================================================================
        # Frontend Application (Next.js)
        # =====================================================================
        location / {
            # Rate limiting for frontend requests
            limit_req zone=general burst=100 nodelay;

            # Try static files first, then proxy to Next.js
            proxy_pass http://jorge_frontend_backend;
            proxy_http_version 1.1;

            # Standard proxy headers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection "";

            # Frontend caching
            proxy_cache frontend_cache;
            proxy_cache_valid 200 10m;
            proxy_cache_valid 404 1m;
            proxy_cache_use_stale error timeout updating;
            proxy_cache_background_update on;

            # Frontend-specific headers
            add_header X-Frame-Options "SAMEORIGIN";
            add_header X-Content-Type-Options "nosniff";
            add_header X-Cache-Status $upstream_cache_status;
        }

        # =====================================================================
        # Static Assets with Aggressive Caching
        # =====================================================================
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            proxy_pass http://jorge_frontend_backend;

            # Aggressive caching for static assets
            proxy_cache static_cache;
            proxy_cache_valid 200 30d;
            proxy_cache_valid 404 1m;

            # Long-term browser caching
            expires 30d;
            add_header Cache-Control "public, no-transform";
            add_header X-Cache-Status $upstream_cache_status;

            # Compression for text-based assets
            gzip_static on;
        }

        # =====================================================================
        # Error Pages
        # =====================================================================
        error_page 429 /429.json;
        location = /429.json {
            internal;
            default_type application/json;
            return 429 '{"error": "Rate limit exceeded", "message": "Too many requests. Please try again later.", "scaling_info": {"max_connections": 10000, "current_load": "high"}}';
        }

        error_page 502 503 504 /50x.json;
        location = /50x.json {
            internal;
            default_type application/json;
            return 503 '{"error": "Service temporarily unavailable", "message": "Jorge platform is scaling up. Please try again in a moment."}';
        }
    }

    # =========================================================================
    # WebSocket Connection Upgrade Map
    # =========================================================================
    map $http_upgrade $connection_upgrade {
        default upgrade;
        ''      close;
    }

    # =========================================================================
    # Monitoring and Metrics Endpoint
    # =========================================================================
    server {
        listen 8080;
        server_name localhost;

        location /nginx_status {
            stub_status on;
            access_log off;
            allow 172.21.0.0/24;  # Internal network only
            deny all;
        }

        location /nginx_metrics {
            access_log off;
            allow 172.21.0.0/24;  # Internal network only
            deny all;
            default_type application/json;
            return 200 '{"status":"healthy","workers":5,"frontend_instances":3,"cache_size":"2GB","websocket_connections":"active"}';
        }
    }
}