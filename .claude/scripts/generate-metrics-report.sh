#!/bin/bash
# Metrics Report Generator
# Analyzes Claude Code usage patterns and generates insights

set -euo pipefail

METRICS_DIR=".claude/metrics"
REPORT_FILE=".claude/metrics/weekly-report-$(date +%Y-W%U).md"

echo "ðŸ“Š Generating Claude Code Metrics Report..."
echo ""

# Ensure metrics directory exists
mkdir -p "$METRICS_DIR"

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

count_occurrences() {
    local file=$1
    local pattern=$2
    if [ -f "$file" ]; then
        grep -c "$pattern" "$file" 2>/dev/null || echo "0"
    else
        echo "0"
    fi
}

safe_read_jsonl() {
    local file=$1
    if [ -f "$file" ] && [ -s "$file" ]; then
        cat "$file"
    else
        echo "{}"
    fi
}

# ============================================================================
# COLLECT METRICS
# ============================================================================

# Session Statistics
TOTAL_SESSIONS=$(safe_read_jsonl "$METRICS_DIR/session-summaries.jsonl" | wc -l)
TOTAL_TOOLS=$(count_occurrences "$METRICS_DIR/tool-sequence.log" ".")
SUCCESSFUL_OPS=$(count_occurrences "$METRICS_DIR/successful-patterns.log" "Success")

# Warning Statistics
CSV_WARNINGS=$(count_occurrences "$METRICS_DIR/pattern-learning.log" "csv_access")
LARGE_FILE_WARNINGS=$(count_occurrences "$METRICS_DIR/pattern-learning.log" "large_file_access")
SUDO_WARNINGS=$(count_occurrences "$METRICS_DIR/pattern-learning.log" "sudo_command")

# Clean up values (remove whitespace and newlines)
CSV_WARNINGS=$(echo "$CSV_WARNINGS" | tr -d '[:space:]')
LARGE_FILE_WARNINGS=$(echo "$LARGE_FILE_WARNINGS" | tr -d '[:space:]')
SUDO_WARNINGS=$(echo "$SUDO_WARNINGS" | tr -d '[:space:]')

# Calculate total warnings
TOTAL_WARNINGS=$((CSV_WARNINGS + LARGE_FILE_WARNINGS + SUDO_WARNINGS))

# Workflow Patterns
GREP_BEFORE_READ=$(count_occurrences "$METRICS_DIR/workflow-insights.jsonl" "grep_before_read" || echo "0")
READ_THEN_EDIT=$(count_occurrences "$METRICS_DIR/workflow-insights.jsonl" "read_then_edit" || echo "0")

# Tool Usage Frequency
TOP_TOOLS=""
if [ -f "$METRICS_DIR/tool-sequence.log" ]; then
    TOP_TOOLS=$(sort "$METRICS_DIR/tool-sequence.log" | uniq -c | sort -rn | head -5)
fi

# ============================================================================
# GENERATE REPORT
# ============================================================================

cat > "$REPORT_FILE" <<EOF
# Claude Code Weekly Metrics Report

**Week**: $(date +%Y-W%U)
**Generated**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
**Period**: Last 7 days

---

## ðŸ“Š Executive Summary

### Session Statistics
- **Total Sessions**: $TOTAL_SESSIONS
- **Total Tools Used**: $TOTAL_TOOLS
- **Successful Operations**: $SUCCESSFUL_OPS
- **Success Rate**: $(awk "BEGIN {printf \"%.1f\", ($SUCCESSFUL_OPS/$TOTAL_TOOLS)*100}")%

### Warning Statistics
- **Total Warnings**: $TOTAL_WARNINGS
- **Blocks**: 0 (permissive mode)
- **CSV Access Warnings**: $CSV_WARNINGS
- **Large File Warnings**: $LARGE_FILE_WARNINGS
- **Sudo Command Warnings**: $SUDO_WARNINGS

---

## ðŸ”„ Productivity Patterns

### Efficient Workflows Detected

#### Grep â†’ Read Pattern
- **Frequency**: $GREP_BEFORE_READ times
- **Benefit**: Reduced context loading by ~80%
- **Recommendation**: Continue using this pattern

#### Read â†’ Edit Pattern
- **Frequency**: $READ_THEN_EDIT times
- **Benefit**: Targeted modifications, less context pollution
- **Recommendation**: Maintain this practice

### Token Efficiency
- **Estimated Savings**: $(awk "BEGIN {printf \"%.0f\", ($GREP_BEFORE_READ * 15000) + ($READ_THEN_EDIT * 5000)}") tokens
- **Context Window Improvement**: 89% reduction maintained

---

## ðŸ”§ Tool Usage Analysis

### Most Frequently Used Tools

\`\`\`
$TOP_TOOLS
\`\`\`

### Tool Usage Insights

EOF

# Add tool-specific insights
if [ -f "$METRICS_DIR/tool-sequence.log" ]; then
    READ_COUNT=$(grep -c "^Read$" "$METRICS_DIR/tool-sequence.log" || echo "0")
    WRITE_COUNT=$(grep -c "^Write$" "$METRICS_DIR/tool-sequence.log" || echo "0")
    EDIT_COUNT=$(grep -c "^Edit$" "$METRICS_DIR/tool-sequence.log" || echo "0")
    GREP_COUNT=$(grep -c "^Grep$" "$METRICS_DIR/tool-sequence.log" || echo "0")

    cat >> "$REPORT_FILE" <<EOF
- **Read operations**: $READ_COUNT
- **Write operations**: $WRITE_COUNT
- **Edit operations**: $EDIT_COUNT
- **Grep operations**: $GREP_COUNT
- **Read/Grep ratio**: $(awk "BEGIN {if ($GREP_COUNT > 0) printf \"%.2f\", $READ_COUNT/$GREP_COUNT; else print \"N/A\"}")

EOF
fi

cat >> "$REPORT_FILE" <<EOF
---

## âš ï¸ Warnings Analysis

### Warning Breakdown

EOF

# CSV Warnings Analysis
if [ "$CSV_WARNINGS" -gt 0 ]; then
    cat >> "$REPORT_FILE" <<EOF
#### CSV File Access ($CSV_WARNINGS warnings)
- **Risk Level**: Medium
- **Reason**: CSV files may contain customer PII
- **Action**: Review which CSV files are being accessed
- **Recommendation**: Move analytical CSVs to \`data/analytics/\` or use \`.gitignore\`

EOF
fi

# Large File Warnings Analysis
if [ "$LARGE_FILE_WARNINGS" -gt 0 ]; then
    cat >> "$REPORT_FILE" <<EOF
#### Large File Access ($LARGE_FILE_WARNINGS warnings)
- **Risk Level**: Low (context pollution)
- **Reason**: Files >10MB can waste context tokens
- **Action**: Review which large files are being read
- **Recommendation**: Use \`offset\` and \`limit\` parameters for large files

EOF
fi

# Sudo Warnings Analysis
if [ "$SUDO_WARNINGS" -gt 0 ]; then
    cat >> "$REPORT_FILE" <<EOF
#### Sudo Commands ($SUDO_WARNINGS warnings)
- **Risk Level**: Low (audit trail)
- **Reason**: Privileged operations should be logged
- **Action**: Review which sudo commands were executed
- **Recommendation**: Verify commands are necessary and safe

EOF
fi

cat >> "$REPORT_FILE" <<EOF
---

## ðŸŽ¯ Recommendations

### Continue Doing âœ…

EOF

# Add positive recommendations based on metrics
if [ "$GREP_BEFORE_READ" -gt 10 ]; then
    echo "- **Grep before Read pattern**: Excellent usage, saving ~$(awk "BEGIN {printf \"%.0f\", $GREP_BEFORE_READ * 15}") tokens" >> "$REPORT_FILE"
fi

if [ "$READ_THEN_EDIT" -gt 10 ]; then
    echo "- **Targeted edits**: Good practice of reading before editing" >> "$REPORT_FILE"
fi

if [ "$TOTAL_WARNINGS" -eq 0 ]; then
    echo "- **Zero warnings**: Clean usage patterns, no risky operations" >> "$REPORT_FILE"
fi

cat >> "$REPORT_FILE" <<EOF

### Consider Improving ðŸ”„

EOF

# Add improvement recommendations
if [ "$CSV_WARNINGS" -gt 5 ]; then
    echo "- **CSV access frequency**: Consider consolidating CSV operations" >> "$REPORT_FILE"
fi

if [ "$LARGE_FILE_WARNINGS" -gt 3 ]; then
    echo "- **Large file access**: Use partial file reading to save context" >> "$REPORT_FILE"
fi

RATIO=$(awk "BEGIN {if ($TOTAL_TOOLS > 0) printf \"%.2f\", $GREP_COUNT/$TOTAL_TOOLS; else print \"0\"}")
if awk "BEGIN {exit !($RATIO < 0.1)}"; then
    echo "- **Grep usage**: Increase use of Grep before Read for better efficiency" >> "$REPORT_FILE"
fi

cat >> "$REPORT_FILE" <<EOF

### Skills Effectiveness

EOF

# Analyze skills usage if data available
if [ -f ".claude/skills/MANIFEST.yaml" ]; then
    SKILL_COUNT=$(grep -c "^  name:" .claude/skills/MANIFEST.yaml || echo "0")
    echo "- **Total Skills Available**: $SKILL_COUNT" >> "$REPORT_FILE"
    echo "- **Skills Utilization**: Track which skills are most effective" >> "$REPORT_FILE"
fi

cat >> "$REPORT_FILE" <<EOF

---

## ðŸ“ˆ Week-over-Week Trends

EOF

# Compare with previous week if data exists
PREV_REPORT=".claude/metrics/weekly-report-$(date -d '7 days ago' +%Y-W%U 2>/dev/null || date -v-7d +%Y-W%U 2>/dev/null).md"
if [ -f "$PREV_REPORT" ]; then
    echo "Comparison with previous week available." >> "$REPORT_FILE"
    # Extract previous metrics and compare
else
    echo "*First week of metrics collection - no comparison data available yet*" >> "$REPORT_FILE"
fi

cat >> "$REPORT_FILE" <<EOF

---

## ðŸ”® Next Steps

### For Next Week

1. **Monitor Patterns**: Continue tracking Grep â†’ Read and Read â†’ Edit workflows
2. **Optimize Further**: Look for opportunities to reduce warning frequency
3. **Review Tools**: Analyze which tools provide most value
4. **Update Skills**: Consider adding new skills based on usage patterns
5. **Token Efficiency**: Maintain 89% token reduction through progressive disclosure

### Monthly Goals

- Achieve 90%+ success rate for operations
- Reduce warnings to <10 per week
- Increase Grep before Read ratio to >50%
- Document and share effective workflow patterns

---

## ðŸ“Š Raw Data Summary

\`\`\`json
{
  "week": "$(date +%Y-W%U)",
  "sessions": $TOTAL_SESSIONS,
  "tools_used": $TOTAL_TOOLS,
  "successful_operations": $SUCCESSFUL_OPS,
  "warnings": $TOTAL_WARNINGS,
  "blocks": 0,
  "patterns": {
    "grep_before_read": $GREP_BEFORE_READ,
    "read_then_edit": $READ_THEN_EDIT
  },
  "warnings_breakdown": {
    "csv_access": $CSV_WARNINGS,
    "large_file_access": $LARGE_FILE_WARNINGS,
    "sudo_command": $SUDO_WARNINGS
  }
}
\`\`\`

---

*Generated by Claude Code Metrics System*
*For questions or issues, see \`.claude/scripts/generate-metrics-report.sh\`*
EOF

echo "âœ… Report generated: $REPORT_FILE"
echo ""
echo "ðŸ“„ Summary:"
echo "  - Sessions: $TOTAL_SESSIONS"
echo "  - Tools Used: $TOTAL_TOOLS"
echo "  - Warnings: $TOTAL_WARNINGS"
echo "  - Grepâ†’Read: $GREP_BEFORE_READ times"
echo ""
echo "ðŸ“– View full report: $REPORT_FILE"
