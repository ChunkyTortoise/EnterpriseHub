# Enterprise-Grade Hooks System for EnterpriseHub
# Version: 1.0.0
# Last Updated: 2026-01-16
#
# Architecture: 5-Layer Security Defense System
# - Layer 1: Command-based instant blocks (secrets, path traversal)
# - Layer 2: Prompt-based pattern analysis (SQL injection, secrets in content)
# - Layer 3: GHL-specific validation (API key handling, rate limiting)
# - Layer 4: Audit logging (SOC2/HIPAA compliance)
# - Layer 5: Cost control (rate limiting for subagents)
#
# Performance Targets:
# - Fast validation: <500ms (Haiku model)
# - Complex validation: <2s (Sonnet model)
# - Non-blocking PostToolUse: async execution

# =============================================================================
# LAYER 1: INSTANT SECURITY BLOCKS (Command-Based) - AUTO-ACCEPT MODE
# =============================================================================
# Fast, deterministic checks that warn about dangerous operations
# Model: None (pattern matching only)
# Response Time: <10ms
# Note: All blocks disabled for auto-accept workflow

PreToolUse:
  # Block 1.1: Secrets Protection (DISABLED for auto-accept)
  - name: block-secrets-in-files
    description: "Prevent reading or writing files containing secrets"
    matcher:
      toolName: ["Read", "Write", "Edit"]
      args:
        file_path:
          pattern: "^(\\.env(\\.local|\\.production)?|secrets/.*|.*\\.(key|pem|crt))$"
    block: false  # DISABLED for auto-accept
    message: |
      ⚠️  WARNING: Accessing secrets or credential files.

      Files containing secrets:
      - .env, .env.local, .env.production
      - secrets/** directory
      - *.key, *.pem, *.crt files

      Ensure proper security practices.

  # Block 1.2: Path Traversal Prevention (DISABLED for auto-accept)
  - name: block-path-traversal
    description: "Prevent directory traversal attacks"
    matcher:
      toolName: ["Read", "Write", "Edit", "Bash"]
      args:
        anyOf:
          - file_path:
              pattern: "\\.\\./"
          - command:
              pattern: "\\.\\./"
    block: false  # DISABLED for auto-accept
    message: |
      ⚠️  WARNING: Path traversal detected (..\/).

      Security notice: Accessing parent directories.
      Using absolute paths is recommended.

  # Block 1.3: Destructive Command Prevention
  - name: block-destructive-bash
    description: "Block dangerous bash commands"
    matcher:
      toolName: "Bash"
      args:
        command:
          anyOf:
            - pattern: "rm\\s+-rf\\s+/"
            - pattern: "rm\\s+-rf\\s+\\.git"
            - pattern: "sudo\\s+"
            - pattern: "chmod\\s+777"
            - pattern: "DROP\\s+DATABASE"
            - pattern: "TRUNCATE\\s+TABLE.*WHERE\\s+1\\s*=\\s*1"
            - pattern: "DELETE\\s+FROM.*WHERE\\s+1\\s*=\\s*1"
            - pattern: ">\\s*/dev/sd[a-z]"
    block: false # Changed to false for auto-accept workflow
    message: |
      ⚠️  WARNING: Destructive command detected.
      Proceeding with caution...

  # Block 1.4: PII/Customer Data Protection (DISABLED for auto-accept)
  - name: block-customer-data
    description: "Prevent access to analytics data with PII"
    matcher:
      toolName: ["Read", "Write", "Edit"]
      args:
        file_path:
          anyOf:
            - pattern: "^data/analytics/.*"
            - pattern: ".*\\.csv$"
            - pattern: ".*customer.*data.*"
    block: false  # DISABLED for auto-accept
    message: |
      ⚠️  WARNING: Customer data and PII access detected.

      Files that may contain PII:
      - Customer analytics (data/analytics/**)
      - CSV files with customer data (*.csv)
      - Customer database exports

      Ensure proper data handling practices.

# =============================================================================
# LAYER 2: CONTENT ANALYSIS (Prompt-Based)
# =============================================================================
# Deep content inspection for patterns that can't be caught by simple matching
# Model: claude-3-5-haiku-20241022 (fast, cost-effective)
# Response Time: <500ms

PreToolUse:
  # Block 2.1: Secrets in Content Detection
  - name: detect-secrets-in-content
    description: "AI-powered detection of secrets in file content"
    matcher:
      toolName: ["Write", "Edit"]
    prompt: |
      Analyze this code/content for potential secrets or credentials:

      File: {file_path}
      Content: {new_string or content}

      Check for:
      1. API keys (sk_*, pk_*, Bearer tokens)
      2. Database credentials (postgresql://, mongodb://)
      3. Private keys (BEGIN PRIVATE KEY)
      4. OAuth tokens
      5. AWS/GCP credentials
      6. Hardcoded passwords

      Respond with JSON:
      {
        "has_secrets": true/false,
        "violations": [
          {"type": "api_key", "line": 42, "pattern": "sk_live_..."}
        ],
        "severity": "critical|high|medium|low",
        "recommendation": "Use environment variables"
      }

      Block if severity is "critical" or "high".
    model: claude-3-5-haiku-20241022
    block: false  # Permissive mode - warn only
    message: |
      ⚠️  WARNING: Potential secrets detected in content.

      {violations}

      Security best practices:
      - Use environment variables (.env.example for docs)
      - Store credentials in secure vault (AWS Secrets Manager)
      - Never commit secrets to git history

      Recommendation: {recommendation}

  # Block 2.2: SQL Injection Detection
  - name: detect-sql-injection
    description: "AI-powered SQL injection pattern detection"
    matcher:
      toolName: ["Write", "Edit"]
      args:
        file_path:
          pattern: ".*\\.(py|js|ts)$"
    prompt: |
      Analyze this code for SQL injection vulnerabilities:

      File: {file_path}
      Code: {new_string or content}

      Check for:
      1. String concatenation in SQL queries
      2. Unparameterized user input in queries
      3. Missing input sanitization
      4. Raw SQL execution without ORM
      5. Dynamic query construction vulnerabilities

      Respond with JSON:
      {
        "vulnerable": true/false,
        "findings": [
          {
            "line": 42,
            "issue": "String concatenation in SQL",
            "example": "query = f'SELECT * FROM users WHERE id={user_id}'",
            "fix": "Use parameterized query: query = 'SELECT * FROM users WHERE id=%s', params=[user_id]"
          }
        ],
        "risk_level": "critical|high|medium|low"
      }

      Block if risk_level is "critical".
    model: claude-3-5-haiku-20241022
    block: false  # Permissive mode - warn only
    message: |
      ⚠️  WARNING: SQL injection vulnerability detected.

      {findings}

      Fix recommendations:
      - Use Prisma/SQLAlchemy parameterized queries
      - Validate and sanitize all user input
      - Use ORM instead of raw SQL where possible

# =============================================================================
# LAYER 3: GHL-SPECIFIC VALIDATION
# =============================================================================
# Business logic validation for GoHighLevel API integration
# Model: claude-3-5-haiku-20241022 (fast validation)

PreToolUse:
  # Block 3.1: GHL API Key Handling
  - name: validate-ghl-api-usage
    description: "Ensure proper GHL API key handling"
    matcher:
      toolName: ["Write", "Edit"]
      args:
        file_path:
          pattern: "ghl_real_estate_ai/.*"
    prompt: |
      Validate GoHighLevel API integration code:

      File: {file_path}
      Code: {new_string or content}

      Check for:
      1. API key stored in environment variables (not hardcoded)
      2. Rate limiting implementation (429 handling)
      3. Proper error handling for GHL API errors
      4. Webhook signature verification
      5. OAuth token refresh logic

      GHL-specific requirements:
      - API calls must include rate limit backoff
      - Webhook endpoints must verify signatures
      - Location IDs must not be hardcoded

      Respond with JSON:
      {
        "compliant": true/false,
        "violations": [
          {
            "issue": "Hardcoded location ID",
            "line": 42,
            "fix": "Load from config: location_id = os.getenv('GHL_LOCATION_ID')"
          }
        ],
        "severity": "high|medium|low"
      }

      Block if severity is "high".
    model: claude-3-5-haiku-20241022
    block: false  # Permissive mode - warn only
    message: |
      ⚠️  GHL API Integration Issue

      {violations}

      GoHighLevel best practices:
      - Store credentials in environment variables
      - Implement exponential backoff for rate limits
      - Verify webhook signatures
      - Use location-specific configurations

  # Block 3.2: Rate Limiting Validation
  - name: enforce-ghl-rate-limiting
    description: "Ensure GHL API calls include rate limiting"
    matcher:
      toolName: ["Write", "Edit"]
      args:
        file_path:
          pattern: "ghl_real_estate_ai/.*ghl.*\\.py$"
    prompt: |
      Analyze this GHL API integration for rate limiting:

      File: {file_path}
      Code: {new_string or content}

      GoHighLevel rate limits:
      - 100 requests per 60 seconds (standard)
      - 1000 requests per 60 seconds (enterprise)

      Required patterns:
      1. Redis-based rate limit tracking
      2. Exponential backoff on 429 responses
      3. Request queue management
      4. Circuit breaker for repeated failures

      Respond with JSON:
      {
        "has_rate_limiting": true/false,
        "missing_features": ["backoff", "circuit_breaker"],
        "recommendation": "Add @rate_limit(100, 60) decorator"
      }

      Warn if rate limiting is missing.
    model: claude-3-5-haiku-20241022
    block: false  # Warn only, don't block
    message: |
      ⚠️  Missing Rate Limiting for GHL API

      {missing_features}

      Recommendation: {recommendation}

      Add rate limiting to prevent API quota exhaustion:
      - Use cache_service.py rate limit decorators
      - Implement exponential backoff on 429
      - Track API usage in Redis

# =============================================================================
# LAYER 4: AUDIT LOGGING (PostToolUse)
# =============================================================================
# Compliance logging for SOC2/HIPAA requirements
# Model: None (direct logging, no AI)
# Execution: Async (non-blocking)

PostToolUse:
  # Log 4.1: All File Operations
  - name: audit-file-operations
    description: "Log all file writes/edits for compliance"
    matcher:
      toolName: ["Write", "Edit"]
    async: true  # Non-blocking
    action:
      type: log
      destination: ".claude/metrics/audit-log.jsonl"
      format: |
        {
          "timestamp": "{timestamp}",
          "tool": "{tool_name}",
          "file": "{file_path}",
          "user": "{user}",
          "operation": "{operation}",
          "success": {success},
          "lines_changed": {lines_changed}
        }

  # Log 4.2: Bash Command Execution
  - name: audit-bash-commands
    description: "Log all bash commands for security review"
    matcher:
      toolName: "Bash"
    async: true
    action:
      type: log
      destination: ".claude/metrics/bash-audit.jsonl"
      format: |
        {
          "timestamp": "{timestamp}",
          "command": "{command}",
          "user": "{user}",
          "exit_code": {exit_code},
          "output_length": {output_length}
        }

  # Log 4.3: GHL API Interactions
  - name: audit-ghl-api-calls
    description: "Track GHL API usage for rate limiting analysis"
    matcher:
      toolName: ["Write", "Edit"]
      args:
        file_path:
          pattern: "ghl_real_estate_ai/.*"
    async: true
    action:
      type: log
      destination: ".claude/metrics/ghl-api-usage.jsonl"
      format: |
        {
          "timestamp": "{timestamp}",
          "file": "{file_path}",
          "operation": "{operation}",
          "user": "{user}"
        }

# =============================================================================
# LAYER 5: COST CONTROL & RESOURCE MANAGEMENT
# =============================================================================
# Prevent excessive AI costs and resource usage
# Model: None (threshold-based)

PostToolUse:
  # Control 5.1: Subagent Rate Limiting
  - name: rate-limit-subagents
    description: "Prevent excessive subagent spawning"
    matcher:
      toolName: "Task"  # Subagent creation
    action:
      type: rate_limit
      limit: 10
      window: 300  # 10 subagents per 5 minutes
      storage: ".claude/metrics/rate-limits.json"
    message: |
      ⚠️  Subagent rate limit reached (10 per 5 minutes).

      Consider:
      - Batching similar tasks
      - Using parallel execution instead of sequential
      - Optimizing task granularity

      Current usage tracked in .claude/metrics/rate-limits.json

  # Control 5.2: Automated Metrics Collection (ENHANCED)
  - name: track-tool-metrics-auto
    description: "Real-time skill usage, token efficiency, and performance tracking"
    matcher:
      toolName: "*"  # Capture ALL tools for comprehensive analytics
    async: true  # Non-blocking - preserves performance
    timeout_ms: 3000  # Reasonable timeout for async metric processing
    action:
      type: script
      path: ".claude/scripts/update-skill-metrics.py"
      args:
        - "--auto"  # Enable automated collection mode
        - "--tool={tool_name}"
        - "--success={success}"
        - "--duration={duration_ms}"
        - "--timestamp={timestamp}"
        - "--operation={operation}"  # What the tool accomplished
        - "--context-tokens={context_tokens}"  # Tokens used from context
        - "--result-tokens={result_tokens}"  # Result tokens if applicable
        - "--skill-tag={skill_tag}"  # If tool was invoked via skill
    priority: 100  # Lower priority than security hooks (which are priority 1)
    retry_on_timeout: true  # Retry once if metrics collection times out
    error_handling: silent  # Never interrupt workflow for metrics collection
  
  # Additional: Skill-Specific Metrics Collection
  - name: track-skill-invocation
    description: "Track skill invocations for skill effectiveness analysis"
    matcher:
      toolName: "Skill"
    async: true
    timeout_ms: 2000
    action:
      type: script
      path: ".claude/scripts/update-skill-metrics.py"
      args:
        - "--auto"
        - "--tool=Skill"
        - "--skill-name={skill_name}"
        - "--skill-outcome={outcome}"
        - "--tokens-saved={tokens_saved}"
        - "--duration={duration_ms}"
    priority: 100
    error_handling: silent

# =============================================================================
# SKILL-SPECIFIC HOOKS
# =============================================================================
# Validation hooks that trigger based on skill usage

PostToolUse:
  # Skill Hook 1: TDD Compliance
  - name: validate-tdd-workflow
    description: "Ensure tests exist before implementation"
    matcher:
      toolName: ["Write", "Edit"]
      args:
        file_path:
          pattern: ".*\\.(py|ts|js)$"
          not_pattern: ".*\\.test\\.(py|ts|js)$"
    prompt: |
      Check if corresponding test file exists:

      Implementation file: {file_path}
      Expected test file: {file_path with .test. inserted}

      TDD requirement: Test must exist before implementation.

      Respond with JSON:
      {
        "test_exists": true/false,
        "test_path": "path/to/test.test.py",
        "recommendation": "Create test first following RED-GREEN-REFACTOR"
      }
    model: claude-3-5-haiku-20241022
    async: true  # Don't block, but warn
    message: |
      ⚠️  TDD Workflow Violation

      Test file not found: {test_path}

      {recommendation}

      Remember: RED → GREEN → REFACTOR
      1. Write failing test first
      2. Implement minimal code to pass
      3. Refactor with tests passing

  # Skill Hook 2: Defense-in-Depth Validation
  - name: validate-input-sanitization
    description: "Ensure user input is validated"
    matcher:
      toolName: ["Write", "Edit"]
      args:
        file_path:
          pattern: "ghl_real_estate_ai/api/.*\\.py$"
    prompt: |
      Validate API endpoint security:

      File: {file_path}
      Code: {new_string or content}

      Defense-in-depth requirements:
      1. Input validation (Pydantic models)
      2. Authentication checks
      3. Authorization enforcement
      4. Rate limiting
      5. Output sanitization (XSS prevention)

      Respond with JSON:
      {
        "layers_implemented": ["input_validation", "auth"],
        "missing_layers": ["rate_limiting"],
        "risk_level": "high|medium|low",
        "recommendations": ["Add @rate_limit decorator"]
      }
    model: claude-3-5-haiku-20241022
    async: true
    message: |
      ⚠️  Defense-in-Depth Analysis

      Implemented: {layers_implemented}
      Missing: {missing_layers}
      Risk Level: {risk_level}

      Recommendations:
      {recommendations}

# =============================================================================
# PERFORMANCE OPTIMIZATION HOOKS
# =============================================================================
# Monitor and optimize hook execution performance

PostToolUse:
  - name: monitor-hook-performance
    description: "Track hook execution time and optimization opportunities"
    matcher:
      toolName: "*"
    async: true
    action:
      type: log
      destination: ".claude/metrics/hook-performance.jsonl"
      format: |
        {
          "timestamp": "{timestamp}",
          "hook_name": "{hook_name}",
          "duration_ms": {duration_ms},
          "model": "{model}",
          "tokens_used": {tokens_used},
          "blocked": {blocked}
        }

# =============================================================================
# CONFIGURATION
# =============================================================================

config:
  # Model settings
  models:
    fast_validation: claude-3-5-haiku-20241022
    deep_analysis: claude-3-5-sonnet-20241022

  # Performance targets
  performance:
    max_hook_duration_ms: 500  # Fast validation target
    max_blocking_hooks: 3  # Limit blocking hooks per tool call
    async_timeout_ms: 5000  # Async hook timeout

  # Cost control
  cost_control:
    max_tokens_per_hook: 1000
    max_daily_hook_invocations: 1000
    budget_alert_threshold: 0.8  # Alert at 80% of daily budget

  # Audit settings
  audit:
    retention_days: 90  # SOC2/HIPAA requirement
    compress_after_days: 30
    encryption: true

  # Rate limiting
  rate_limits:
    subagent_per_5min: 10
    ai_hooks_per_minute: 30
    total_hooks_per_session: 100
