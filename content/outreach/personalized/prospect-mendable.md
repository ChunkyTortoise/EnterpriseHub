# Prospect: Mendable (now SideGuide)

**Segment**: SaaS CTO | **Template**: Template 3
**Priority**: Batch 3, Week 3

---

## Company Research

Mendable (rebranded to SideGuide) is a RAG-powered developer documentation search platform. YC-backed startup that helps companies build AI-powered search for their documentation. The platform lets developers and support teams find answers in documentation using natural language queries. Targets developer tools companies that want AI search for their docs. Built for the API documentation and developer experience use case.

## Why They're a Fit

Mendable/SideGuide is building RAG specifically for documentation -- a use case with extremely high cacheability and repeatable query patterns. Their developer documentation focus means they serve technical companies that value production-grade engineering. As a YC-backed startup, they may need fractional AI architecture support to scale.

## Personalization Hooks

- Documentation search is one of the most cacheable RAG use cases
- Developer tools audience values engineering rigor and test coverage
- YC backing suggests growth ambitions with lean team
- Rebrand from Mendable to SideGuide shows product evolution
- Developer experience focus aligns with API-first, well-tested engineering

---

## Email Sequence

### Day 1: Initial Outreach

**Subject**: Fractional AI CTO -- $150/hr vs $250K/yr hire

Hi team,

Documentation search is one of the best use cases for RAG -- and one of the most cacheable. Developers ask the same questions repeatedly ("How do I authenticate?", "What are the rate limits?"), which means intelligent caching can dramatically reduce costs.

I've built production RAG systems with:
- **88% cache hit rate** via 3-tier caching (semantic layer catches paraphrased queries)
- **89% LLM cost reduction** -- critical for a startup managing burn rate
- **BM25 + semantic search + re-ranking** for high-accuracy retrieval
- **Citation faithfulness: 0.88** -- every answer linked to source docs
- **8,500+ automated tests** -- production-grade quality your developer audience expects

As a fractional AI CTO ($150/hr), I can provide the architecture guidance a YC startup needs without the cost of a $250K+ full-time hire.

Worth a 30-minute discovery call?

Cayman Roden
Python/AI Engineer | Fractional AI CTO
caymanroden@gmail.com | (310) 982-0492

### Day 4: Follow-Up

**Subject**: Re: Fractional AI CTO -- $150/hr vs $250K/yr hire

Quick follow-up with a specific example: documentation queries are the most cacheable workload I've seen. "How do I set up authentication?" and "auth setup guide" and "getting started with API keys" are semantically identical.

My L3 semantic cache catches all three variants. For a docs search platform, this could reduce LLM costs by 70-90%.

15 minutes to discuss?

Cayman

### Day 8: Final Touch

**Subject**: RAG caching for documentation search

I documented the caching architecture optimized for documentation retrieval. Reply "send it" if useful.

Cayman

---

## LinkedIn Messages

### Connection Request

Hi -- I build production RAG pipelines optimized for high-cacheability workloads like documentation search (88% hit rate, 89% cost reduction). Would love to connect and share notes.

### Follow-Up Message

Thanks for connecting. Documentation search is the most cacheable RAG use case. My 3-tier system catches paraphrased queries and serves cached results -- 88% hit rate, 89% cost reduction. Could be directly relevant to your platform. Open to a 15-minute architecture chat?
